{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import nltk\n",
    "import unicodedata\n",
    "import numpy as np\n",
    "from weighted_levenshtein import lev, osa, dam_lev\n",
    "from string import ascii_lowercase\n",
    "from copy import deepcopy\n",
    "import json\n",
    "\n",
    "import sklearn_crfsuite\n",
    "from sklearn_crfsuite.metrics import flat_classification_report\n",
    "from sklearn_crfsuite.metrics import sequence_accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "brand = []\n",
    "with open('brand.csv', newline='', encoding='utf-8') as f:\n",
    "    reader = csv.reader(f)\n",
    "    for row in reader:\n",
    "        brand.append(unicodedata.normalize('NFKD', row[0]).encode('ascii','ignore'))\n",
    "#print(brand)\n",
    "\n",
    "brand_abb = []\n",
    "with open('brand_singkatan.csv', newline='', encoding='utf-8') as f:\n",
    "    reader = csv.reader(f)\n",
    "    for row in reader:\n",
    "        brand_abb.append(unicodedata.normalize('NFKD', row[0]).encode('ascii','ignore'))\n",
    "#print(brand_abb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "alfha = 0.4\n",
    "\n",
    "insert_costs = np.full(128, 100, dtype=np.float64)\n",
    "insert_costs[ord('-')] = 10\n",
    "insert_costs[ord(' ')] = 10\n",
    "\n",
    "delete_costs = np.full(128, 100, dtype=np.float64)\n",
    "delete_costs[ord('-')] = 10\n",
    "delete_costs[ord(' ')] = 10\n",
    "\n",
    "substitute_costs = np.full((128,128), 50, dtype=np.float64)\n",
    "for c in ascii_lowercase:\n",
    "    substitute_costs[ord(c), ord(c.capitalize())] = 10\n",
    "    substitute_costs[ord(c), ord(c)] = 0\n",
    "    substitute_costs[ord(c.capitalize()), ord(c)] = 10\n",
    "    substitute_costs[ord(c.capitalize()), ord(c.capitalize())] = 0\n",
    "substitute_costs[ord('-'), ord(' ')] = 10\n",
    "substitute_costs[ord(' '), ord('-')] = 10\n",
    "for i in range(10):\n",
    "    for j in range(10):\n",
    "        if i == j:\n",
    "            substitute_costs[ord(str(i)), ord(str(j))] = 0\n",
    "            substitute_costs[ord(str(j)), ord(str(i))] = 0\n",
    "        else:\n",
    "            substitute_costs[ord(str(i)), ord(str(j))] = 10\n",
    "            substitute_costs[ord(str(j)), ord(str(i))] = 10\n",
    "\n",
    "def edit_distance_normalized_cost(word, target):\n",
    "    cost = lev(word, target, insert_costs=insert_costs, delete_costs=delete_costs, substitute_costs=substitute_costs)\n",
    "    return (cost + alfha) / len(target)\n",
    "\n",
    "def check_under_threshold(cost, threshold):\n",
    "    if cost <= threshold:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def check_edit_distance_brand(sentence, pos):\n",
    "    threshold = 15\n",
    "    words = sentence.split()\n",
    "    candidate = []\n",
    "    candidate.append(words[pos])\n",
    "    if pos >= 0:\n",
    "        if pos < (len(words) - 1):\n",
    "            candidate.append(words[pos] + \" \" + words[pos + 1])\n",
    "        #if pos < (len(words) - 2):\n",
    "        #      candidate.append(words[pos] + \" \" + words[pos + 1] + \" \" + words[pos + 2])\n",
    "    if (pos - 1) >= 0:\n",
    "        candidate.append(words[pos - 1] + \" \" + words[pos])\n",
    "        if pos < (len(words) - 1):\n",
    "            candidate.append(words[pos - 1] + \" \" + words[pos] + \" \" + words[pos + 1])\n",
    "        #if pos < (len(words) - 2):\n",
    "        #    candidate.append(words[pos - 1] + \" \" + words[pos] + \" \" + words[pos + 1] + \" \" + words[pos + 2])\n",
    "    #if (pos - 2) >= 0:\n",
    "    #    candidate.append(words[pos - 2] + \" \" + words[pos - 1] + \" \" + words[pos])\n",
    "        #if pos < (len(words) - 1):\n",
    "        #    candidate.append(words[pos - 2] + \" \" + words[pos - 1] + \" \" + words[pos] + \" \" + words[pos + 1])\n",
    "        #if pos < (len(words) - 2):\n",
    "        #    candidate.append(words[pos - 2] + \" \" + words[pos - 1] + \" \" + words[pos] + \" \" + words[pos + 1] + \" \" + words[pos + 2])\n",
    "    candidate.sort(key = lambda s: len(s))\n",
    "    exist = False\n",
    "    for c in candidate:\n",
    "        for b in brand:\n",
    "            zzzz = unicodedata.normalize('NFKD', c).encode('ascii','ignore')\n",
    "            if check_under_threshold(edit_distance_normalized_cost(zzzz,b),threshold):\n",
    "                exist = True\n",
    "                break\n",
    "    return exist\n",
    "#print(check_edit_distance_brand('Acquarella',0))\n",
    "\n",
    "def check_edit_distance_brand_abb(word):\n",
    "    threshold = 5\n",
    "    exist = False\n",
    "    for b in brand_abb:\n",
    "        zzzz = unicodedata.normalize('NFKD', word).encode('ascii','ignore')\n",
    "        if check_under_threshold(edit_distance_normalized_cost(zzzz,b),threshold) :\n",
    "            exist = True\n",
    "            break\n",
    "    return exist\n",
    "#print(check_edit_distance_brand_abb('Bb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "unlabeled = []\n",
    "with open(\"unlabeled.txt\", encoding='utf-8') as fd:\n",
    "    for line in fd:\n",
    "        sentence = line[:-2]\n",
    "        tokens = nltk.tokenize.word_tokenize(sentence)\n",
    "        unlabeled.append(tokens)\n",
    "#print(unlabeled[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataTrain = []\n",
    "with open(\"dataTrain.tsv\", encoding='utf-8') as fd:\n",
    "    rd = csv.reader(fd, delimiter=\"\\t\", quotechar='\"')\n",
    "    sentence = []\n",
    "    for row in rd:\n",
    "        if not row:\n",
    "            dataTrain.append(sentence)\n",
    "            sentence = []\n",
    "        else:\n",
    "            sentence.append(row)\n",
    "\n",
    "dataTest = []\n",
    "with open(\"dataTest.tsv\", encoding='utf-8') as fd:\n",
    "    rd = csv.reader(fd, delimiter=\"\\t\", quotechar='\"')\n",
    "    sentence = []\n",
    "    for row in rd:\n",
    "        if not row:\n",
    "            dataTest.append(sentence)\n",
    "            sentence = []\n",
    "        else:\n",
    "            sentence.append(row)\n",
    "dataTrain = list(filter(None, dataTrain))            \n",
    "dataTest = list(filter(None, dataTest))  \n",
    "#print(dataTrain[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word2features(sent, i):\n",
    "    word = sent[i][0]\n",
    "    #postag = sent[i][1]\n",
    "    sentence = ''\n",
    "    for w in sent:\n",
    "        sentence += w[0] + \" \"\n",
    "    features = {\n",
    "        'bias': 1.0,\n",
    "        'word.lower()': word.lower(),\n",
    "        'word[-3:]': word[-3:],\n",
    "        'word[-2:]': word[-2:],\n",
    "        'word.isupper()': word.isupper(),\n",
    "        'word.istitle()': word.istitle(),\n",
    "        'word.isdigit()': word.isdigit(),\n",
    "        'word.onList': check_edit_distance_brand(sentence,i),\n",
    "        'word.onListAbb': check_edit_distance_brand_abb(word)\n",
    "        #'postag': postag,\n",
    "        #'postag[:2]': postag[:2],\n",
    "    }\n",
    "    if i > 0:\n",
    "        word1 = sent[i-1][0]\n",
    "        #postag1 = sent[i-1][1]\n",
    "        features.update({\n",
    "            '-1:word.lower()': word1.lower(),\n",
    "            '-1:word.istitle()': word1.istitle(),\n",
    "            '-1:word.isupper()': word1.isupper(),\n",
    "            #'-1:onList': check_edit_distance_brand(sentence,(i - 1)),\n",
    "            #'-1:postag': postag1,\n",
    "            #'-1:postag[:2]': postag1[:2],\n",
    "        })\n",
    "    else:\n",
    "        features['BOS'] = True\n",
    "\n",
    "    if i < len(sent)-1:\n",
    "        word1 = sent[i+1][0]\n",
    "        #postag1 = sent[i+1][1]\n",
    "        features.update({\n",
    "            '+1:word.lower()': word1.lower(),\n",
    "            '+1:word.istitle()': word1.istitle(),\n",
    "            '+1:word.isupper()': word1.isupper(),\n",
    "            #'+1:postag': postag1,\n",
    "            #'+1:postag[:2]': postag1[:2],\n",
    "            #'+1:onList': check_edit_distance_brand(sentence,(i + 1)),\n",
    "        })\n",
    "    else:\n",
    "        features['EOS'] = True\n",
    "\n",
    "    return features\n",
    "\n",
    "\n",
    "def sent2features(sent):\n",
    "    return [word2features(sent, i) for i in range(len(sent))]\n",
    "\n",
    "def sent2labels(sent):\n",
    "    return [label for token, label in sent]\n",
    "\n",
    "def sent2tokens(sent):\n",
    "    return [token for token, label in sent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = [sent2features(s) for s in dataTrain]\n",
    "y_train = [sent2labels(s) for s in dataTrain]\n",
    "\n",
    "X_test = [sent2features(s) for s in dataTest]\n",
    "y_test = [sent2labels(s) for s in dataTest]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_unlabeled = [sent2features(s) for s in unlabeled]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "a = [1,2,3]\n",
    "if a:\n",
    "    print(a)\n",
    "while(a):\n",
    "    a.pop()\n",
    "print(a)\n",
    "print(X_unlabeled[0])\n",
    "print(y_train[0])\n",
    "i = 3\n",
    "while(i > 0):\n",
    "    i -= 3\n",
    "    print('boo')\n",
    "'''\n",
    "#print(X_train[0][0])\n",
    "#print(X_unlabeled[0][0])\n",
    "json.dump(X_train, open(\"X_train.txt\",'w'))\n",
    "json.dump(y_train, open(\"y_train.txt\",'w'))\n",
    "json.dump(X_test, open(\"X_test.txt\",'w'))\n",
    "json.dump(y_test, open(\"y_test.txt\",'w'))\n",
    "json.dump(X_unlabeled, open(\"X_unlabeled.txt\",'w'))\n",
    "#d2 = json.load(open(\"X_train.txt\"))\n",
    "#print(d2[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CRF(algorithm='lbfgs', all_possible_states=None, all_possible_transitions=True,\n",
       "    averaging=None, c=None, c1=0.1, c2=0.1, calibration_candidates=None,\n",
       "    calibration_eta=None, calibration_max_trials=None, calibration_rate=None,\n",
       "    calibration_samples=None, delta=None, epsilon=None, error_sensitive=None,\n",
       "    gamma=None, keep_tempfiles=None, linesearch=None, max_iterations=100,\n",
       "    max_linesearch=None, min_freq=None, model_filename=None, num_memories=None,\n",
       "    pa_type=None, period=None, trainer_cls=None, variance=None, verbose=False)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crf = sklearn_crfsuite.CRF(\n",
    "    algorithm='lbfgs',\n",
    "    c1=0.1,\n",
    "    c2=0.1,\n",
    "    max_iterations=100,\n",
    "    all_possible_transitions=True\n",
    ")\n",
    "crf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       B-BRA      0.641     0.543     0.588        46\n",
      "       I-BRA      0.333     0.444     0.381         9\n",
      "       B-PRO      0.500     0.190     0.276        21\n",
      "       I-PRO      0.361     0.312     0.335       112\n",
      " B-PRO|B-BRA      0.779     0.688     0.731        77\n",
      " I-PRO|B-BRA      0.769     0.370     0.500        27\n",
      " B-PRO|B-TYP      0.000     0.000     0.000        11\n",
      " I-PRO|B-TYP      0.600     0.441     0.508        68\n",
      " I-PRO|I-BRA      0.750     0.536     0.625        28\n",
      " I-PRO|I-TYP      0.500     0.333     0.400        90\n",
      "       B-TYP      0.000     0.000     0.000         9\n",
      "       I-TYP      0.000     0.000     0.000         6\n",
      "\n",
      "   micro avg      0.558     0.409     0.472       504\n",
      "   macro avg      0.436     0.322     0.362       504\n",
      "weighted avg      0.538     0.409     0.460       504\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = crf.predict(X_test)\n",
    "labels = list(crf.classes_)\n",
    "labels.remove('O') # remove 'O' label from evaluation\n",
    "sorted_labels = sorted(labels,key=lambda name: (name[1:], name[0])) # group B and I results\n",
    "print(flat_classification_report(y_test, y_pred, labels=sorted_labels, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0-4488- lower:0.9 - upper:0.95\n",
      "1-3819- lower:0.9 - upper:0.95\n",
      "2-3495- lower:0.9 - upper:0.95\n",
      "3-3375- lower:0.9 - upper:0.95\n",
      "4-3300- lower:0.9 - upper:0.95\n",
      "5-3263- lower:0.9 - upper:0.95\n",
      "6-3238- lower:0.9 - upper:0.95\n",
      "7-3224- lower:0.9 - upper:0.95\n",
      "8-3215- lower:0.9 - upper:0.95\n",
      "9-3209- lower:0.9 - upper:0.95\n",
      "10-3204- lower:0.9 - upper:0.95\n",
      "11-3202- lower:0.9 - upper:0.95\n",
      "12-3202- lower:0.89 - upper:0.955\n",
      "13-3200- lower:0.89 - upper:0.955\n",
      "14-3199- lower:0.89 - upper:0.955\n",
      "15-3198- lower:0.89 - upper:0.955\n",
      "16-3198- lower:0.88 - upper:0.96\n",
      "17-3192- lower:0.88 - upper:0.96\n",
      "18-3187- lower:0.88 - upper:0.96\n",
      "19-3182- lower:0.88 - upper:0.96\n",
      "20-3175- lower:0.88 - upper:0.96\n",
      "21-3168- lower:0.88 - upper:0.96\n",
      "22-3164- lower:0.88 - upper:0.96\n",
      "23-3161- lower:0.88 - upper:0.96\n",
      "24-3160- lower:0.88 - upper:0.96\n",
      "25-3157- lower:0.88 - upper:0.96\n",
      "26-3156- lower:0.88 - upper:0.96\n",
      "27-3151- lower:0.88 - upper:0.96\n",
      "28-3148- lower:0.88 - upper:0.96\n",
      "29-3147- lower:0.88 - upper:0.96\n",
      "30-3147- lower:0.87 - upper:0.965\n",
      "31-3144- lower:0.87 - upper:0.965\n",
      "32-3142- lower:0.87 - upper:0.965\n",
      "33-3138- lower:0.87 - upper:0.965\n",
      "34-3133- lower:0.87 - upper:0.965\n",
      "35-3132- lower:0.87 - upper:0.965\n",
      "36-3129- lower:0.87 - upper:0.965\n",
      "37-3126- lower:0.87 - upper:0.965\n",
      "38-3123- lower:0.87 - upper:0.965\n",
      "39-3121- lower:0.87 - upper:0.965\n",
      "40-3119- lower:0.87 - upper:0.965\n",
      "41-3118- lower:0.87 - upper:0.965\n",
      "42-3117- lower:0.87 - upper:0.965\n",
      "43-3116- lower:0.87 - upper:0.965\n",
      "44-3116- lower:0.86 - upper:0.97\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "for i in range(len(y_test)):\n",
    "    print(y_test[i])\n",
    "    print(y_pred[i])\n",
    "    print(sequence_accuracy_score(y_test[i], y_pred[i]))\n",
    "'''\n",
    "X_train_sup = deepcopy(X_train)\n",
    "y_train_sup = deepcopy(y_train)\n",
    "X_unlabeled_sup = deepcopy(X_unlabeled)\n",
    "unlabeled_sup = deepcopy(unlabeled)\n",
    "upper = 0.95\n",
    "lower = 0.9\n",
    "w = 0\n",
    "label_for_unlabeled = []\n",
    "while(X_unlabeled_sup):#or w < 1 (default: X_unlabeled_sup)\n",
    "    print(str(w) + '-' + str(len(X_unlabeled_sup)) + '- lower:' + str(lower) + ' - upper:' + str(upper))\n",
    "    found = False\n",
    "    num = []\n",
    "    w += 1\n",
    "    for z in range(len(X_unlabeled_sup)): #X_test/X_unlabeled\n",
    "        a = crf.predict_marginals_single(X_unlabeled_sup[z])\n",
    "        b = crf.predict_single(X_unlabeled_sup[z]) #same, but not used becaused it's already predicted before, it's in y_pred\n",
    "        #b = y_pred[z]\n",
    "        total = 0\n",
    "        size = len(a)\n",
    "        for i in range(size):\n",
    "            total += a[i][b[i]]\n",
    "        confidence = total / size\n",
    "        #print(confidence)\n",
    "        if confidence < upper and confidence > lower:\n",
    "            found = True\n",
    "            row = []\n",
    "            row.append(unlabeled_sup[z])\n",
    "            row.append(b)\n",
    "            label_for_unlabeled.append(row)\n",
    "            X_train_sup.append(X_unlabeled_sup[z])\n",
    "            y_train_sup.append(b)\n",
    "            num.append(z)\n",
    "    if found == True:\n",
    "        num.sort(reverse=True)\n",
    "        for i in num:\n",
    "            X_unlabeled_sup.pop(i)\n",
    "            unlabeled_sup.pop(i)\n",
    "        crf.fit(X_train_sup, y_train_sup)\n",
    "    else:\n",
    "        if lower > 0.6:\n",
    "            lower -= 0.01\n",
    "        else:\n",
    "            lower -= 0.05\n",
    "        if upper < 0.99:\n",
    "            if upper >= 0.98:\n",
    "                upper += 0.001\n",
    "            else:\n",
    "                upper += 0.005\n",
    "        elif lower < 0.4:\n",
    "            upper += 0.001\n",
    "y_pred = crf.predict(X_test)\n",
    "labels = list(crf.classes_)\n",
    "labels.remove('O') # remove 'O' label from evaluation\n",
    "sorted_labels = sorted(labels,key=lambda name: (name[1:], name[0])) # group B and I results\n",
    "print(flat_classification_report(y_test, y_pred, labels=sorted_labels, digits=3))\n",
    "#print(label_for_unlabeled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataTest_labels = []\n",
    "for sentence in dataTest:\n",
    "    aa = [token[1] for token in sentence]\n",
    "    dataTest_labels.append(aa)\n",
    "    \n",
    "dataTest_token = []\n",
    "for sentence in dataTest:\n",
    "    aa = [token[0] for token in sentence]\n",
    "    dataTest_token.append(aa)\n",
    "\n",
    "#print(dataTest_labels[0])\n",
    "#print(dataTest_token[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bra_data = []\n",
    "bra_guess = []\n",
    "typ_data = []\n",
    "typ_guess = []\n",
    "pro_data = []\n",
    "pro_guess = []\n",
    "o_data = []\n",
    "o_guess = []\n",
    "for i in range(len(dataTest)):\n",
    "    bra_data_row = []\n",
    "    bra_guess_row = []\n",
    "    typ_data_row = []\n",
    "    typ_guess_row = []\n",
    "    pro_data_row = []\n",
    "    pro_guess_row = []\n",
    "    o_data_row = []\n",
    "    o_guess_row = []\n",
    "    sen_pro_data = ''\n",
    "    sen_pro_guess = ''\n",
    "    sen_typ_data = ''\n",
    "    sen_typ_guess = ''\n",
    "    sen_bra_data = ''\n",
    "    sen_bra_guess = ''\n",
    "    for j in range(len(dataTest[i])):        \n",
    "        if dataTest_labels[i][j] == 'O':\n",
    "            o_data_row.append(dataTest_token[i][j])\n",
    "            if sen_pro_data:\n",
    "                pro_data_row.append(sen_pro_data)\n",
    "                sen_pro_data = ''\n",
    "            elif sen_bra_data:\n",
    "                bra_data_row.append(sen_bra_data)\n",
    "                sen_bra_data = ''\n",
    "            elif sen_typ_data:\n",
    "                typ_data_row.append(sen_typ_data)\n",
    "                sen_typ_data = ''\n",
    "        else:\n",
    "            if '|' in dataTest_labels[i][j]:\n",
    "                if sen_pro_data and dataTest_labels[i][j][0] == 'B':\n",
    "                    pro_data_row.append(sen_pro_data)\n",
    "                    sen_pro_data = ''\n",
    "                    sen_pro_data += dataTest_token[i][j]\n",
    "                elif dataTest_labels[i][j][0] == 'B':\n",
    "                    sen_pro_data += dataTest_token[i][j]\n",
    "                elif dataTest_labels[i][j][0] == 'I':\n",
    "                    sen_pro_data += ' ' + dataTest_token[i][j]\n",
    "                if dataTest_labels[i][j][8:] == 'BRA':\n",
    "                    if sen_bra_data and dataTest_labels[i][j][6:7] == 'B':\n",
    "                        bra_data_row.append(sen_bra_data)\n",
    "                        sen_bra_data = ''\n",
    "                        sen_bra_data += dataTest_token[i][j]\n",
    "                    elif dataTest_labels[i][j][6:7] == 'B':\n",
    "                        sen_bra_data += dataTest_token[i][j]\n",
    "                    elif dataTest_labels[i][j][6:7] == 'I':\n",
    "                        sen_bra_data += ' ' + dataTest_token[i][j]\n",
    "                elif dataTest_labels[i][j][8:] == 'TYP':\n",
    "                    if sen_typ_data and dataTest_labels[i][j][6:7] == 'B':\n",
    "                        typ_data_row.append(sen_typ_data)\n",
    "                        sen_typ_data = ''\n",
    "                        sen_typ_data += dataTest_token[i][j]\n",
    "                    elif dataTest_labels[i][j][6:7] == 'B':\n",
    "                        sen_typ_data += dataTest_token[i][j]\n",
    "                    elif dataTest_labels[i][j][6:7] == 'I':\n",
    "                        sen_typ_data += ' ' + dataTest_token[i][j]\n",
    "            elif dataTest_labels[i][j][2:5] == 'PRO':\n",
    "                if sen_pro_data and dataTest_labels[i][j][0] == 'B':\n",
    "                    pro_data_row.append(sen_pro_data)\n",
    "                    sen_pro_data = ''\n",
    "                    sen_pro_data += dataTest_token[i][j]\n",
    "                elif dataTest_labels[i][j][0] == 'B':\n",
    "                    sen_pro_data += dataTest_token[i][j]\n",
    "                elif dataTest_labels[i][j][0] == 'I':\n",
    "                    sen_pro_data += ' ' + dataTest_token[i][j]\n",
    "            elif dataTest_labels[i][j][2:5] == 'BRA':\n",
    "                if sen_bra_data and dataTest_labels[i][j][0] == 'B':\n",
    "                    bra_data_row.append(sen_bra_data)\n",
    "                    sen_bra_data = ''\n",
    "                    sen_bra_data += dataTest_token[i][j]\n",
    "                elif dataTest_labels[i][j][0] == 'B':\n",
    "                    sen_bra_data += dataTest_token[i][j]\n",
    "                elif dataTest_labels[i][j][0] == 'I':\n",
    "                    sen_bra_data += ' ' + dataTest_token[i][j]\n",
    "            elif dataTest_labels[i][j][2:5] == 'TYP':\n",
    "                if sen_typ_data and dataTest_labels[i][j][0] == 'B':\n",
    "                    typ_data_row.append(sen_typ_data)\n",
    "                    sen_typ_data = ''\n",
    "                    sen_typ_data += dataTest_token[i][j]\n",
    "                elif dataTest_labels[i][j][0] == 'B':\n",
    "                    sen_typ_data += dataTest_token[i][j]\n",
    "                elif dataTest_labels[i][j][0] == 'I':\n",
    "                    sen_typ_data += ' ' + dataTest_token[i][j]\n",
    "        if y_pred[i][j] == 'O':\n",
    "            o_guess_row.append(dataTest_token[i][j])\n",
    "            if sen_pro_guess:\n",
    "                pro_guess_row.append(sen_pro_guess)\n",
    "                sen_pro_guess = ''\n",
    "            elif sen_bra_guess:\n",
    "                bra_guess_row.append(sen_bra_guess)\n",
    "                sen_bra_guess = ''\n",
    "            elif sen_typ_guess:\n",
    "                typ_guess_row.append(sen_typ_guess)\n",
    "                sen_typ_guess = ''\n",
    "        else:\n",
    "            if '|' in y_pred[i][j]:\n",
    "                if sen_pro_guess and y_pred[i][j][0] == 'B':\n",
    "                    pro_guess_row.append(sen_pro_guess)\n",
    "                    sen_pro_guess = ''\n",
    "                    sen_pro_guess += dataTest_token[i][j]\n",
    "                elif y_pred[i][j][0] == 'B':\n",
    "                    sen_pro_guess += dataTest_token[i][j]\n",
    "                elif y_pred[i][j][0] == 'I':\n",
    "                    sen_pro_guess += ' ' + dataTest_token[i][j]\n",
    "                if y_pred[i][j][8:] == 'BRA':\n",
    "                    if sen_bra_guess and y_pred[i][j][6:7] == 'B':\n",
    "                        bra_guess_row.append(sen_bra_guess)\n",
    "                        sen_bra_guess = ''\n",
    "                        sen_bra_guess += dataTest_token[i][j]\n",
    "                    elif y_pred[i][j][6:7] == 'B':\n",
    "                        sen_bra_guess += dataTest_token[i][j]\n",
    "                    elif y_pred[i][j][6:7] == 'I':\n",
    "                        sen_bra_guess += ' ' + dataTest_token[i][j]\n",
    "                elif y_pred[i][j][8:] == 'TYP':\n",
    "                    if sen_typ_guess and y_pred[i][j][6:7] == 'B':\n",
    "                        typ_guess_row.append(sen_typ_guess)\n",
    "                        sen_typ_guess = ''\n",
    "                        sen_typ_guess += dataTest_token[i][j]\n",
    "                    elif y_pred[i][j][6:7] == 'B':\n",
    "                        sen_typ_guess += dataTest_token[i][j]\n",
    "                    elif y_pred[i][j][6:7] == 'I':\n",
    "                        sen_typ_guess += ' ' + dataTest_token[i][j]\n",
    "            elif y_pred[i][j][2:5] == 'PRO':\n",
    "                if sen_pro_guess and y_pred[i][j][0] == 'B':\n",
    "                    pro_guess_row.append(sen_pro_guess)\n",
    "                    sen_pro_guess = ''\n",
    "                    sen_pro_guess += dataTest_token[i][j]\n",
    "                elif y_pred[i][j][0] == 'B':\n",
    "                    sen_pro_guess += dataTest_token[i][j]\n",
    "                elif y_pred[i][j][0] == 'I':\n",
    "                    sen_pro_guess += ' ' + dataTest_token[i][j]\n",
    "            elif y_pred[i][j][2:5] == 'BRA':\n",
    "                if sen_bra_guess and y_pred[i][j][0] == 'B':\n",
    "                    bra_guess_row.append(sen_bra_guess)\n",
    "                    sen_bra_guess = ''\n",
    "                    sen_bra_guess += dataTest_token[i][j]\n",
    "                elif y_pred[i][j][0] == 'B':\n",
    "                    sen_bra_guess += dataTest_token[i][j]\n",
    "                elif y_pred[i][j][0] == 'I':\n",
    "                    sen_bra_guess += ' ' + dataTest_token[i][j]\n",
    "            elif y_pred[i][j][2:5] == 'TYP':\n",
    "                if sen_typ_guess and y_pred[i][j][0] == 'B':\n",
    "                    typ_guess_row.append(sen_typ_guess)\n",
    "                    sen_typ_guess = ''\n",
    "                    sen_typ_guess += dataTest_token[i][j]\n",
    "                elif y_pred[i][j][0] == 'B':\n",
    "                    sen_typ_guess += dataTest_token[i][j]\n",
    "                elif y_pred[i][j][0] == 'I':\n",
    "                    sen_typ_guess += ' ' + dataTest_token[i][j]\n",
    "    if sen_pro_data:\n",
    "        pro_data_row.append(sen_pro_data)\n",
    "    elif sen_bra_data:\n",
    "        bra_data_row.append(sen_bra_data)\n",
    "    elif sen_typ_data:\n",
    "        typ_data_row.append(sen_typ_data)\n",
    "    if sen_pro_guess:\n",
    "        pro_guess_row.append(sen_pro_guess)\n",
    "    elif sen_bra_guess:\n",
    "        bra_guess_row.append(sen_bra_guess)\n",
    "    elif sen_typ_guess:\n",
    "        typ_guess_row.append(sen_typ_guess)\n",
    "    o_data.append(o_data_row)\n",
    "    o_guess.append(o_guess_row)\n",
    "    pro_data.append(pro_data_row)\n",
    "    pro_guess.append(pro_guess_row)\n",
    "    bra_data.append(bra_data_row)\n",
    "    bra_guess.append(bra_guess_row)\n",
    "    typ_data.append(typ_data_row)\n",
    "    typ_guess.append(typ_guess_row)\n",
    "'''\n",
    "for i in range(len(bra_data)):\n",
    "    print('PRO')\n",
    "    print(pro_data[i])\n",
    "    print(pro_guess[i])\n",
    "    print('BRA')\n",
    "    print(bra_data[i])\n",
    "    print(bra_guess[i])\n",
    "    print('TYP')\n",
    "    print(typ_data[i])\n",
    "    print(typ_guess[i])\n",
    "    print('---------')\n",
    "'''\n",
    "#none is the actual number from data test, r is number of guess right, g is number of guess\n",
    "bra = 0\n",
    "bra_r = 0\n",
    "bra_g = 0\n",
    "typ = 0\n",
    "typ_r = 0\n",
    "typ_g = 0\n",
    "pro = 0\n",
    "pro_r = 0\n",
    "pro_g = 0\n",
    "o = 0\n",
    "o_r = 0\n",
    "o_g = 0\n",
    "for i in range(len(pro_data)):\n",
    "    for j in range(len(pro_data[i])):\n",
    "        pro += 1\n",
    "    for j in range(len(pro_guess[i])):\n",
    "        pro_g += 1\n",
    "        if pro_guess[i][j] in pro_data[i]:\n",
    "            pro_r += 1\n",
    "            pro_data[i].remove(pro_guess[i][j])\n",
    "    for j in range(len(bra_data[i])):\n",
    "        bra += 1\n",
    "    for j in range(len(bra_guess[i])):\n",
    "        bra_g += 1\n",
    "        if bra_guess[i][j] in bra_data[i]:\n",
    "            bra_r += 1\n",
    "            bra_data[i].remove(bra_guess[i][j])\n",
    "    for j in range(len(typ_data[i])):\n",
    "        typ += 1\n",
    "    for j in range(len(typ_guess[i])):\n",
    "        typ_g += 1\n",
    "        if typ_guess[i][j] in typ_data[i]:\n",
    "            typ_r += 1\n",
    "            typ_data[i].remove(typ_guess[i][j])\n",
    "    for j in range(len(o_data[i])):\n",
    "        o += 1\n",
    "    for j in range(len(o_guess[i])):\n",
    "        o_g += 1\n",
    "        if o_guess[i][j] in o_data[i]:\n",
    "            o_r += 1\n",
    "            o_data[i].remove(o_guess[i][j])\n",
    "\n",
    "print('PRO')\n",
    "precision_pro = pro_r/pro_g\n",
    "recall_pro = pro_r/pro\n",
    "f1_pro = 2 * ((precision_pro * recall_pro)/(precision_pro + recall_pro))\n",
    "print('Precision : ' + str(precision_pro))\n",
    "print('Recall : ' + str(recall_pro))\n",
    "print('F1 : ' + str(f1_pro))\n",
    "print('BRA')\n",
    "precision_bra = bra_r/bra_g\n",
    "recall_bra = bra_r/bra\n",
    "f1_bra = 2 * ((precision_bra * recall_bra)/(precision_bra + recall_bra))\n",
    "print('Precision : ' + str(precision_bra))\n",
    "print('Recall : ' + str(recall_bra))\n",
    "print('F1 : ' + str(f1_bra))\n",
    "print('TYP')\n",
    "precision_typ = typ_r/typ_g\n",
    "recall_typ = typ_r/typ\n",
    "f1_typ = 2 * ((precision_typ * recall_typ)/(precision_typ + recall_typ))\n",
    "print('Precision : ' + str(precision_typ))\n",
    "print('Recall : ' + str(recall_typ))\n",
    "print('F1 : ' + str(f1_typ))\n",
    "print('O')\n",
    "precision_o = o_r/o_g\n",
    "recall_o = o_r/o\n",
    "f1_o = 2 * ((precision_o * recall_o)/(precision_o + recall_o))\n",
    "print('Precision : ' + str(precision_o))\n",
    "print('Recall : ' + str(recall_o))\n",
    "print('F1 : ' + str(f1_o))\n",
    "print('Overall Without O')\n",
    "total = pro + typ + bra\n",
    "precision = ((pro * precision_pro) + (bra * precision_bra) + (typ * precision_typ)) / total\n",
    "recall = ((pro * recall_pro) + (bra * recall_bra) + (typ * recall_typ)) / total\n",
    "f1 = ((pro * f1_pro) + (bra * f1_bra) + (typ * f1_typ)) / total\n",
    "print('Precision : ' + str(precision))\n",
    "print('Recall : ' + str(recall))\n",
    "print('F1 : ' + str(f1))\n",
    "print('Overall With O')\n",
    "total = pro + typ + bra + o\n",
    "precision = ((pro * precision_pro) + (bra * precision_bra) + (typ * precision_typ) + (o * precision_o)) / total\n",
    "recall = ((pro * recall_pro) + (bra * recall_bra) + (typ * recall_typ) + (o * recall_o)) / total\n",
    "f1 = ((pro * f1_pro) + (bra * f1_bra) + (typ * f1_typ) + (o * f1_o)) / total\n",
    "print('Precision : ' + str(precision))\n",
    "print('Recall : ' + str(recall))\n",
    "print('F1 : ' + str(f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('labeled_automatically (4).tsv','w', encoding='utf-8') \n",
    "for i in range(len(label_for_unlabeled)):\n",
    "    for j in range(len(label_for_unlabeled[i][0])):\n",
    "        f.write(label_for_unlabeled[i][0][j])\n",
    "        f.write('\\t')\n",
    "        f.write(label_for_unlabeled[i][1][j])\n",
    "        f.write('\\n')\n",
    "        #print(label_for_unlabeled[i][j])\n",
    "        #print(label_for_unlabeled[i + 1][j])\n",
    "    f.write('\\n')\n",
    "f.write('\\n')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
