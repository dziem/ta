{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import nltk\n",
    "import unicodedata\n",
    "import numpy as np\n",
    "from weighted_levenshtein import lev, osa, dam_lev\n",
    "from string import ascii_lowercase\n",
    "from copy import deepcopy\n",
    "import json\n",
    "import re\n",
    "from collections import Counter\n",
    "import scipy.stats\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "import sklearn_crfsuite\n",
    "from sklearn_crfsuite.metrics import flat_classification_report\n",
    "from sklearn_crfsuite.metrics import sequence_accuracy_score\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn_crfsuite import metrics\n",
    "from sklearn_crfsuite import scorers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read brand and brand abbreviation for the edit distance\n",
    "brand = []\n",
    "with open('brand.csv', newline='', encoding='utf-8') as f:\n",
    "    reader = csv.reader(f)\n",
    "    for row in reader:\n",
    "        brand.append(unicodedata.normalize('NFKD', row[0]).encode('ascii','ignore'))\n",
    "#print(brand)\n",
    "\n",
    "brand_abb = []\n",
    "with open('brand_singkatan.csv', newline='', encoding='utf-8') as f:\n",
    "    reader = csv.reader(f)\n",
    "    for row in reader:\n",
    "        brand_abb.append(unicodedata.normalize('NFKD', row[0]).encode('ascii','ignore'))\n",
    "#print(brand_abb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the edit distance function\n",
    "alfha = 0.4\n",
    "\n",
    "insert_costs = np.full(128, 100, dtype=np.float64)\n",
    "insert_costs[ord('-')] = 10\n",
    "insert_costs[ord(' ')] = 10\n",
    "\n",
    "delete_costs = np.full(128, 100, dtype=np.float64)\n",
    "delete_costs[ord('-')] = 10\n",
    "delete_costs[ord(' ')] = 10\n",
    "\n",
    "substitute_costs = np.full((128,128), 50, dtype=np.float64)\n",
    "for c in ascii_lowercase:\n",
    "    substitute_costs[ord(c), ord(c.capitalize())] = 10\n",
    "    substitute_costs[ord(c), ord(c)] = 0\n",
    "    substitute_costs[ord(c.capitalize()), ord(c)] = 10\n",
    "    substitute_costs[ord(c.capitalize()), ord(c.capitalize())] = 0\n",
    "substitute_costs[ord('-'), ord(' ')] = 10\n",
    "substitute_costs[ord(' '), ord('-')] = 10\n",
    "for i in range(10):\n",
    "    for j in range(10):\n",
    "        if i == j:\n",
    "            substitute_costs[ord(str(i)), ord(str(j))] = 0\n",
    "            substitute_costs[ord(str(j)), ord(str(i))] = 0\n",
    "        else:\n",
    "            substitute_costs[ord(str(i)), ord(str(j))] = 10\n",
    "            substitute_costs[ord(str(j)), ord(str(i))] = 10\n",
    "\n",
    "def edit_distance_normalized_cost(word, target):\n",
    "    cost = lev(word, target, insert_costs=insert_costs, delete_costs=delete_costs, substitute_costs=substitute_costs)\n",
    "    return (cost + alfha) / len(target)\n",
    "\n",
    "def check_under_threshold(cost, threshold):\n",
    "    if cost <= threshold:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def check_edit_distance_brand(sentence, pos):\n",
    "    threshold = 15\n",
    "    words = sentence.split()\n",
    "    candidate = []\n",
    "    candidate.append(words[pos])\n",
    "    if pos >= 0:\n",
    "        if pos < (len(words) - 1):\n",
    "            candidate.append(words[pos] + \" \" + words[pos + 1])\n",
    "        #if pos < (len(words) - 2):\n",
    "        #      candidate.append(words[pos] + \" \" + words[pos + 1] + \" \" + words[pos + 2])\n",
    "    if (pos - 1) >= 0:\n",
    "        candidate.append(words[pos - 1] + \" \" + words[pos])\n",
    "        if pos < (len(words) - 1):\n",
    "            candidate.append(words[pos - 1] + \" \" + words[pos] + \" \" + words[pos + 1])\n",
    "        #if pos < (len(words) - 2):\n",
    "        #    candidate.append(words[pos - 1] + \" \" + words[pos] + \" \" + words[pos + 1] + \" \" + words[pos + 2])\n",
    "    #if (pos - 2) >= 0:\n",
    "    #    candidate.append(words[pos - 2] + \" \" + words[pos - 1] + \" \" + words[pos])\n",
    "        #if pos < (len(words) - 1):\n",
    "        #    candidate.append(words[pos - 2] + \" \" + words[pos - 1] + \" \" + words[pos] + \" \" + words[pos + 1])\n",
    "        #if pos < (len(words) - 2):\n",
    "        #    candidate.append(words[pos - 2] + \" \" + words[pos - 1] + \" \" + words[pos] + \" \" + words[pos + 1] + \" \" + words[pos + 2])\n",
    "    candidate.sort(key = lambda s: len(s))\n",
    "    exist = False\n",
    "    for c in candidate:\n",
    "        for b in brand:\n",
    "            zzzz = unicodedata.normalize('NFKD', c).encode('ascii','ignore')\n",
    "            if check_under_threshold(edit_distance_normalized_cost(zzzz,b),threshold):\n",
    "                exist = True\n",
    "                break\n",
    "    return exist\n",
    "#print(check_edit_distance_brand('Acquarella',0))\n",
    "\n",
    "def check_edit_distance_brand_abb(word):\n",
    "    threshold = 5\n",
    "    exist = False\n",
    "    for b in brand_abb:\n",
    "        zzzz = unicodedata.normalize('NFKD', word).encode('ascii','ignore')\n",
    "        if check_under_threshold(edit_distance_normalized_cost(zzzz,b),threshold) :\n",
    "            exist = True\n",
    "            break\n",
    "    return exist\n",
    "#print(check_edit_distance_brand_abb('Bb'))\n",
    "\n",
    "common_token_before = ['pake','pakai','ama','sama','yang','yg','si','dari','dr','merk','pakek','pk','coba','merek','brand','by']\n",
    "def check_edit_distance_common(word):\n",
    "    threshold = 5\n",
    "    exist = False\n",
    "    for b in common_token_before:\n",
    "        zzzz = unicodedata.normalize('NFKD', word).encode('ascii','ignore')\n",
    "        if check_under_threshold(edit_distance_normalized_cost(zzzz,b),threshold) :\n",
    "            exist = True\n",
    "            break\n",
    "    return exist\n",
    "#print(check_edit_distance_common('dr'))\n",
    "def list_indication(word):\n",
    "    if bool(re.match(r\"[0-9].\", word)):\n",
    "        return True\n",
    "    elif word == '-' or word == ',' or word == 'dan' or word == '&' or word == 'and' or word == '*' or word =='+':\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "thing_in_pro = ['shampoo', 'conditioner', 'volumizer cream', 'cat rambut', 'serum', 'lipstik', 'lipstick', 'l/p', 'bb cream', 'eyeliner', 'mascara', 'foundation', 'foundi', 'brush', 'brushes', 'pressed powder', 'eyeshadow cream', 'liquid liner', 'palette', 'bronzer', 'blush', 'eyeshadow', 'liquid lipstick', 'concealer', 'lipbalm', 'cheek stain', 'compact powder', 'powder', 'lip stain', 'lip butter', 'lip velvet', 'baby oil', 'overnight serum', 'toner', 'face wash', 'lotion', 'uv milk', 'cleansing oil', 'cleanser', 'cream', 'remover', 'essence', 'moist', 'moisturizer', 'facial wash', 'facial foam', 'mask sheet', 'brightening foam', 'make up remover', 'sabun', 'night cream', 'pelembab', 'lulur', 'skin food', 'sunblock', 'facial mask', 'peel off', 'remover', 'gel eyeliner', 'aminexil', 'curling oil', 'sisir', 'hair color', 'hairspray', 'swatch', 'e/s', 'e/l', 'l/s', 'eyelash curler', 'lip glaze', 'fluidline', 'bedak', 'deodorants', 'pensil alis', 'petroleum jelly', 'milk cleanser', 'nail polish', 'cleansing foam', 'cleansing milk', 'lipnicure', 'lip liner', 'lip velvet', 'dupe', 'loose powder', 'bbc', 'bb', 'tinted moisturizer','TM', 'eye cream', 'spray', 'face spray', 'facial mist', 'air mawar', 'lip filler', 'cleansing balm', 'oil', 'c/o', 'clay mask', 'sunscreen', 'moisturizing lotion', 'lip scrub', 'skin conditioner', 'lip therapy', 'mousse', 'seri','line','range', 'erase paste', 'tweezer', 'blush on', 'baby powder', 'bath soap', 'hydrosol', 'mask', 'wipes', 'masker']\n",
    "def check_edit_distance_thing(sentence, pos):\n",
    "    threshold = 10\n",
    "    words = sentence.split()\n",
    "    candidate = []\n",
    "    candidate.append(words[pos])\n",
    "    if pos >= 0:\n",
    "        if pos < (len(words) - 1):\n",
    "            candidate.append(words[pos] + \" \" + words[pos + 1])\n",
    "    if (pos - 1) >= 0:\n",
    "        candidate.append(words[pos - 1] + \" \" + words[pos])\n",
    "        if pos < (len(words) - 1):\n",
    "            candidate.append(words[pos - 1] + \" \" + words[pos] + \" \" + words[pos + 1])\n",
    "    candidate.sort(key = lambda s: len(s))\n",
    "    exist = False\n",
    "    for c in candidate:\n",
    "        for b in thing_in_pro:\n",
    "            zzzz = unicodedata.normalize('NFKD', c).encode('ascii','ignore')\n",
    "            if check_under_threshold(edit_distance_normalized_cost(zzzz,b),threshold):\n",
    "                exist = True\n",
    "                break\n",
    "    return exist\n",
    "#print(check_edit_distance_thing('shampoo batangan',0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read unlabeled data and tokenize it\n",
    "unlabeled = []\n",
    "with open(\"unlabeled.txt\", encoding='utf-8') as fd:\n",
    "    for line in fd:\n",
    "        sentence = line\n",
    "        tokens = nltk.tokenize.word_tokenize(sentence)\n",
    "        unlabeled.append(tokens)\n",
    "#print(unlabeled[2])\n",
    "#json.dump(unlabeled, open(\"unlabeled_tokenized.txt\",'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read dataTrain and dataTest\n",
    "dataTrain = []\n",
    "with open(\"dataTrain_!O.tsv\", encoding='utf-8') as fd:\n",
    "    rd = csv.reader(fd, delimiter=\"\\t\", quotechar='\"')\n",
    "    sentence = []\n",
    "    for row in rd:\n",
    "        if not row:\n",
    "            dataTrain.append(sentence)\n",
    "            sentence = []\n",
    "        else:\n",
    "            sentence.append(row)\n",
    "\n",
    "dataTest = []\n",
    "with open(\"dataTest_!O.tsv\", encoding='utf-8') as fd:\n",
    "    rd = csv.reader(fd, delimiter=\"\\t\", quotechar='\"')\n",
    "    sentence = []\n",
    "    for row in rd:\n",
    "        if not row:\n",
    "            dataTest.append(sentence)\n",
    "            sentence = []\n",
    "        else:\n",
    "            sentence.append(row)\n",
    "dataTrain = list(filter(None, dataTrain))            \n",
    "dataTest = list(filter(None, dataTest))  \n",
    "#print(dataTrain[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature extraction\n",
    "def word2features(sent, i):\n",
    "    word = sent[i][0]\n",
    "    #postag = sent[i][1]\n",
    "    sentence = ''\n",
    "    for w in sent:\n",
    "        sentence += w[0] + \" \"\n",
    "    features = {\n",
    "        'bias': 1.0,\n",
    "        'word.lower()': word.lower(),\n",
    "        'word[-3:]': word[-3:],\n",
    "        'word[-2:]': word[-2:],\n",
    "        'word.isupper()': word.isupper(),\n",
    "        'word.istitle()': word.istitle(),\n",
    "        'word.isdigit()': word.isdigit(),\n",
    "        #'word.onThingList': check_edit_distance_thing(sentence,i),\n",
    "        'word.indicateList': list_indication(word),\n",
    "        #'word.onCommonList': check_edit_distance_common(word),\n",
    "        #'word.onList': check_edit_distance_brand(sentence,i), #on list brand\n",
    "        #'word.onListAbb': check_edit_distance_brand_abb(word) #on list brand abbreviation\n",
    "        #'postag': postag,\n",
    "        #'postag[:2]': postag[:2],\n",
    "    }\n",
    "    if i > 0:\n",
    "        word1 = sent[i-1][0]\n",
    "        #postag1 = sent[i-1][1]\n",
    "        features.update({\n",
    "            '-1:word.lower()': word1.lower(),\n",
    "            '-1:word.istitle()': word1.istitle(),\n",
    "            '-1:word.isupper()': word1.isupper(),\n",
    "            #'-1:word.onThingList': check_edit_distance_thing(sentence,(i - 1)),\n",
    "            #'-1:word.indicateList': list_indication(word1),\n",
    "            #'-1:word.onCommonList': check_edit_distance_common(word1),\n",
    "            #'-1:onList': check_edit_distance_brand(sentence,(i - 1)),\n",
    "            #'-1:postag': postag1,\n",
    "            #'-1:postag[:2]': postag1[:2],\n",
    "        })\n",
    "    else:\n",
    "        features['BOS'] = True\n",
    "    '''\n",
    "    if i > 1:\n",
    "        word1 = sent[i-2][0]\n",
    "        #postag1 = sent[i-1][1]\n",
    "        features.update({\n",
    "            '-2:word.lower()': word1.lower(),\n",
    "            '-2:word.istitle()': word1.istitle(),\n",
    "            '-2:word.isupper()': word1.isupper(),\n",
    "        })\n",
    "    if i < len(sent)-2:\n",
    "        word1 = sent[i+2][0]\n",
    "        #postag1 = sent[i+1][1]\n",
    "        features.update({\n",
    "            '+2:word.lower()': word1.lower(),\n",
    "            '+2:word.istitle()': word1.istitle(),\n",
    "            '+2:word.isupper()': word1.isupper(),\n",
    "        })\n",
    "    '''\n",
    "    if i < len(sent)-1:\n",
    "        word1 = sent[i+1][0]\n",
    "        #postag1 = sent[i+1][1]\n",
    "        features.update({\n",
    "            '+1:word.lower()': word1.lower(),\n",
    "            '+1:word.istitle()': word1.istitle(),\n",
    "            '+1:word.isupper()': word1.isupper(),\n",
    "            #'+1:word.onThingList': check_edit_distance_thing(sentence,(i + 1)),\n",
    "            #'+1:word.indicateList': list_indication(word1),\n",
    "            #'+1:word.onCommonList': check_edit_distance_common(word1),\n",
    "            #'+1:postag': postag1,\n",
    "            #'+1:postag[:2]': postag1[:2],\n",
    "            #'+1:onList': check_edit_distance_brand(sentence,(i + 1)),\n",
    "        })\n",
    "    else:\n",
    "        features['EOS'] = True\n",
    "\n",
    "    return features\n",
    "\n",
    "\n",
    "def sent2features(sent):\n",
    "    return [word2features(sent, i) for i in range(len(sent))]\n",
    "\n",
    "def sent2labels(sent):\n",
    "    return [label for token, label in sent]\n",
    "\n",
    "def sent2tokens(sent):\n",
    "    return [token for token, label in sent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract features and label from data test and train\n",
    "X_train = [sent2features(s) for s in dataTrain]\n",
    "y_train = [sent2labels(s) for s in dataTrain]\n",
    "\n",
    "X_test = [sent2features(s) for s in dataTest]\n",
    "y_test = [sent2labels(s) for s in dataTest]\n",
    "#print(X_train[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add previous extracted features\n",
    "X_train_read = json.load(open(\"var/2/X_train_!O.txt\"))\n",
    "for i in range(len(X_train)):\n",
    "    for j in range(len(X_train[i])):\n",
    "        X_train[i][j]['word.onList'] = X_train_read[i][j]['word.onList']\n",
    "        X_train[i][j]['word.onListAbb'] = X_train_read[i][j]['word.onListAbb']\n",
    "        X_train[i][j]['word.onThingList'] = X_train_read[i][j]['word.onThingList']\n",
    "        X_train[i][j]['word.onCommonList'] = X_train_read[i][j]['word.onCommonList']\n",
    "X_test_read = json.load(open(\"var/2/X_test_!O.txt\"))\n",
    "for i in range(len(X_test)):\n",
    "    for j in range(len(X_test[i])):\n",
    "        X_test[i][j]['word.onList'] = X_test_read[i][j]['word.onList']\n",
    "        X_test[i][j]['word.onListAbb'] = X_test_read[i][j]['word.onListAbb']\n",
    "        X_test[i][j]['word.onThingList'] = X_test_read[i][j]['word.onThingList']\n",
    "        X_test[i][j]['word.onCommonList'] = X_test_read[i][j]['word.onCommonList']\n",
    "#print(X_train[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load saved feature and label if don't need (or want) to re-extraxt the feature and label\n",
    "X_train = json.load(open(\"var/2/X_train_!O.txt\"))\n",
    "#y_train = json.load(open(\"var/2/y_train_!O_updated.txt\"))\n",
    "y_train = [sent2labels(s) for s in dataTrain]\n",
    "X_test = json.load(open(\"var/2/X_test_!O.txt\"))\n",
    "#y_test = json.load(open(\"var/2/y_test_!O_updated.txt\"))\n",
    "y_test = [sent2labels(s) for s in dataTest]\n",
    "X_unlabeled = json.load(open(\"var/2/X_unlabeled_new.txt\"))\n",
    "unlabeled = json.load(open(\"var/2/unlabeled_tokenized_new.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(X_train)):\n",
    "    for j in range(len(X_train[i])):\n",
    "        X_train[i][j].pop('word.onList')\n",
    "        X_train[i][j].pop('word.onListAbb')\n",
    "for i in range(len(X_test)):\n",
    "    for j in range(len(X_test[i])):\n",
    "        X_test[i][j].pop('word.onList')\n",
    "        X_test[i][j].pop('word.onListAbb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add joint features & neighbour's features\n",
    "for i in range(len(X_train)):\n",
    "    for j in range(len(X_train[i])):\n",
    "        if j > 0:\n",
    "            X_train[i][j]['jointFeatures'] = []\n",
    "            #if X_train[i][j - 1]['word.onThingList'] == True and (X_train[i][j]['word.onList'] == True or X_train[i][j]['word.onListAbb'] == True):\n",
    "            #    X_train[i][j]['jointFeatures'].append('Thing+Brand')\n",
    "            #if X_train[i][j]['word.onThingList'] == True and (X_train[i][j - 1]['word.onList'] == True or X_train[i][j - 1]['word.onListAbb'] == True):\n",
    "            #    X_train[i][j]['jointFeatures'].append('Brand+Thing')\n",
    "            #if X_train[i][j - 1]['word.onCommonList'] == True and (X_train[i][j]['word.onList'] == True or X_train[i][j]['word.onListAbb'] == True):\n",
    "            #    X_train[i][j]['jointFeatures'].append('Common+Brand')\n",
    "            #if X_train[i][j]['word.onCommonList'] == True and (X_train[i][j - 1]['word.onList'] == True or X_train[i][j - 1]['word.onListAbb'] == True):\n",
    "            #    X_train[i][j]['jointFeatures'].append('Brand+Common')\n",
    "            #if X_train[i][j - 1]['word.indicateList'] == True and (X_train[i][j]['word.onList'] == True or X_train[i][j]['word.onListAbb'] == True):\n",
    "            #    X_train[i][j]['jointFeatures'].append('Indication+Brand')\n",
    "            #if X_train[i][j]['word.indicateList'] == True and (X_train[i][j - 1]['word.onList'] == True or X_train[i][j - 1]['word.onListAbb'] == True):\n",
    "            #    X_train[i][j]['jointFeatures'].append('Brand+Indication')\n",
    "            if X_train[i][j - 1]['word.onThingList'] == True and X_train[i][j]['word.indicateList'] == True:\n",
    "                X_train[i][j]['jointFeatures'].append('Thing+Indication')\n",
    "            if X_train[i][j]['word.onThingList'] == True and X_train[i][j - 1]['word.indicateList'] == True:\n",
    "                X_train[i][j]['jointFeatures'].append('Indication+Thing')\n",
    "            if X_train[i][j - 1]['word.onThingList'] == True and X_train[i][j]['word.onCommonList'] == True:\n",
    "                X_train[i][j]['jointFeatures'].append('Thing+Common')\n",
    "            if X_train[i][j]['word.onThingList'] == True and X_train[i][j - 1]['word.onCommonList'] == True:\n",
    "                X_train[i][j]['jointFeatures'].append('Common+Thing')\n",
    "            if X_train[i][j - 1]['word.indicateList'] == True and X_train[i][j]['word.onCommonList'] == True:\n",
    "                X_train[i][j]['jointFeatures'].append('Indication+Common')\n",
    "            if X_train[i][j]['word.indicateList'] == True and X_train[i][j - 1]['word.onCommonList'] == True:\n",
    "                X_train[i][j]['jointFeatures'].append('Common+Indication')\n",
    "            '''\n",
    "            if X_train[i][j - 1]['word.onCommonList'] == True and X_train[i][j]['word.isupper()'] == True:\n",
    "                X_train[i][j]['jointFeatures'].append('Common+Upper')\n",
    "            if X_train[i][j - 1]['word.onCommonList'] == True and X_train[i][j]['word.istitle()'] == True:\n",
    "                X_train[i][j]['jointFeatures'].append('Common+Title')\n",
    "            if X_train[i][j - 1]['word.indicateList'] == True and X_train[i][j]['word.isupper()'] == True:\n",
    "                X_train[i][j]['jointFeatures'].append('Indication+Upper')\n",
    "            if X_train[i][j - 1]['word.indicateList'] == True and X_train[i][j]['word.istitle()'] == True:\n",
    "                X_train[i][j]['jointFeatures'].append('Indication+Title')\n",
    "            if X_train[i][j - 1]['word.isupper()'] == True and (X_train[i][j]['word.onList'] == True or X_train[i][j]['word.onListAbb'] == True):\n",
    "                X_train[i][j]['jointFeatures'].append('Upper+Brand')\n",
    "            if X_train[i][j]['word.isupper()'] == True and (X_train[i][j - 1]['word.onList'] == True or X_train[i][j - 1]['word.onListAbb'] == True):\n",
    "                X_train[i][j]['jointFeatures'].append('Brand+Upper')\n",
    "            if X_train[i][j - 1]['word.istitle()'] == True and (X_train[i][j]['word.onList'] == True or X_train[i][j]['word.onListAbb'] == True):\n",
    "                X_train[i][j]['jointFeatures'].append('Title+Brand')\n",
    "            if X_train[i][j]['word.istitle()'] == True and (X_train[i][j - 1]['word.onList'] == True or X_train[i][j - 1]['word.onListAbb'] == True):\n",
    "                X_train[i][j]['jointFeatures'].append('Brand+Title')\n",
    "            if X_train[i][j - 1]['word.isupper()'] == True and X_train[i][j]['word.onThingList'] == True:\n",
    "                X_train[i][j]['jointFeatures'].append('Upper+Thing')\n",
    "            if X_train[i][j]['word.isupper()'] == True and X_train[i][j - 1]['word.onThingList'] == True:\n",
    "                X_train[i][j]['jointFeatures'].append('Thing+Upper')\n",
    "            if X_train[i][j - 1]['word.istitle()'] == True and X_train[i][j]['word.onThingList'] == True:\n",
    "                X_train[i][j]['jointFeatures'].append('Title+Thing')\n",
    "            if X_train[i][j]['word.istitle()'] == True and X_train[i][j - 1]['word.onThingList'] == True:\n",
    "                X_train[i][j]['jointFeatures'].append('Thing+Title')\n",
    "            '''\n",
    "        if j >= 0:\n",
    "            if j < (len(X_train[i]) - 1):\n",
    "                #if (X_train[i][j + 1]['word.onList'] == True or X_train[i][j + 1]['word.onListAbb'] == True):\n",
    "                #    X_train[i][j]['+1:neigbourFeatures'] = 'Brand'\n",
    "                if X_train[i][j + 1]['word.onThingList'] == True:\n",
    "                    X_train[i][j]['+1:neigbourFeatures'] = 'Thing'\n",
    "                elif X_train[i][j + 1]['word.indicateList'] == True:\n",
    "                    X_train[i][j]['+1:neigbourFeatures'] = 'Indicate'\n",
    "                elif X_train[i][j + 1]['word.onCommonList'] == True:\n",
    "                    X_train[i][j]['+1:neigbourFeatures'] = 'Common'\n",
    "            if j < (len(X_train[i]) - 2):\n",
    "                #if (X_train[i][j + 2]['word.onList'] == True or X_train[i][j + 2]['word.onListAbb'] == True):\n",
    "                #    X_train[i][j]['+2:neigbourFeatures'] = 'Brand'\n",
    "                if X_train[i][j + 2]['word.onThingList'] == True:\n",
    "                    X_train[i][j]['+2:neigbourFeatures'] = 'Thing'\n",
    "                elif X_train[i][j + 2]['word.indicateList'] == True:\n",
    "                    X_train[i][j]['+2:neigbourFeatures'] = 'Indicate'\n",
    "                elif X_train[i][j + 2]['word.onCommonList'] == True:\n",
    "                    X_train[i][j]['+2:neigbourFeatures'] = 'Common'\n",
    "        if (j - 1) >= 0:\n",
    "            #if (X_train[i][j - 1]['word.onList'] == True or X_train[i][j - 1]['word.onListAbb'] == True):\n",
    "            #    X_train[i][j]['-1:neigbourFeatures'] = 'Brand'\n",
    "            if X_train[i][j - 1]['word.onThingList'] == True:\n",
    "                X_train[i][j]['-1:neigbourFeatures'] = 'Thing'\n",
    "            elif X_train[i][j - 1]['word.indicateList'] == True:\n",
    "                X_train[i][j]['-1:neigbourFeatures'] = 'Indicate'\n",
    "            elif X_train[i][j - 1]['word.onCommonList'] == True:\n",
    "                X_train[i][j]['-1:neigbourFeatures'] = 'Common'\n",
    "        if (j - 2) >= 0:\n",
    "            #if (X_train[i][j - 2]['word.onList'] == True or X_train[i][j - 2]['word.onListAbb'] == True):\n",
    "            #    X_train[i][j]['-2:neigbourFeatures'] = 'Brand'\n",
    "            if X_train[i][j - 2]['word.onThingList'] == True:\n",
    "                X_train[i][j]['-2:neigbourFeatures'] = 'Thing'\n",
    "            elif X_train[i][j - 2]['word.indicateList'] == True:\n",
    "                X_train[i][j]['-2:neigbourFeatures'] = 'Indicate'\n",
    "            elif X_train[i][j - 2]['word.onCommonList'] == True:\n",
    "                X_train[i][j]['-2:neigbourFeatures'] = 'Common'\n",
    "for i in range(len(X_test)):\n",
    "    for j in range(len(X_test[i])):        \n",
    "        if j > 0:\n",
    "            X_test[i][j]['jointFeatures'] = []\n",
    "            #if X_test[i][j - 1]['word.onThingList'] == True and (X_test[i][j]['word.onList'] == True or X_test[i][j]['word.onListAbb'] == True):\n",
    "            #    X_test[i][j]['jointFeatures'].append('Thing+Brand')\n",
    "            #if X_test[i][j]['word.onThingList'] == True and (X_test[i][j - 1]['word.onList'] == True or X_test[i][j - 1]['word.onListAbb'] == True):\n",
    "            #    X_test[i][j]['jointFeatures'].append('Brand+Thing')\n",
    "            #if X_test[i][j - 1]['word.onCommonList'] == True and (X_test[i][j]['word.onList'] == True or X_test[i][j]['word.onListAbb'] == True):\n",
    "            #    X_test[i][j]['jointFeatures'].append('Common+Brand')\n",
    "            #if X_test[i][j]['word.onCommonList'] == True and (X_test[i][j - 1]['word.onList'] == True or X_test[i][j - 1]['word.onListAbb'] == True):\n",
    "            #    X_test[i][j]['jointFeatures'].append('Brand+Common')\n",
    "            #if X_test[i][j - 1]['word.indicateList'] == True and (X_test[i][j]['word.onList'] == True or X_test[i][j]['word.onListAbb'] == True):\n",
    "            #    X_test[i][j]['jointFeatures'].append('Indication+Brand')\n",
    "            #if X_test[i][j]['word.indicateList'] == True and (X_test[i][j - 1]['word.onList'] == True or X_test[i][j - 1]['word.onListAbb'] == True):\n",
    "            #    X_test[i][j]['jointFeatures'].append('Brand+Indication')\n",
    "            if X_test[i][j - 1]['word.onThingList'] == True and X_test[i][j]['word.indicateList'] == True:\n",
    "                X_test[i][j]['jointFeatures'].append('Thing+Indication')\n",
    "            if X_test[i][j]['word.onThingList'] == True and X_test[i][j - 1]['word.indicateList'] == True:\n",
    "                X_test[i][j]['jointFeatures'].append('Indication+Thing')\n",
    "            if X_test[i][j - 1]['word.onThingList'] == True and X_test[i][j]['word.onCommonList'] == True:\n",
    "                X_test[i][j]['jointFeatures'].append('Thing+Common')\n",
    "            if X_test[i][j]['word.onThingList'] == True and X_test[i][j - 1]['word.onCommonList'] == True:\n",
    "                X_test[i][j]['jointFeatures'].append('Common+Thing')\n",
    "            if X_test[i][j - 1]['word.indicateList'] == True and X_test[i][j]['word.onCommonList'] == True:\n",
    "                X_test[i][j]['jointFeatures'].append('Indication+Common')\n",
    "            if X_test[i][j]['word.indicateList'] == True and X_test[i][j - 1]['word.onCommonList'] == True:\n",
    "                X_test[i][j]['jointFeatures'].append('Common+Indication')    \n",
    "            '''\n",
    "            if X_test[i][j - 1]['word.onCommonList'] == True and X_test[i][j]['word.isupper()'] == True:\n",
    "                X_test[i][j]['jointFeatures'].append('Common+Upper')\n",
    "            if X_test[i][j - 1]['word.onCommonList'] == True and X_test[i][j]['word.istitle()'] == True:\n",
    "                X_test[i][j]['jointFeatures'].append('Common+Title')\n",
    "            if X_test[i][j - 1]['word.indicateList'] == True and X_test[i][j]['word.isupper()'] == True:\n",
    "                X_test[i][j]['jointFeatures'].append('Indication+Upper')\n",
    "            if X_test[i][j - 1]['word.indicateList'] == True and X_test[i][j]['word.istitle()'] == True:\n",
    "                X_test[i][j]['jointFeatures'].append('Indication+Title')\n",
    "            if X_test[i][j - 1]['word.isupper()'] == True and (X_test[i][j]['word.onList'] == True or X_test[i][j]['word.onListAbb'] == True):\n",
    "                X_test[i][j]['jointFeatures'].append('Upper+Brand')\n",
    "            if X_test[i][j]['word.isupper()'] == True and (X_test[i][j - 1]['word.onList'] == True or X_test[i][j - 1]['word.onListAbb'] == True):\n",
    "                X_test[i][j]['jointFeatures'].append('Brand+Upper')\n",
    "            if X_test[i][j - 1]['word.istitle()'] == True and (X_test[i][j]['word.onList'] == True or X_test[i][j]['word.onListAbb'] == True):\n",
    "                X_test[i][j]['jointFeatures'].append('Title+Brand')\n",
    "            if X_test[i][j]['word.istitle()'] == True and (X_test[i][j - 1]['word.onList'] == True or X_test[i][j - 1]['word.onListAbb'] == True):\n",
    "                X_test[i][j]['jointFeatures'].append('Brand+Title')\n",
    "            if X_test[i][j - 1]['word.isupper()'] == True and X_test[i][j]['word.onThingList'] == True:\n",
    "                X_test[i][j]['jointFeatures'].append('Upper+Thing')\n",
    "            if X_test[i][j]['word.isupper()'] == True and X_test[i][j - 1]['word.onThingList'] == True:\n",
    "                X_test[i][j]['jointFeatures'].append('Thing+Upper')\n",
    "            if X_test[i][j - 1]['word.istitle()'] == True and X_test[i][j]['word.onThingList'] == True:\n",
    "                X_test[i][j]['jointFeatures'].append('Title+Thing')\n",
    "            if X_test[i][j]['word.istitle()'] == True and X_test[i][j - 1]['word.onThingList'] == True:\n",
    "                X_test[i][j]['jointFeatures'].append('Thing+Title')\n",
    "            '''\n",
    "        if j >= 0:\n",
    "            if j < (len(X_test[i]) - 1):\n",
    "                #if (X_test[i][j + 1]['word.onList'] == True or X_test[i][j + 1]['word.onListAbb'] == True):\n",
    "                #    X_test[i][j]['+1:neigbourFeatures'] = 'Brand'\n",
    "                if X_test[i][j + 1]['word.onThingList'] == True:\n",
    "                    X_test[i][j]['+1:neigbourFeatures'] = 'Thing'\n",
    "                elif X_test[i][j + 1]['word.indicateList'] == True:\n",
    "                    X_test[i][j]['+1:neigbourFeatures'] = 'Indicate'\n",
    "                elif X_test[i][j + 1]['word.onCommonList'] == True:\n",
    "                    X_test[i][j]['+1:neigbourFeatures'] = 'Common'\n",
    "            if j < (len(X_test[i]) - 2):\n",
    "                #if (X_test[i][j + 2]['word.onList'] == True or X_test[i][j + 2]['word.onListAbb'] == True):\n",
    "                #    X_test[i][j]['+2:neigbourFeatures'] = 'Brand'\n",
    "                if X_test[i][j + 2]['word.onThingList'] == True:\n",
    "                    X_test[i][j]['+2:neigbourFeatures'] = 'Thing'\n",
    "                elif X_test[i][j + 2]['word.indicateList'] == True:\n",
    "                    X_test[i][j]['+2:neigbourFeatures'] = 'Indicate'\n",
    "                elif X_test[i][j + 2]['word.onCommonList'] == True:\n",
    "                    X_test[i][j]['+2:neigbourFeatures'] = 'Common'\n",
    "        if (j - 1) >= 0:\n",
    "            #if (X_test[i][j - 1]['word.onList'] == True or X_test[i][j - 1]['word.onListAbb'] == True):\n",
    "            #    X_test[i][j]['-1:neigbourFeatures'] = 'Brand'\n",
    "            if X_test[i][j - 1]['word.onThingList'] == True:\n",
    "                X_test[i][j]['-1:neigbourFeatures'] = 'Thing'\n",
    "            elif X_test[i][j - 1]['word.indicateList'] == True:\n",
    "                X_test[i][j]['-1:neigbourFeatures'] = 'Indicate'\n",
    "            elif X_test[i][j - 1]['word.onCommonList'] == True:\n",
    "                X_test[i][j]['-1:neigbourFeatures'] = 'Common'\n",
    "                \n",
    "        if (j - 2) >= 0:\n",
    "            #if (X_test[i][j - 2]['word.onList'] == True or X_test[i][j - 2]['word.onListAbb'] == True):\n",
    "            #    X_test[i][j]['-2:neigbourFeatures'] = 'Brand'\n",
    "            if X_test[i][j - 2]['word.onThingList'] == True:\n",
    "                X_test[i][j]['-2:neigbourFeatures'] = 'Thing'\n",
    "            elif X_test[i][j - 2]['word.indicateList'] == True:\n",
    "                X_test[i][j]['-2:neigbourFeatures'] = 'Indicate'\n",
    "            elif X_test[i][j - 2]['word.onCommonList'] == True:\n",
    "                X_test[i][j]['-2:neigbourFeatures'] = 'Common'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract features from unlabeled data\n",
    "X_unlabeled = [sent2features(s) for s in unlabeled]\n",
    "json.dump(X_unlabeled, open(\"X_unlabeled.txt\",'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract newly added features\n",
    "#read & extract from og (original from first experiment, cuz the extracted features are from there too) file\n",
    "#unlabeled = json.load(open(\"unlabeled_tokenized_og.txt\"))\n",
    "#X_unlabeled = [sent2features(s) for s in unlabeled]\n",
    "#re-add the brand list feature\n",
    "'''\n",
    "unlabeled = json.load(open(\"var/1/unlabeled_tokenized.txt\"))\n",
    "X_unlabeled = [sent2features(s) for s in unlabeled]\n",
    "X_unlabeled_read = json.load(open(\"var/1/X_unlabeled.txt\"))\n",
    "for i in range(len(X_unlabeled)):\n",
    "    for j in range(len(X_unlabeled[i])):\n",
    "        X_unlabeled[i][j]['word.onList'] = X_unlabeled_read[i][j]['word.onList']\n",
    "        X_unlabeled[i][j]['word.onListAbb'] = X_unlabeled_read[i][j]['word.onListAbb']\n",
    "        X_unlabeled[i][j]['word.onThingList'] = X_unlabeled_read[i][j]['word.onThingList']\n",
    "        X_unlabeled[i][j]['word.onCommonList'] = X_unlabeled_read[i][j]['word.onCommonList']\n",
    "'''\n",
    "#add joint features & neighbour's features\n",
    "for i in range(len(X_unlabeled)):\n",
    "    for j in range(len(X_unlabeled[i])):\n",
    "        if j > 0:\n",
    "            X_unlabeled[i][j]['jointFeatures'] = []\n",
    "            if X_unlabeled[i][j - 1]['word.onThingList'] == True and (X_unlabeled[i][j]['word.onList'] == True or X_unlabeled[i][j]['word.onListAbb'] == True):\n",
    "                X_unlabeled[i][j]['jointFeatures'].append('Thing+Brand')\n",
    "            if X_unlabeled[i][j]['word.onThingList'] == True and (X_unlabeled[i][j - 1]['word.onList'] == True or X_unlabeled[i][j - 1]['word.onListAbb'] == True):\n",
    "                X_unlabeled[i][j]['jointFeatures'].append('Brand+Thing')\n",
    "            if X_unlabeled[i][j - 1]['word.onCommonList'] == True and (X_unlabeled[i][j]['word.onList'] == True or X_unlabeled[i][j]['word.onListAbb'] == True):\n",
    "                X_unlabeled[i][j]['jointFeatures'].append('Common+Brand')\n",
    "            if X_unlabeled[i][j]['word.onCommonList'] == True and (X_unlabeled[i][j - 1]['word.onList'] == True or X_unlabeled[i][j - 1]['word.onListAbb'] == True):\n",
    "                X_unlabeled[i][j]['jointFeatures'].append('Brand+Common')\n",
    "            if X_unlabeled[i][j - 1]['word.indicateList'] == True and (X_unlabeled[i][j]['word.onList'] == True or X_unlabeled[i][j]['word.onListAbb'] == True):\n",
    "                X_unlabeled[i][j]['jointFeatures'].append('Indication+Brand')\n",
    "            if X_unlabeled[i][j]['word.indicateList'] == True and (X_unlabeled[i][j - 1]['word.onList'] == True or X_unlabeled[i][j - 1]['word.onListAbb'] == True):\n",
    "                X_unlabeled[i][j]['jointFeatures'].append('Brand+Indication')\n",
    "            if X_unlabeled[i][j - 1]['word.onThingList'] == True and X_unlabeled[i][j]['word.indicateList'] == True:\n",
    "                X_unlabeled[i][j]['jointFeatures'].append('Thing+Indication')\n",
    "            if X_unlabeled[i][j]['word.onThingList'] == True and X_unlabeled[i][j - 1]['word.indicateList'] == True:\n",
    "                X_unlabeled[i][j]['jointFeatures'].append('Indication+Thing')\n",
    "            if X_unlabeled[i][j - 1]['word.onThingList'] == True and X_unlabeled[i][j]['word.onCommonList'] == True:\n",
    "                X_unlabeled[i][j]['jointFeatures'].append('Thing+Common')\n",
    "            if X_unlabeled[i][j]['word.onThingList'] == True and X_unlabeled[i][j - 1]['word.onCommonList'] == True:\n",
    "                X_unlabeled[i][j]['jointFeatures'].append('Common+Thing')\n",
    "            if X_unlabeled[i][j - 1]['word.indicateList'] == True and X_unlabeled[i][j]['word.onCommonList'] == True:\n",
    "                X_unlabeled[i][j]['jointFeatures'].append('Indication+Common')\n",
    "            if X_unlabeled[i][j]['word.indicateList'] == True and X_unlabeled[i][j - 1]['word.onCommonList'] == True:\n",
    "                X_unlabeled[i][j]['jointFeatures'].append('Common+Indication')    \n",
    "        if j >= 0:\n",
    "            if j < (len(X_unlabeled[i]) - 1):\n",
    "                if (X_unlabeled[i][j + 1]['word.onList'] == True or X_unlabeled[i][j + 1]['word.onListAbb'] == True):\n",
    "                    X_unlabeled[i][j]['+1:neigbourFeatures'] = 'Brand'\n",
    "                elif X_unlabeled[i][j + 1]['word.onThingList'] == True:\n",
    "                    X_unlabeled[i][j]['+1:neigbourFeatures'] = 'Thing'\n",
    "                elif X_unlabeled[i][j + 1]['word.indicateList'] == True:\n",
    "                    X_unlabeled[i][j]['+1:neigbourFeatures'] = 'Indicate'\n",
    "                elif X_unlabeled[i][j + 1]['word.onCommonList'] == True:\n",
    "                    X_unlabeled[i][j]['+1:neigbourFeatures'] = 'Common'\n",
    "            if j < (len(X_unlabeled[i]) - 2):\n",
    "                if (X_unlabeled[i][j + 2]['word.onList'] == True or X_unlabeled[i][j + 2]['word.onListAbb'] == True):\n",
    "                    X_unlabeled[i][j]['+2:neigbourFeatures'] = 'Brand'\n",
    "                elif X_unlabeled[i][j + 2]['word.onThingList'] == True:\n",
    "                    X_unlabeled[i][j]['+2:neigbourFeatures'] = 'Thing'\n",
    "                elif X_unlabeled[i][j + 2]['word.indicateList'] == True:\n",
    "                    X_unlabeled[i][j]['+2:neigbourFeatures'] = 'Indicate'\n",
    "                elif X_unlabeled[i][j + 2]['word.onCommonList'] == True:\n",
    "                    X_unlabeled[i][j]['+2:neigbourFeatures'] = 'Common'\n",
    "        if (j - 1) >= 0:\n",
    "            if (X_unlabeled[i][j - 1]['word.onList'] == True or X_unlabeled[i][j - 1]['word.onListAbb'] == True):\n",
    "                X_unlabeled[i][j]['-1:neigbourFeatures'] = 'Brand'\n",
    "            elif X_unlabeled[i][j - 1]['word.onThingList'] == True:\n",
    "                X_unlabeled[i][j]['-1:neigbourFeatures'] = 'Thing'\n",
    "            elif X_unlabeled[i][j - 1]['word.indicateList'] == True:\n",
    "                X_unlabeled[i][j]['-1:neigbourFeatures'] = 'Indicate'\n",
    "            elif X_unlabeled[i][j - 1]['word.onCommonList'] == True:\n",
    "                X_unlabeled[i][j]['-1:neigbourFeatures'] = 'Common'\n",
    "                \n",
    "        if (j - 2) >= 0:\n",
    "            if (X_unlabeled[i][j - 2]['word.onList'] == True or X_unlabeled[i][j - 2]['word.onListAbb'] == True):\n",
    "                X_unlabeled[i][j]['-2:neigbourFeatures'] = 'Brand'\n",
    "            elif X_unlabeled[i][j - 2]['word.onThingList'] == True:\n",
    "                X_unlabeled[i][j]['-2:neigbourFeatures'] = 'Thing'\n",
    "            elif X_unlabeled[i][j - 2]['word.indicateList'] == True:\n",
    "                X_unlabeled[i][j]['-2:neigbourFeatures'] = 'Indicate'\n",
    "            elif X_unlabeled[i][j - 2]['word.onCommonList'] == True:\n",
    "                X_unlabeled[i][j]['-2:neigbourFeatures'] = 'Common'\n",
    "#json.dump(X_unlabeled, open(\"X_unlabeled.txt\",'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save extracted feature and label to a file to avoid re-extracting the same thing\n",
    "#json.dump(X_train, open(\"X_train.txt\",'w'))\n",
    "#json.dump(y_train, open(\"y_train.txt\",'w'))\n",
    "#json.dump(X_test, open(\"X_test.txt\",'w'))\n",
    "#json.dump(y_test, open(\"y_test.txt\",'w'))\n",
    "json.dump(X_unlabeled, open(\"X_unlabeled_new.txt\",'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#find optimum param for training\n",
    "crf = sklearn_crfsuite.CRF(\n",
    "    algorithm='lbfgs',\n",
    "    max_iterations=100,\n",
    "    all_possible_transitions=True\n",
    ")\n",
    "params_space = {\n",
    "    'c1': scipy.stats.expon(scale=0.5),\n",
    "    'c2': scipy.stats.expon(scale=0.05),\n",
    "}\n",
    "\n",
    "# use the same metric for evaluation\n",
    "f1_scorer = make_scorer(metrics.flat_f1_score,\n",
    "                        average='weighted', labels=labels)\n",
    "\n",
    "# search\n",
    "rs = RandomizedSearchCV(crf, params_space,\n",
    "                        cv=3,\n",
    "                        verbose=1,\n",
    "                        n_jobs=-1,\n",
    "                        n_iter=50,\n",
    "                        scoring=f1_scorer)\n",
    "rs.fit(X_train, y_train)\n",
    "print('best params:', rs.best_params_)\n",
    "print('best CV score:', rs.best_score_)\n",
    "#print('model size: {:0.2f}M'.format(rs.best_estimator_.size_ / 1000000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CRF(algorithm='lbfgs', all_possible_states=None, all_possible_transitions=True,\n",
       "    averaging=None, c=None, c1=0.1, c2=0.1, calibration_candidates=None,\n",
       "    calibration_eta=None, calibration_max_trials=None, calibration_rate=None,\n",
       "    calibration_samples=None, delta=None, epsilon=None, error_sensitive=None,\n",
       "    gamma=None, keep_tempfiles=None, linesearch=None, max_iterations=100,\n",
       "    max_linesearch=None, min_freq=None, model_filename=None, num_memories=None,\n",
       "    pa_type=None, period=None, trainer_cls=None, variance=None, verbose=False)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create crf object and train it with data train\n",
    "crf = sklearn_crfsuite.CRF(\n",
    "    algorithm='lbfgs',\n",
    "    c1=0.1,#0.23816962106578055,#0.1\n",
    "    c2=0.1,#0.0104234047496269,#0.1\n",
    "    max_iterations=100,\n",
    "    all_possible_transitions=True\n",
    ")\n",
    "crf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#per label evaluation\n",
    "y_pred = crf.predict(X_test)\n",
    "labels = list(crf.classes_)\n",
    "labels.remove('O') # remove 'O' label from evaluation\n",
    "sorted_labels = sorted(labels,key=lambda name: (name[1:], name[0])) # group B and I results\n",
    "print(flat_classification_report(y_test, y_pred, labels=sorted_labels, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top positive:\n",
      "5.445782 O        BOS\n",
      "5.128899 B-PRO|B-BRA BOS\n",
      "4.200890 B-PRO    BOS\n",
      "4.008197 B-BRA    BOS\n",
      "3.689991 B-PRO|B-TYP BOS\n",
      "3.592484 B-PRO    word.lower():udpp\n",
      "3.527133 O        word.lower():nude\n",
      "3.485149 B-PRO    word.lower():lipbalmnya\n",
      "3.485149 B-PRO    -1:word.lower():thebathbox\n",
      "3.398500 B-BRA    word.lower():nizoral\n",
      "3.212500 O        word.lower():itu\n",
      "3.206125 I-PRO|B-TYP -1:word.lower():loreal\n",
      "3.136639 I-PRO|B-BRA -1:word.lower():nya\n",
      "2.986771 B-PRO    word.onThingList\n",
      "2.951717 O        word[-2:]:ah\n",
      "2.853221 B-TYP    word.lower():regenerist\n",
      "2.842527 B-BRA    word.lower():etude\n",
      "2.791501 I-PRO|I-BRA -1:word.lower():la\n",
      "2.790271 B-BRA    word.onListAbb\n",
      "2.787301 I-PRO|B-BRA word.onListAbb\n",
      "2.756773 O        word.lower():sample\n",
      "2.747935 I-PRO    word.lower():nya\n",
      "2.747802 B-BRA    word.lower():phytomer\n",
      "2.743901 B-TYP    word.lower():anr\n",
      "2.695201 B-BRA    word.lower():bodyshop\n",
      "2.683184 O        word[-2:]:ga\n",
      "2.676737 I-PRO|B-BRA word.onList\n",
      "2.667544 O        word.lower():nya\n",
      "2.660852 B-PRO    word.lower():eldw\n",
      "2.621708 I-PRO    -1:word.lower():outlaw\n",
      "2.585922 B-TYP    word.lower():twc-nya\n",
      "2.571555 I-PRO|B-TYP -1:word.lower():-\n",
      "2.568436 O        word.onCommonList\n",
      "2.565919 O        -1:word.lower():counter\n",
      "2.538968 O        word.lower():something\n",
      "2.531788 I-PRO    word.lower():whitening\n",
      "2.531442 I-PRO|I-BRA -1:word.lower():n\n",
      "2.529225 B-BRA    word.lower():jodie\n",
      "2.527978 I-PRO|I-BRA -1:word.lower():paul\n",
      "2.509676 B-BRA    -1:word.lower():milani\n",
      "2.504226 B-BRA    word[-3:]:***\n",
      "2.504226 B-BRA    word[-2:]:**\n",
      "2.495660 I-PRO|B-BRA word[-3:]:eal\n",
      "2.493474 O        word.lower():link\n",
      "2.492187 B-PRO|B-BRA word[-3:]:eal\n",
      "2.488670 I-PRO|B-TYP +1:word.lower():colorshow\n",
      "2.482382 I-PRO|B-TYP -1:word.lower():l'oreal\n",
      "2.478072 I-PRO|B-TYP -1:word.lower():nars\n",
      "2.471477 B-TYP    BOS\n",
      "2.463449 I-PRO|B-TYP -1:word.lower():wnw\n",
      "2.456122 I-BRA    -1:word.lower():idéalia\n",
      "2.450767 B-PRO|B-BRA word.lower():j&j\n",
      "2.448519 B-PRO    word[-2:]:po\n",
      "2.441853 I-PRO    word.onThingList\n",
      "2.420791 O        word.lower():.\n",
      "2.420791 O        word[-3:]:.\n",
      "2.420791 O        word[-2:]:.\n",
      "2.415075 I-PRO|B-TYP -1:word.lower():mufe\n",
      "2.405208 O        EOS\n",
      "2.400183 B-BRA    word[-2:]:mc\n",
      "2.383804 O        word[-2:]:uh\n",
      "2.379883 B-BRA    word.lower():psalnya\n",
      "2.372828 I-PRO|B-TYP -1:word.lower():ecotools\n",
      "2.360521 I-PRO|I-TYP -1:word.lower():foam\n",
      "2.359902 B-BRA    +1:word.lower():punya\n",
      "2.357107 I-PRO|B-TYP -1:word.lower():in\n",
      "2.328823 I-PRO|I-BRA -1:word.lower():my\n",
      "2.315115 B-BRA    word.lower():kellynya\n",
      "2.314217 I-PRO|I-BRA -1:word.lower():the\n",
      "2.297136 I-PRO|I-TYP -1:word.lower():foaming\n",
      "2.296557 B-BRA    word.onList\n",
      "2.296283 B-BRA    word.lower():babyliss-nya\n",
      "2.295249 I-PRO    word.lower():clay\n",
      "2.290904 I-BRA    word.onList\n",
      "2.289816 O        word.lower():bikin\n",
      "2.283561 B-PRO    +1:word.lower():1\n",
      "2.281785 I-PRO|B-TYP -1:word.lower():fo\n",
      "2.275691 O        word.lower():ada\n",
      "2.272233 B-BRA    word.lower():addiction\n",
      "2.270041 O        bias\n",
      "2.262180 I-PRO|B-TYP word.lower():georgia-nya\n",
      "2.257387 B-TYP    word.lower():fte\n",
      "2.250319 I-PRO|B-TYP -1:word.lower():beras\n",
      "2.246865 O        word.lower()::\n",
      "2.246865 O        word[-3:]::\n",
      "2.246865 O        word[-2:]::\n",
      "2.235420 B-BRA    word.lower():amira..\n",
      "2.232360 O        -1:word.lower():jelly\n",
      "2.232188 B-BRA    word.lower():obagi\n",
      "2.230995 B-BRA    word.lower():phyto\n",
      "2.230995 B-BRA    word[-3:]:yto\n",
      "2.225418 B-PRO    word[-3:]:DPP\n",
      "2.224982 B-BRA    word.lower():berapaan\n",
      "2.224506 I-PRO|I-BRA +1:word.lower():-\n",
      "2.223503 B-TYP    word.lower():nectar\n",
      "2.222049 B-PRO    word[-2:]:PP\n",
      "2.213304 B-BRA    word[-3:]:ysl\n",
      "2.210419 I-PRO    -1:word.lower():seaweed\n",
      "2.207063 I-PRO|I-BRA word.lower():clearnya\n",
      "2.202511 O        word.lower():(\n",
      "2.202511 O        word[-3:]:(\n",
      "2.202511 O        word[-2:]:(\n",
      "2.201519 O        word.lower():,\n",
      "2.201519 O        word[-3:]:,\n",
      "2.201519 O        word[-2:]:,\n",
      "2.193193 I-PRO|I-BRA -1:word.lower():body\n",
      "2.192117 I-PRO|B-TYP -1:word.lower():ud\n",
      "2.190648 I-PRO|B-TYP -1:word.lower():yg\n",
      "2.189501 B-BRA    word[-3:]:eal\n",
      "2.185623 B-BRA    word[-2:]:sl\n",
      "2.181374 I-PRO    +1:word.lower():minutes\n",
      "2.174572 B-PRO    +1:word.lower():crem\n",
      "2.158787 O        word.lower():/\n",
      "2.158787 O        word[-3:]:/\n",
      "2.158787 O        word[-2:]:/\n",
      "2.153713 O        jointFeatures:Common+Thing\n",
      "2.150053 I-PRO|B-BRA +1:word.lower():bisa\n",
      "2.143480 I-PRO    word.lower():primer\n",
      "2.141362 I-PRO|B-TYP +1:word.lower():benefit\n",
      "2.139664 B-TYP    word.lower():microdermaabasi\n",
      "2.136000 I-PRO|B-BRA word.lower():loreal\n",
      "2.133623 I-PRO|B-TYP -1:word.lower():yang\n",
      "2.121443 B-BRA    word.lower():tbsku\n",
      "2.121443 B-BRA    word[-3:]:Sku\n",
      "2.107804 I-PRO    -1:word.lower():dipbrow\n",
      "2.104353 I-PRO    word.lower():mist\n",
      "2.100714 O        +1:word.lower():kali2\n",
      "2.100581 I-PRO|B-BRA -1:word.lower():dari\n",
      "2.089315 B-BRA    word.lower():prettia\n",
      "2.089094 B-PRO    -1:word.lower():deh\n",
      "2.086385 I-PRO|I-BRA -1:word.lower():clean\n",
      "2.085566 O        word.lower():-\n",
      "2.085566 O        word[-3:]:-\n",
      "2.085566 O        word[-2:]:-\n",
      "2.081366 B-TYP    word.lower():glossimer\n",
      "2.077131 O        word[-3:]:rus\n",
      "2.077122 I-PRO    +1:word.lower():bar\n",
      "2.075274 B-TYP    -1:word.lower():varian\n",
      "2.071923 O        word[-2:]:eh\n",
      "2.070787 I-PRO    -1:word.lower():pureness\n",
      "2.069895 B-PRO|B-BRA word.onList\n",
      "2.057504 O        -1:word.lower():fuchsia\n",
      "2.057269 I-PRO|B-TYP -1:word.lower():mitu\n",
      "2.049427 I-PRO|B-TYP -1:word.lower():decay\n",
      "2.047441 O        word.lower():irrésistible\n",
      "2.044854 B-PRO|B-BRA word.lower():etude\n",
      "2.042960 B-TYP    word.lower():diorstar\n",
      "2.041860 B-BRA    word[-3:]:ura\n",
      "2.041006 B-BRA    word.lower():kojiesan\n",
      "2.040882 B-TYP    word.lower():dipbrownya\n",
      "2.036331 B-BRA    word.lower():garniers\n",
      "2.031777 I-PRO|B-BRA -1:word.lower():by\n",
      "2.025317 O        word.lower():...\n",
      "2.025317 O        word[-3:]:...\n",
      "2.025038 B-PRO    +1:word.lower():powdernya\n",
      "2.019506 O        word.lower():ini\n",
      "2.016863 O        word[-3:]:ini\n",
      "2.014529 I-BRA    -1:word.lower():for\n",
      "2.013481 B-PRO|B-TYP +1:word.lower():defense\n",
      "2.013474 B-BRA    word.lower():mitu-mitu\n",
      "2.012295 I-PRO    -1:word.lower():pc\n",
      "2.007200 O        word.lower():paling\n",
      "2.006838 O        +1:word.lower():$\n",
      "2.005191 B-PRO|B-BRA word.lower():mitu\n",
      "2.002751 I-PRO    word[-3:]:ade\n",
      "2.001216 B-PRO    -1:word.lower():dari\n",
      "2.001126 B-BRA    +1:word.lower():hrg\n",
      "2.000296 B-BRA    +1:word.lower():ada\n",
      "1.999581 B-BRA    word.lower():oilatum\n",
      "1.999581 B-BRA    -1:word.lower():40rb\n",
      "1.998144 B-PRO    word[-3:]:mpo\n",
      "1.995720 O        word[-3:]:ara\n",
      "1.991452 I-PRO|B-TYP -1:word.lower():varian\n",
      "1.990980 B-TYP    word.lower():serioxyl\n",
      "1.990980 B-TYP    word[-3:]:xyl\n",
      "1.984218 I-BRA    -1:word.lower():la\n",
      "1.980617 B-TYP    word.lower():femme\n",
      "1.979687 B-BRA    word[-3:]:tum\n",
      "1.975258 I-PRO|B-TYP -1:word.lower():kose\n",
      "1.969215 B-BRA    EOS\n",
      "1.965323 I-PRO|I-TYP +1:word.lower():loreal\n",
      "1.963866 I-PRO|I-BRA -1:word.lower():snail\n",
      "1.960835 B-TYP    +1:word.lower():adanya\n",
      "1.957426 O        word.lower():punya\n",
      "1.955617 B-PRO|B-BRA +1:word.lower():yang\n",
      "1.953809 O        word[-2:]:ih\n",
      "1.952921 B-BRA    word.lower():estee\n",
      "1.952921 B-BRA    word[-3:]:tee\n",
      "1.952137 O        word[-2:]:ke\n",
      "1.949514 O        word.lower():..\n",
      "1.949514 O        word[-3:]:..\n",
      "1.939836 I-BRA    -1:word.lower():paul\n",
      "1.936947 O        word[-3:]:h..\n",
      "1.936491 I-PRO    word.lower():matte\n",
      "1.929971 O        word.lower():pre-essence\n",
      "1.928194 B-BRA    -1:word.lower():lah\n",
      "1.926781 B-BRA    word.lower():tarte\n",
      "1.925536 I-PRO    word.lower():spf\n",
      "1.925277 I-PRO|I-TYP +1:word.lower():estee\n",
      "1.922773 I-PRO    -1:word.lower():wardah\n",
      "1.921897 O        word[-2:]:uk\n",
      "1.919632 B-BRA    word.lower():natur\n",
      "1.918497 I-PRO    word.lower():foundation\n",
      "1.918302 O        word.lower():lagi\n",
      "1.916475 I-PRO|I-TYP +1:word.lower()::\n",
      "1.914858 B-BRA    word.lower():borjuis\n",
      "1.913590 B-BRA    word.lower():cussons\n",
      "1.911889 I-PRO|B-TYP +1:word.lower()::\n",
      "1.911423 B-TYP    -1:word.lower():prefer\n",
      "1.910254 I-PRO|B-TYP -1:word.lower():nyx\n",
      "1.903878 I-PRO|B-BRA word.lower():kerastasenya\n",
      "1.903528 I-PRO|B-TYP word[-3:]:rce\n",
      "1.897772 B-TYP    word.lower():tamagohada\n",
      "1.896498 I-PRO    +1:word.lower():--\n",
      "1.895050 I-PRO    word.lower():uv\n",
      "1.894294 I-PRO|B-TYP +1:word.lower():sebamed\n",
      "1.892072 O        -1:word.lower():di\n",
      "1.891049 I-PRO    -1:word.lower():purederm\n",
      "1.890749 I-PRO    word.lower():scandalous\n",
      "1.890749 I-PRO    -1:word.lower():(#721)\n",
      "1.887969 I-PRO    word.lower():beras\n",
      "1.883990 O        word[-2:]:li\n",
      "1.883329 B-TYP    word.lower():repairwear\n",
      "1.880339 B-BRA    word.lower():paula\n",
      "1.879586 O        word.lower():natural\n",
      "1.878749 O        word.lower():sm\n",
      "1.878749 O        word[-3:]:sm\n",
      "1.876058 O        word[-3:]:uma\n",
      "1.874868 I-PRO|B-BRA -1:word.lower():lippen\n",
      "1.872738 B-TYP    word.lower():echinacea\n",
      "1.872738 B-TYP    word[-3:]:cea\n",
      "1.872277 B-TYP    word[-2:]:yl\n",
      "1.872041 I-PRO|B-TYP -1:word.lower():rimmel\n",
      "1.871735 O        word.lower():cuma\n",
      "1.871557 B-TYP    word.lower():spirit\n",
      "1.868563 I-PRO|I-BRA -1:word.lower():st\n",
      "1.867922 I-PRO|B-TYP word.lower():thailand\n",
      "1.867122 I-PRO    +1:word.lower():styling\n",
      "1.865416 O        word[-2:]:an\n",
      "1.860412 I-PRO|B-TYP -1:word.lower():skinfood\n",
      "1.860338 I-PRO|I-TYP -1:word.lower():duo\n",
      "1.858936 B-PRO|B-BRA word.lower():palgantong\n",
      "1.850787 B-BRA    word.lower():bbpr\n",
      "1.850787 B-BRA    word[-3:]:bpr\n",
      "1.850787 B-BRA    word[-2:]:pr\n",
      "1.848749 B-TYP    word[-3:]:tar\n",
      "1.844115 O        word.lower():ya\n",
      "1.843541 I-PRO    -1:word.lower():palgantong\n",
      "1.842711 O        -1:word.lower():cover\n",
      "1.839998 I-PRO    word[-2:]:it\n",
      "1.837599 I-PRO|I-BRA word.onList\n",
      "1.837540 O        word[-3:]:ya\n",
      "1.833392 I-PRO|I-TYP -1:word.lower():hawaiian\n",
      "1.830061 O        word[-2:]:up\n",
      "1.829177 O        word.lower():collection\n",
      "1.826820 I-PRO|B-TYP word[-2:]:ri\n",
      "1.825380 I-PRO|I-TYP -1:word.lower():no\n",
      "1.824958 B-BRA    -1:word.lower():kayak\n",
      "1.819205 B-TYP    -1:word.lower():fw\n",
      "1.817372 I-PRO|B-TYP word.lower():grapes\n",
      "1.813112 I-PRO|I-BRA -1:word.lower():burt\n",
      "1.811019 B-TYP    word.lower():bonacure\n",
      "1.810448 B-TYP    word.lower():tlc\n",
      "1.810448 B-TYP    word[-3:]:TLC\n",
      "1.810050 I-PRO    word.lower():mulberry\n",
      "1.810028 B-PRO|B-BRA word.lower():abh\n",
      "1.807553 O        -1:word.lower():langsung\n",
      "1.805560 B-PRO    +1:word.lower():varian\n",
      "1.804676 B-BRA    word[-2:]:pf\n",
      "1.803576 I-PRO|B-BRA -1:word.lower():muka\n",
      "1.800655 B-TYP    word.lower():freshwater\n",
      "1.799329 O        word.lower():?\n",
      "1.799329 O        word[-3:]:?\n",
      "1.799329 O        word[-2:]:?\n",
      "1.798921 B-PRO|B-TYP word[-2:]:st\n",
      "1.798246 B-TYP    word[-2:]:LC\n",
      "1.798107 I-PRO|I-TYP -1:word.lower():clear\n",
      "1.796353 B-PRO|B-BRA +1:word.lower():pearl\n",
      "1.793441 O        word.lower():trus\n",
      "1.788339 B-PRO|B-TYP word[-3:]:mlc\n",
      "1.787072 O        +1:word.lower():banget\n",
      "1.786905 I-PRO    word.lower():serumnya\n",
      "1.785477 B-BRA    word.lower():essence..\n",
      "1.784336 B-BRA    word[-2:]:pc\n",
      "1.784008 B-PRO|B-TYP word.lower():smlc\n",
      "1.781976 I-BRA    -1:word.lower():bobbi\n",
      "1.781975 I-PRO    word.lower():make\n",
      "1.781770 B-BRA    word[-3:]:rte\n",
      "1.779181 B-BRA    word[-3:]:pc\n",
      "1.775988 O        word[-2:]:ma\n",
      "1.774620 I-PRO    -1:word.lower():donner\n",
      "1.768062 I-PRO|B-TYP word.lower():lipbalm\n",
      "1.764674 B-BRA    -1:word.lower():enakan\n",
      "1.764615 I-PRO|B-BRA +1:word.lower():everlast\n",
      "1.764173 B-TYP    word.lower():ciment\n",
      "1.762276 O        word.lower():ato\n",
      "1.760766 I-PRO    +1:word.lower():up\n",
      "1.759403 I-PRO|B-TYP word.lower():pureness\n",
      "1.757278 I-PRO|I-TYP word.isdigit()\n",
      "1.753923 I-PRO|I-TYP word[-3:]:ray\n",
      "1.752652 I-PRO|B-TYP word.lower():teatree\n",
      "1.752652 I-PRO|B-TYP -1:word.lower():variann\n",
      "1.752380 I-PRO    word[-3:]:eel\n",
      "1.752030 I-PRO|B-TYP word.lower():apricot\n",
      "1.752030 I-PRO|B-TYP word[-3:]:cot\n",
      "1.751701 I-PRO|B-BRA word.lower():caring\n",
      "1.745883 O        word[-2:]:au\n",
      "1.745698 B-BRA    -1:word.lower():nanya\n",
      "1.743046 I-PRO|B-TYP +1:word.lower():key\n",
      "1.739378 I-PRO    word.lower():retractable\n",
      "1.736179 I-PRO|I-BRA word.lower():shop\n",
      "1.735838 O        word[-2:]:lu\n",
      "1.735117 B-PRO|B-BRA word.lower():ysl\n",
      "1.734940 O        word.lower():=\n",
      "1.734940 O        word[-3:]:=\n",
      "1.734940 O        word[-2:]:=\n",
      "1.734837 I-BRA    word[-3:]:bb\n",
      "1.733616 B-PRO|B-BRA word.lower():selsunnya\n",
      "1.731735 I-PRO|B-TYP word.lower():matahari\n",
      "1.730918 I-PRO|B-TYP word[-3:]:ous\n",
      "1.729147 B-PRO|B-TYP word.lower():awake\n",
      "1.728870 I-PRO|B-TYP -1:word.lower():lancome\n",
      "1.725102 B-TYP    word.lower():magnum\n",
      "1.725102 B-TYP    word[-3:]:num\n",
      "1.723382 I-PRO|I-TYP word.lower():clean\n",
      "1.721715 O        word[-2:]:ai\n",
      "1.716452 B-PRO|B-TYP word.lower():dipbrow\n",
      "1.714958 B-PRO|B-BRA -1:word.lower():.\n",
      "1.713573 B-BRA    word.lower():inez\n",
      "1.713573 B-BRA    word[-3:]:nez\n",
      "1.713573 B-BRA    word[-2:]:ez\n",
      "1.711413 O        -1:word.lower():hd\n",
      "1.709864 B-PRO|B-BRA -1:word.lower():finally\n",
      "1.709864 B-PRO|B-BRA +1:word.lower():pomade\n",
      "1.709337 B-PRO    word.lower():dupenya\n",
      "1.707459 O        -1:word.lower():mentholantumnya\n",
      "1.706823 I-PRO    -1:word.lower():mm\n",
      "1.705399 I-PRO    +1:word.lower():jg\n",
      "1.703830 B-TYP    +1:word.lower():keringnya\n",
      "1.697585 B-PRO|B-TYP -1:word.lower():pakai\n",
      "1.696357 O        word[-3:]:ang\n",
      "1.695484 I-PRO    word[-3:]:nge\n",
      "1.692740 I-PRO    word.lower():treatment\n",
      "1.691682 I-PRO|B-TYP word[-3:]:ine\n",
      "1.690746 B-BRA    word.lower():kadus\n",
      "1.689352 O        word[-3:]:tau\n",
      "1.688511 I-PRO|I-TYP +1:word.lower():gakkk\n",
      "1.688495 B-TYP    word[-3:]:mme\n",
      "1.686123 B-TYP    word[-3:]:ada\n",
      "1.685122 I-PRO    +1:word.lower():powder\n",
      "1.683346 B-TYP    +1:word.lower():divine\n",
      "1.682675 I-PRO    -1:word.lower():wisdom\n",
      "1.682230 I-PRO|B-BRA -1:word.lower():di\n",
      "1.682094 I-PRO|I-TYP word.lower():express\n",
      "1.680717 I-BRA    word.lower():bb\n",
      "1.680577 I-PRO    -1:word.lower():cartney\n",
      "1.680438 I-PRO    -1:word.lower():tfs\n",
      "1.678979 B-PRO|B-BRA word[-3:]:abh\n",
      "1.678740 B-PRO|B-TYP word[-2:]:lc\n",
      "1.677671 I-PRO|B-TYP -1:word.lower():mac\n",
      "1.676107 O        -1:word.lower():pre\n",
      "1.671795 O        word.lower():venture\n",
      "1.667698 B-BRA    word.lower():emc\n",
      "1.666057 O        word[-3:]:ato\n",
      "1.665633 B-BRA    word[-3:]:dus\n",
      "1.663692 B-BRA    -1:word.lower():lalu\n",
      "1.661258 B-BRA    word.lower():bbw\n",
      "1.661258 B-BRA    word[-3:]:bbw\n",
      "1.661200 I-TYP    -1:word.lower():white\n",
      "1.657377 I-PRO|B-TYP word.lower():seikisho\n",
      "1.654113 I-PRO    -1:word.lower():viva\n",
      "1.647756 I-PRO|B-BRA word.lower():inez\n",
      "1.647756 I-PRO|B-BRA word[-3:]:nez\n",
      "1.647756 I-PRO|B-BRA word[-2:]:ez\n",
      "1.646993 I-PRO    word[-3:]:lay\n",
      "1.646742 B-BRA    +1:word.lower():mua\n",
      "1.646425 I-PRO    -1:word.lower():grape\n",
      "1.642300 I-PRO|I-TYP +1:word.lower():ternyata\n",
      "1.640203 B-BRA    +1:word.lower():sold\n",
      "1.639293 B-PRO|B-BRA word[-3:]:nyx\n",
      "1.638227 B-BRA    word.lower():palty\n",
      "1.638227 B-BRA    word[-3:]:lty\n",
      "1.637285 B-PRO|B-BRA word.lower():cussons\n",
      "1.636344 I-PRO|I-BRA -1:word.lower():of\n",
      "1.636044 O        word[-3:]:hal\n",
      "1.634442 B-BRA    word[-2:]:bw\n",
      "1.633098 I-PRO|B-TYP -1:word.lower():seri\n",
      "1.630845 B-BRA    -1:word.lower():bilang\n",
      "1.628798 B-BRA    word[-3:]:tia\n",
      "1.627895 I-PRO    -1:word.lower():flushed\n",
      "1.626916 I-PRO|I-TYP word[-2:]:ny\n",
      "1.620900 B-BRA    word.lower():sebamed\n",
      "1.619772 I-PRO|B-TYP -1:word.lower():hadalabo\n",
      "1.619640 B-BRA    +1:word.lower():dimana\n",
      "1.618196 I-PRO|I-TYP +1:word.lower():ku\n",
      "1.618095 I-PRO|I-BRA -1:word.lower():silk\n",
      "1.617479 O        word[-2:]:pa\n",
      "1.615311 I-PRO|I-TYP -1:word.lower():studio\n",
      "1.612811 B-TYP    word.lower():sonia\n",
      "1.612193 I-PRO|B-BRA -1:word.lower():balmnya\n",
      "1.610547 B-BRA    word.lower():ultima\n",
      "1.607899 O        -1:word.lower():lipstick..\n",
      "1.603879 I-PRO|I-TYP -1:word.lower():bain\n",
      "1.602667 I-PRO|I-BRA -1:word.lower():vincent\n",
      "1.602194 I-PRO|I-TYP -1:word.lower():ease\n",
      "1.599909 B-TYP    word.lower():aquadisiac\n",
      "1.599894 O        word.lower():karena\n",
      "1.598303 I-PRO|B-BRA word.lower():viva\n",
      "1.597555 B-BRA    -1:word.lower():produk\n",
      "1.597398 I-BRA    -1:word.lower():body\n",
      "1.596474 O        word.lower():gue\n",
      "1.596326 I-PRO    word.lower():putih\n",
      "1.595401 I-PRO|B-BRA word.lower():biospray\n",
      "1.589409 I-PRO    word[-3:]:tih\n",
      "1.589205 I-PRO|I-TYP -1:word.lower():cream\n",
      "1.586849 I-PRO    -1:word.lower():hydraction\n",
      "1.586687 O        word.lower():aku\n",
      "1.584549 B-PRO|B-BRA word.onListAbb\n",
      "1.582041 O        word[-3:]:P\n",
      "1.582041 O        word[-2:]:P\n",
      "1.580514 B-PRO    jointFeatures:Common+Indication\n",
      "1.580453 B-PRO|B-TYP +2:neigbourFeatures:Brand\n",
      "1.577961 I-PRO|I-TYP word.lower():precious\n",
      "1.577503 I-PRO    -1:word.lower():lipstik\n",
      "1.573788 I-PRO    -1:word.lower():kojiesan\n",
      "1.573521 I-PRO|B-TYP word[-3:]:ion\n",
      "1.572799 I-PRO    +1:word.lower():oil-free\n",
      "1.572389 B-TYP    word[-3:]:rit\n",
      "1.570787 B-BRA    +1:word.lower():bwt\n",
      "1.569711 B-BRA    -1:word.lower():merknya\n",
      "1.568079 I-PRO|I-TYP -1:word.lower():black\n",
      "1.564585 B-PRO|B-BRA word[-2:]:sl\n",
      "1.562001 O        word.lower():warmed\n",
      "1.561242 B-PRO    +1:word.lower():pake\n",
      "1.559118 O        word[-2:]:tu\n",
      "1.558977 I-PRO|I-TYP +1:word.lower():..\n",
      "1.557940 I-PRO|B-BRA word.lower():skinfood\n",
      "1.556155 I-PRO|B-TYP word.lower():seaweed\n",
      "1.555871 I-PRO    +1:word.lower():leave-in\n",
      "1.549050 O        word[-3:]:oba\n",
      "1.548880 I-PRO    bias\n",
      "1.547153 I-PRO    -1:word.lower():spf\n",
      "1.546100 I-PRO|B-TYP word.lower():lipbutter\n",
      "1.545656 I-PRO    word.lower():foundie\n",
      "1.543544 B-PRO|B-BRA +1:word.lower():sakura\n",
      "1.541529 B-PRO    -1:word.lower():juga..\n",
      "1.540554 I-PRO    word[-3:]:nch\n",
      "1.540420 B-TYP    +1:word.lower():kalo\n",
      "1.539387 O        -1:word.lower():damp\n",
      "1.537502 B-BRA    word.lower():banyak\n",
      "1.536510 O        word.lower():or\n",
      "1.536510 O        word[-3:]:or\n",
      "1.535245 I-PRO|I-TYP jointFeatures:Thing+Indication\n",
      "1.534396 B-PRO    word.lower():ddml\n",
      "1.534396 B-PRO    word[-3:]:DML\n",
      "1.534396 B-PRO    word[-2:]:ML\n",
      "1.533704 I-PRO    word.lower():reckless\n",
      "1.533209 B-TYP    word[-3:]:iac\n",
      "1.532340 I-PRO|B-TYP -1:neigbourFeatures:Common\n",
      "1.530974 O        word.lower():si\n",
      "1.529604 O        -1:word.lower():my\n",
      "1.528881 I-PRO    -1:word.lower():apricot\n",
      "1.527811 B-PRO    -1:word.lower():dg\n",
      "1.527551 B-TYP    word[-3:]:anr\n",
      "1.526906 O        word[-3:]:aku\n",
      "1.526673 B-BRA    word.lower():payot\n",
      "1.526673 B-BRA    word[-3:]:yot\n",
      "1.525740 B-BRA    word.lower():xlc\n",
      "1.525740 B-BRA    word[-3:]:xlc\n",
      "1.525588 O        word.lower():p\n",
      "1.525173 B-BRA    word.lower():moogoo.\n",
      "1.525173 B-BRA    word[-3:]:oo.\n",
      "1.525173 B-BRA    word[-2:]:o.\n",
      "1.525173 B-BRA    -1:word.lower():ake\n",
      "1.523157 I-PRO    word.lower():oil-free\n",
      "1.522146 I-PRO|B-BRA -1:word.lower():pencil\n",
      "1.522105 O        word[-3:]:mpe\n",
      "1.521951 B-TYP    word[-2:]:nr\n",
      "1.518282 B-PRO|B-TYP +1:word.lower():ever\n",
      "1.518272 I-TYP    word.lower():care\n",
      "1.517797 I-PRO|I-TYP -1:word.lower():.\n",
      "1.516400 I-PRO|I-BRA word.lower():bumble\n",
      "1.514324 B-BRA    word[-3:]:e..\n",
      "1.514280 B-PRO|B-BRA word[-3:]:ysl\n",
      "1.513194 B-PRO    word.lower():black\n",
      "1.513122 I-PRO    +1:word.lower():gnc\n",
      "1.511916 B-BRA    word.lower():viva\n",
      "1.511356 B-BRA    +1:word.lower():tulisannya\n",
      "1.511150 I-PRO    -1:word.lower():dhc\n",
      "1.509699 I-PRO|I-TYP word[-3:]:aya\n",
      "1.508963 I-PRO    -1:word.lower():biore\n",
      "1.507701 B-BRA    -1:word.lower():review\n",
      "1.507650 O        word[-3:]:get\n",
      "1.504772 O        word[-3:]:ama\n",
      "1.502689 B-BRA    word.lower():beauteen\n",
      "1.501440 I-PRO|B-TYP word.lower():whitening\n",
      "1.500121 O        word.lower():and\n",
      "1.498640 O        -1:word.lower():ginseng\n",
      "1.498052 O        word[-3:]:BB\n",
      "1.498052 O        word[-2:]:BB\n",
      "1.497652 I-PRO|B-BRA word.lower():smashbox..\n",
      "1.497652 I-PRO|B-BRA -1:word.lower():kitnya\n",
      "1.495993 B-PRO    word[-3:]:ack\n",
      "1.495959 B-BRA    word[-3:]:bb\n",
      "1.495635 B-PRO    +1:word.lower():beras\n",
      "1.495367 I-PRO|B-BRA word[-3:]:x..\n",
      "1.493805 B-TYP    word[-2:]:ro\n",
      "1.493067 I-PRO|B-TYP word[-3:]:ast\n",
      "1.492764 I-PRO|I-TYP -1:word.lower():spring\n",
      "1.491925 I-PRO|B-TYP word.lower():resilience\n",
      "1.491241 B-TYP    -1:word.lower():nama\n",
      "1.490532 I-PRO    -1:word.lower():yang\n",
      "1.490277 B-BRA    +1:word.lower():brandt\n",
      "1.489970 B-TYP    +1:word.lower():oil\n",
      "1.486142 I-PRO|I-TYP -1:word.lower():strobe\n",
      "1.483686 I-TYP    word[-2:]:ra\n",
      "1.483006 I-PRO|I-BRA -1:word.lower():&\n",
      "1.482556 B-PRO|B-BRA +1:word.lower():luxe\n",
      "1.482434 I-PRO    +1:word.lower():colorstay\n",
      "1.481026 I-PRO    -1:word.lower():warna\n",
      "1.480022 I-PRO|B-TYP -1:word.lower():revlon\n",
      "1.479415 O        word.lower():katanya\n",
      "1.476756 I-PRO|B-TYP -1:word.lower():ysl\n",
      "1.476713 I-PRO    +1:word.lower():2\n",
      "1.476004 B-BRA    word.lower():anastasia\n",
      "1.475223 I-PRO|B-BRA word[-3:]:ray\n",
      "1.474495 B-BRA    -1:word.lower():trus\n",
      "1.474069 I-PRO|I-TYP -1:word.lower():eye\n",
      "1.473300 O        word[-2:]:lo\n",
      "1.472187 I-PRO|I-TYP word[-3:]:tea\n",
      "1.469191 I-BRA    +1:word.lower():sm\n",
      "1.469084 O        word.lower():metro\n",
      "1.468747 O        word[-3:]:ung\n",
      "1.468480 O        word[-3:]:ual\n",
      "1.468333 O        -1:word.lower():makeup\n",
      "1.467358 B-TYP    -1:word.lower():tuh\n",
      "1.467354 I-BRA    -1:word.lower():n\n",
      "1.466893 B-BRA    -1:word.lower():wl\n",
      "1.466802 O        word.lower():!\n",
      "1.466802 O        word[-3:]:!\n",
      "1.466802 O        word[-2:]:!\n",
      "1.465107 I-BRA    word.lower():brandt\n",
      "1.465107 I-BRA    word[-3:]:ndt\n",
      "1.465107 I-BRA    word[-2:]:dt\n",
      "1.464557 I-PRO|I-TYP +1:word.lower():blush\n",
      "1.463668 I-PRO    EOS\n",
      "1.461545 I-PRO|B-TYP word[-3:]:tay\n",
      "1.459943 I-PRO    word.lower():lipstick\n",
      "1.459389 B-TYP    word[-2:]:ig\n",
      "1.459303 I-PRO    -1:word.lower():sleeping\n",
      "1.458670 I-PRO|B-TYP word.lower():lunasol\n",
      "1.458423 B-PRO    -1:word.lower():pk\n",
      "1.458097 I-BRA    word.lower():for\n",
      "1.456617 B-BRA    word.lower():lancome..\n",
      "1.456405 I-PRO    +1:word.lower():green)\n",
      "1.456142 B-TYP    word.lower():ever\n",
      "1.455287 O        word.lower():harmony\n",
      "1.454952 O        word[-3:]:ger\n",
      "1.453048 I-PRO    word.lower():balm\n",
      "1.451699 O        word[-2:]:sa\n",
      "1.451447 B-TYP    word[-2:]:re\n",
      "1.451393 B-PRO|B-BRA word[-3:]:j&j\n",
      "1.451393 B-PRO|B-BRA word[-2:]:&j\n",
      "1.450773 O        word[-3:]:uat\n",
      "1.449362 B-TYP    word.lower():twig\n",
      "1.449362 B-TYP    word[-3:]:wig\n",
      "1.449297 I-PRO|B-TYP word[-3:]:sol\n",
      "1.448413 I-PRO|B-TYP -1:word.lower():bees\n",
      "1.447906 I-PRO    +1:word.lower():biru\n",
      "1.447722 I-PRO|I-TYP word.lower():potion\n",
      "1.447437 B-BRA    word.lower():bioreku\n",
      "1.447437 B-BRA    word[-3:]:eku\n",
      "1.446965 B-BRA    word.lower():la\n",
      "1.445799 I-PRO    -1:word.lower():smlc\n",
      "1.444740 B-TYP    word.lower():grape\n",
      "1.443064 I-PRO|B-BRA -1:word.lower():hbl\n",
      "1.442810 B-BRA    word.lower():ysl\n",
      "1.442635 I-PRO|B-TYP word[-3:]:eed\n",
      "1.442098 O        word.lower():pake\n",
      "1.441988 I-PRO|B-BRA word.lower():nivea..\n",
      "1.441416 B-BRA    -1:word.lower():like\n",
      "1.441385 B-BRA    word[-2:]:ku\n",
      "1.439849 B-BRA    word[-3:]:aan\n",
      "1.438384 B-PRO|B-BRA word[-2:]:bh\n",
      "1.437294 I-PRO|B-TYP -1:neigbourFeatures:Thing\n",
      "1.436220 I-PRO|B-TYP -1:word.lower():j&j\n",
      "1.435650 B-BRA    -1:word.lower():kalo\n",
      "1.435215 I-PRO    -1:word.lower():eyes\n",
      "1.435178 I-PRO|I-BRA -1:word.lower():dessert\n",
      "1.433282 B-PRO    +1:word.lower():mask\n",
      "1.433052 B-BRA    word[-3:]:uis\n",
      "1.433022 B-PRO|B-BRA word[-3:]:itu\n",
      "1.433012 B-PRO    -1:word.lower():apply\n",
      "1.432473 O        -1:word.lower():cleansers\n",
      "1.431893 I-TYP    -1:word.lower():repair\n",
      "1.431095 B-BRA    +1:word.lower():cuma\n",
      "1.430826 I-PRO    +1:word.lower():/\n",
      "1.430735 I-TYP    +1:word.lower():bau\n",
      "1.430618 O        word.lower():shimmer\n",
      "1.430322 I-PRO|I-TYP -1:word.lower():calming\n",
      "1.429941 I-PRO    word[-3:]:ive\n",
      "1.429185 I-PRO|I-TYP +1:word.lower():even\n",
      "1.428978 I-PRO|B-BRA word.lower():etude\n",
      "1.428587 I-PRO    -1:word.lower():paddle\n",
      "1.428030 I-PRO    word[-3:]:die\n",
      "1.426496 I-PRO|B-TYP word.lower():fte\n",
      "1.426112 I-PRO    -1:word.lower():bodlot\n",
      "1.425770 B-TYP    word.lower():hypercurl\n",
      "1.424670 O        word[-3:]:ehe\n",
      "1.423699 I-PRO|B-BRA +1:word.lower():yah\n",
      "1.419955 B-PRO    +1:word.lower():kerastasenya\n",
      "1.418911 I-PRO    -1:word.lower():bourjois\n",
      "1.418151 B-PRO    +1:word.lower():shimmer\n",
      "1.417501 I-BRA    -1:word.lower():'s\n",
      "1.417334 B-BRA    word.lower():oriflame\n",
      "1.417306 O        word.lower():watsons\n",
      "1.416392 B-PRO|B-BRA +1:word.lower():le\n",
      "1.413274 I-PRO    +1:word.lower():detox\n",
      "1.413213 I-PRO|B-TYP word.lower():anr\n",
      "1.412281 I-PRO|B-TYP word[-3:]:lle\n",
      "1.411923 B-BRA    word.lower():flirt!\n",
      "1.411923 B-BRA    word[-3:]:rt!\n",
      "1.411735 I-PRO|B-TYP word.lower():luxe\n",
      "1.411521 B-BRA    word.lower():kelly\n",
      "1.411097 I-PRO|B-TYP +1:word.lower():fresh\n",
      "1.406586 B-BRA    -1:word.lower():sephora\n",
      "1.405989 I-PRO|B-BRA +1:word.lower():itu\n",
      "1.405697 B-TYP    word[-3:]:FTE\n",
      "1.402725 I-PRO|B-TYP word[-3:]:aya\n",
      "1.401682 B-PRO|B-BRA -1:word.lower():atau\n",
      "1.401001 I-PRO|B-TYP EOS\n",
      "1.400192 B-BRA    -1:word.lower():refill\n",
      "1.399918 B-PRO    word[-2:]:pp\n",
      "1.395436 I-PRO    word.lower():sleeping\n",
      "1.394892 O        word[-2:]:rb\n",
      "1.392915 I-BRA    +1:word.lower():ini\n",
      "1.392238 I-PRO    -1:word.lower():hui\n",
      "1.391312 I-PRO    word[-3:]:ras\n",
      "1.391162 B-BRA    word[-2:]:bb\n",
      "1.390911 I-PRO    word.lower():cannes\n",
      "1.390754 B-TYP    word[-2:]:ea\n",
      "1.390454 B-PRO    word[-3:]:ldw\n",
      "1.390454 B-PRO    word[-2:]:dw\n",
      "1.389139 B-PRO|B-BRA word[-3:]:LDW\n",
      "1.389139 B-PRO|B-BRA word[-2:]:DW\n",
      "1.387476 I-PRO    word.lower():face\n",
      "1.386499 O        word.lower():n\n",
      "1.386499 O        word[-3:]:n\n",
      "1.386499 O        word[-2:]:n\n",
      "1.386410 B-TYP    word.lower():ginseng\n",
      "1.383363 B-TYP    +1:word.lower():ato\n",
      "1.381589 B-PRO    -1:word.lower():.\n",
      "1.380349 B-BRA    +1:word.lower():lagi..\n",
      "1.379715 B-PRO    word.lower():lipgloss\n",
      "1.379605 I-PRO    word.lower():bha..\n",
      "1.379605 I-PRO    word[-3:]:A..\n",
      "1.379303 B-TYP    -1:word.lower():beli\n",
      "1.378352 B-BRA    -1:word.lower():or\n",
      "1.378298 I-PRO    word[-2:]:n)\n",
      "1.378137 O        word[-2:]:sm\n",
      "1.377927 B-PRO|B-BRA +1:word.lower():vit\n",
      "1.377016 I-PRO|B-TYP word.lower():goatmilk\n",
      "1.375152 B-PRO|B-BRA -1:word.lower():=\n",
      "1.375034 I-PRO    word.lower():colorshow\n",
      "1.373910 I-PRO    word.lower():biru\n",
      "1.373910 I-PRO    word[-3:]:iru\n",
      "1.373879 I-PRO    -1:word.lower():wear\n",
      "1.373727 B-BRA    word.lower():tbs\n",
      "1.373626 B-BRA    word[-3:]:lly\n",
      "1.373322 I-PRO    word.onCommonList\n",
      "1.372493 B-BRA    word.lower():palmer\n",
      "1.372425 I-PRO|I-TYP -1:word.lower():beautifying\n",
      "1.371009 B-PRO|B-TYP -1:word.lower():nyoba\n",
      "1.369837 B-BRA    +1:word.lower():jg\n",
      "1.368331 I-PRO|B-TYP -1:word.lower():maybelline\n",
      "1.367999 O        word[-3:]:eli\n",
      "1.367395 B-PRO|B-TYP word.lower():ice\n",
      "1.367172 O        word.lower():buat\n",
      "1.367128 B-PRO|B-BRA +1:word.lower():matte\n",
      "1.366265 I-PRO    -1:word.lower():cucumber\n",
      "1.365243 I-PRO    word.lower():water\n",
      "1.364751 I-PRO|B-TYP word.lower():glamour\n",
      "1.363203 B-BRA    word.lower():stifel\n",
      "1.363203 B-BRA    word[-3:]:fel\n",
      "1.361643 I-PRO|B-TYP word[-3:]:nse\n",
      "1.360099 O        word.lower():)\n",
      "1.360099 O        word[-3:]:)\n",
      "1.360099 O        word[-2:]:)\n",
      "1.359392 I-PRO|B-TYP word[-3:]:uxe\n",
      "1.359392 I-PRO|B-TYP word[-2:]:xe\n",
      "1.359144 B-TYP    -1:word.lower():kl\n",
      "1.358099 B-BRA    word.lower():cetaphil\n",
      "1.357730 B-PRO|B-BRA word[-3:]:uis\n",
      "1.357157 B-BRA    -1:word.lower():+\n",
      "1.355666 B-BRA    word.lower():bmc\n",
      "1.355666 B-BRA    word[-3:]:bmc\n",
      "1.355607 I-PRO    -1:word.lower():non\n",
      "1.353743 B-BRA    word[-2:]:lc\n",
      "1.353742 B-PRO    word.lower():lipglosses\n",
      "1.353574 I-PRO    word.lower():lipglosses\n",
      "1.353053 I-PRO|I-BRA word[-3:]:der\n",
      "1.352353 I-PRO|B-TYP -1:word.lower():etude\n",
      "1.351737 B-TYP    word.lower():snob\n",
      "1.351737 B-TYP    word[-3:]:nob\n",
      "1.350314 B-BRA    word[-3:]:j&j\n",
      "1.350314 B-BRA    word[-2:]:&j\n",
      "1.348431 B-PRO    +1:word.lower():sendiri\n",
      "1.348133 O        word[-3:]:blm\n",
      "1.347969 I-PRO|B-TYP -1:word.lower():kerastase\n",
      "1.347947 I-PRO    word.lower():warna\n",
      "1.347910 O        word[-2:]:ja\n",
      "1.347856 I-PRO    word.lower():sun\n",
      "1.347327 I-PRO|B-BRA word.lower():sulwhasoo\n",
      "1.347327 I-PRO|B-BRA word[-3:]:soo\n",
      "1.347127 I-PRO|I-TYP word.lower():finish\n",
      "1.347019 I-PRO|B-TYP -1:word.lower():line\n",
      "1.346008 O        word[-2:]:ni\n",
      "1.345568 I-PRO|B-TYP -1:word.lower():lipbalm\n",
      "1.345128 I-PRO|I-TYP word[-3:]:ion\n",
      "1.344613 B-PRO|B-BRA word.lower():garnier\n",
      "1.343167 B-BRA    +1:word.lower():kan\n",
      "1.342799 B-PRO|B-BRA -1:word.lower():-\n",
      "1.342414 B-BRA    word.lower():bubchen\n",
      "1.342178 O        word.lower():i\n",
      "1.340822 B-BRA    word.lower():mufe\n",
      "1.340707 I-PRO    word[-3:]:rna\n",
      "1.340475 O        word.lower():beli\n",
      "1.339616 B-PRO|B-BRA word.lower():garamycin\n",
      "1.339616 B-PRO|B-BRA +1:word.lower():salep\n",
      "1.338843 I-PRO|I-TYP -1:word.lower():total\n",
      "1.338682 I-PRO|B-BRA -1:neigbourFeatures:Common\n",
      "1.338435 B-BRA    word[-3:]:san\n",
      "1.337736 O        word.lower():say\n",
      "1.337454 I-BRA    word[-3:]:hop\n",
      "1.337072 I-PRO|I-TYP -1:word.lower():blow\n",
      "1.336254 I-PRO    word.lower():normal\n",
      "1.335934 O        word[-2:]:as\n",
      "1.335726 O        word.lower():d\n",
      "1.335597 B-BRA    word.lower():l'oreal\n",
      "1.335128 B-TYP    word[-3:]:mlc\n",
      "1.335071 I-PRO|I-TYP word[-3:]:ing\n",
      "1.334059 B-BRA    +1:word.lower():beli\n",
      "1.333565 I-PRO|B-TYP -1:word.lower():hydrosol\n",
      "1.333136 I-PRO|B-BRA -1:word.lower():merek\n",
      "1.331823 I-PRO|B-TYP +1:word.lower():207\n",
      "1.331118 B-TYP    +1:word.lower():is\n",
      "1.331030 B-PRO    word[-3:]:ars\n",
      "1.330972 B-TYP    word[-2:]:TE\n",
      "1.330592 I-PRO|B-BRA -1:word.lower():brush-nya\n",
      "1.330214 B-BRA    word.lower():evian\n",
      "1.330054 B-PRO|B-BRA word.lower():essence\n",
      "1.329043 I-PRO|B-TYP word[-3:]:alm\n",
      "1.327435 I-PRO    word.lower():hijau\n",
      "1.327435 I-PRO    word[-3:]:jau\n",
      "1.327320 I-PRO|B-BRA -1:neigbourFeatures:Thing\n",
      "1.327258 B-TYP    word[-2:]:lc\n",
      "1.327136 B-TYP    word.lower():bain\n",
      "1.326263 O        word[-2:]:ti\n",
      "1.325328 B-BRA    -1:word.lower():website\n",
      "1.325217 B-TYP    word.lower():vorsatz\n",
      "1.325217 B-TYP    word[-3:]:atz\n",
      "1.324892 I-PRO    -1:word.lower():amp\n",
      "1.324632 I-PRO|I-TYP word.lower():jerawat\n",
      "1.324480 I-PRO|I-TYP word[-2:]:th\n",
      "1.323454 O        word[-3:]:aja\n",
      "1.323300 I-TYP    -1:word.lower():mythic\n",
      "1.323196 I-TYP    word.lower():kasmaran\n",
      "1.323196 I-TYP    -1:word.lower():merak\n",
      "1.322111 I-PRO    -1:word.lower():benton\n",
      "1.320363 O        word[-3:]:di\n",
      "1.320170 I-PRO    word[-3:]:how\n",
      "1.319997 I-PRO    -1:word.lower():jj\n",
      "1.319948 B-BRA    word[-2:]:t!\n",
      "1.319685 I-PRO|I-TYP -1:word.lower():pumpkin\n",
      "1.319427 I-PRO    -1:word.lower():oily/combination\n",
      "1.318448 I-TYP    word[-2:]:ge\n",
      "1.317610 I-PRO|B-BRA -1:word.lower():merk\n",
      "1.317098 I-PRO    word[-2:]:oy\n",
      "1.316614 I-PRO    word.lower():natural\n",
      "1.316303 O        -1:word.lower():fte\n",
      "1.316211 B-PRO|B-BRA word[-2:]:op\n",
      "1.314989 O        +1:word.lower():water\n",
      "1.314679 I-PRO|I-TYP word[-3:]:wat\n",
      "1.314580 B-TYP    word.lower():smlc\n",
      "1.314552 I-BRA    word[-2:]:ui\n",
      "1.314126 B-PRO|B-BRA +1:word.lower():fairness\n",
      "1.313401 I-BRA    word[-3:]:n..\n",
      "1.312933 I-PRO    word.lower():pencil\n",
      "1.312722 I-PRO    +1:word.lower():dipake\n",
      "1.312526 O        word[-3:]:is\n",
      "1.312035 I-PRO|B-TYP -1:word.lower():lauder\n",
      "1.311749 I-PRO    word.lower():powdernya\n",
      "1.311712 I-PRO|B-TYP -1:word.lower():bonacure\n",
      "1.310596 B-BRA    word.lower():olay..\n",
      "1.310596 B-BRA    +1:word.lower():ahahaha\n",
      "1.310536 B-BRA    -1:word.lower():keluaran\n",
      "1.309140 B-PRO    -1:word.lower():belon\n",
      "1.307848 I-PRO    word[-3:]:uid\n",
      "1.307385 B-PRO    word.lower():slate\n",
      "1.307371 B-BRA    word.lower():skinfood\n",
      "1.306842 O        word.lower():gw\n",
      "1.306752 I-PRO|I-BRA word.lower():bees\n",
      "1.306752 I-PRO|I-BRA word[-3:]:ees\n",
      "1.306098 B-BRA    word.lower():wardah\n",
      "1.305939 I-PRO    word.lower():in\n",
      "1.305939 I-PRO    word[-3:]:in\n",
      "1.305433 B-BRA    word.lower():structura\n",
      "1.304847 I-PRO    word[-3:]:bar\n",
      "1.304690 O        word[-3:]:kal\n",
      "1.301557 I-PRO|I-TYP -1:word.lower():caprice\n",
      "1.300767 I-PRO    word[-3:]:uv\n",
      "1.300767 I-PRO    word[-2:]:uv\n",
      "1.300737 B-TYP    word[-2:]:ob\n",
      "1.300522 I-PRO|B-BRA word[-3:]:MAC\n",
      "1.299892 B-PRO    word[-3:]:ses\n",
      "1.299360 B-PRO|B-BRA word[-3:]:cin\n",
      "1.298963 I-PRO    -1:word.lower():colorstay\n",
      "1.297615 I-PRO|B-TYP word.lower():bayem\n",
      "1.297615 I-PRO|B-TYP -1:word.lower():smpo\n",
      "1.294356 B-BRA    word.lower():cherro\n",
      "1.294356 B-BRA    word[-3:]:rro\n",
      "1.294244 I-PRO|B-TYP word[-3:]:yem\n",
      "1.293579 I-PRO|I-TYP -1:word.lower():super\n",
      "1.293538 I-PRO|B-TYP word.lower():greentea\n",
      "1.293227 B-PRO    +1:word.lower():mac\n",
      "1.292130 I-PRO|B-BRA -1:word.lower():mask\n",
      "1.290432 I-PRO|B-TYP -1:word.lower():nuxe\n",
      "1.290424 I-PRO|B-TYP word[-2:]:ve\n",
      "1.289915 O        -1:word.lower():)\n",
      "1.289456 B-TYP    word[-2:]:tz\n",
      "1.288885 I-PRO|B-BRA -1:word.lower():thermage\n",
      "1.288835 B-PRO|B-BRA word.lower():biore\n",
      "1.288741 I-PRO|I-TYP +1:word.lower():;\n",
      "1.287781 B-PRO|B-BRA word[-2:]:do\n",
      "1.284178 B-PRO|B-BRA word[-3:]:ong\n",
      "1.283423 I-PRO|B-BRA -2:neigbourFeatures:Thing\n",
      "1.280937 I-PRO    word.lower():bar\n",
      "1.280391 B-BRA    word.lower():maybell***\n",
      "1.279444 I-BRA    word[-3:]:als\n",
      "1.279296 I-PRO    -1:word.lower():(yg\n",
      "1.278649 I-TYP    -1:word.lower():bain\n",
      "1.277605 I-PRO    -1:word.lower():vit\n",
      "1.277515 B-PRO    word.lower():lippen\n",
      "1.276420 O        word[-2:]:aa\n",
      "1.275255 B-PRO    -1:word.lower():berikutnya\n",
      "1.275036 I-BRA    +1:word.lower():cream\n",
      "1.274700 O        word.lower():beda\n",
      "1.272507 I-PRO|I-TYP word[-3:]:key\n",
      "1.272502 B-BRA    word[-3:]:een\n",
      "1.272229 I-PRO|B-TYP word.lower():bengkuang\n",
      "1.271616 B-BRA    word.lower():mally\n",
      "1.271616 B-BRA    +1:word.lower():*rolling\n",
      "1.271578 I-PRO|I-BRA -1:word.lower():juice\n",
      "1.269861 I-PRO|I-TYP +1:word.lower():with\n",
      "1.269730 I-PRO|I-TYP word[-2:]:nk\n",
      "1.269007 I-PRO|B-TYP word.lower():schwarzkopf\n",
      "1.268981 I-PRO|I-TYP -1:word.lower():natural\n",
      "1.268675 B-BRA    word[-3:]:y..\n",
      "1.268137 I-PRO|B-BRA word.lower():tbs\n",
      "1.268014 B-PRO|B-TYP word.lower():anr-nya\n",
      "1.267615 B-BRA    word[-3:]:itu\n",
      "1.266886 I-PRO|I-TYP word[-2:]:le\n",
      "1.266880 I-BRA    -1:word.lower():the\n",
      "1.266414 I-TYP    word.lower():dream-nya\n",
      "1.266414 I-TYP    -1:word.lower():collagen\n",
      "1.264967 B-PRO|B-BRA word[-3:]:lla\n",
      "1.264883 B-PRO    -1:word.lower():sisanya\n",
      "1.264272 I-PRO    +1:word.lower():bha..\n",
      "1.263803 O        +1:word.lower():to\n",
      "1.263705 I-PRO    -1:word.lower():orgasm\n",
      "1.263309 I-PRO|I-TYP word[-3:]:oil\n",
      "1.263307 B-PRO|B-BRA word.lower():mua\n",
      "1.262641 B-PRO|B-BRA +1:word.lower():hd\n",
      "1.262500 B-PRO    word[-2:]:ck\n",
      "1.262377 I-PRO|B-TYP word[-3:]:lor\n",
      "1.262364 I-PRO    -1:word.lower():lashblast\n",
      "1.261422 I-PRO    -1:word.lower():batiste\n",
      "1.261174 I-TYP    word.lower():expressnya\n",
      "1.260390 B-PRO    word[-3:]:pen\n",
      "1.260119 I-TYP    word.lower():spa\n",
      "1.260112 B-BRA    word.lower():garnier\n",
      "1.260078 I-PRO|B-TYP -1:word.lower():skii\n",
      "1.259798 I-PRO|B-TYP word.lower():dipbrow\n",
      "1.258640 O        word[-3:]:mia\n",
      "1.257305 O        word.lower():ethereal\n",
      "1.257123 B-BRA    word[-3:]:hen\n",
      "1.256990 O        word.lower():tammia\n",
      "1.254632 B-BRA    word.lower():clarii\n",
      "1.254632 B-BRA    word[-3:]:rii\n",
      "1.254508 I-PRO|I-BRA word.lower():line\n",
      "1.253951 I-PRO|B-BRA word.lower():silk\n",
      "1.253893 B-TYP    word[-2:]:st\n",
      "1.253727 B-PRO|B-BRA word[-2:]:pf\n",
      "1.253271 B-TYP    -1:word.lower():wow..bagusan\n",
      "1.253121 I-PRO    word[-2:]:di\n",
      "1.252914 B-PRO|B-TYP +1:word.lower():oil\n",
      "1.252894 I-PRO    word.lower():gel\n",
      "1.252523 B-BRA    word.lower():natur..\n",
      "1.251662 I-PRO|B-TYP word.lower():spirulina\n",
      "1.251488 I-PRO|I-TYP word.lower():day\n",
      "1.250920 O        word.lower():di\n",
      "1.249071 O        word[-3:]:tuh\n",
      "1.248572 I-PRO    word.lower():-\n",
      "1.248572 I-PRO    word[-3:]:-\n",
      "1.248572 I-PRO    word[-2:]:-\n",
      "1.247489 O        -1:word.lower():shop\n",
      "1.247341 O        word[-3:]:are\n",
      "1.247210 I-PRO    word.lower():berkerudung)\n",
      "1.247210 I-PRO    word[-3:]:ng)\n",
      "1.247210 I-PRO    word[-2:]:g)\n",
      "1.246757 I-PRO    word.lower():)\n",
      "1.246757 I-PRO    word[-3:]:)\n",
      "1.246757 I-PRO    word[-2:]:)\n",
      "1.246313 I-PRO|I-BRA -1:word.lower():skin\n",
      "1.245628 I-PRO    word.lower():collection\n",
      "1.245539 O        word.lower():is\n",
      "1.245045 I-PRO    -1:word.lower():treatment\n",
      "1.244926 I-PRO    word.lower():kerontokan\n",
      "1.244453 I-PRO    word.lower():cleansers\n",
      "1.244434 B-PRO|B-TYP -1:word.lower():klo\n",
      "1.244200 B-PRO    word.lower():nars\n",
      "1.243994 I-PRO|I-TYP word[-2:]:om\n",
      "1.243843 I-PRO    +1:word.lower():something\n",
      "1.242593 I-PRO    +1:word.lower():matahari\n",
      "1.241810 I-PRO|B-TYP +1:word.lower():lipbalm\n",
      "1.241617 I-PRO    -1:word.lower():technakohl\n",
      "1.241602 B-PRO|B-BRA -1:word.lower():?\n",
      "1.241249 B-TYP    word[-3:]:asi\n",
      "1.241134 B-PRO|B-TYP +1:word.lower():peel\n",
      "1.241003 O        -1:word.lower():stila\n",
      "1.238536 O        word.lower():a\n",
      "1.238491 O        word[-3:]:deh\n",
      "1.238049 I-PRO|B-TYP word.lower():ginseng\n",
      "1.237827 O        word.lower():deh\n",
      "1.237709 B-TYP    word.lower():benetint\n",
      "1.235915 B-BRA    word.lower():iqqu\n",
      "1.235915 B-BRA    word[-3:]:qqu\n",
      "1.235915 B-BRA    word[-2:]:qu\n",
      "1.235513 I-PRO|B-TYP word.lower():biotouch\n",
      "1.235219 I-TYP    word[-3:]:ine\n",
      "1.234190 I-PRO    +1:word.lower():curler\n",
      "1.233844 I-PRO|B-BRA word.isupper()\n",
      "1.231063 I-PRO|I-BRA word.lower():sp\n",
      "1.231063 I-PRO|I-BRA word[-3:]:sp\n",
      "1.230882 B-BRA    -1:word.lower():drpd\n",
      "1.230523 B-PRO    -1:word.lower():tekstur\n",
      "1.230187 O        +1:word.lower():controlnya\n",
      "1.229966 B-BRA    word.lower():dove\n",
      "1.229885 I-PRO|I-BRA word[-2:]:sp\n",
      "1.229823 I-PRO    word.lower():something..\n",
      "1.229627 O        -1:word.lower():paling\n",
      "1.229597 B-BRA    -1:word.lower():gitu\n",
      "1.229566 I-PRO|I-TYP -1:word.lower():pure\n",
      "1.228635 B-PRO|B-BRA +1:word.lower():light\n",
      "1.228595 O        word.lower():sukses\n",
      "1.228558 B-TYP    +1:word.lower():pun\n",
      "1.226381 B-PRO|B-BRA word[-2:]:ul\n",
      "1.226364 I-PRO|B-TYP word[-3:]:opf\n",
      "1.226170 I-PRO|I-TYP +1:word.lower():10\n",
      "1.225971 O        word.lower():love\n",
      "1.225970 I-PRO    word.lower():lipstick..\n",
      "1.225644 I-PRO|I-TYP word.lower():balmnya\n",
      "1.225500 I-PRO    -1:word.lower():oil\n",
      "1.224826 B-BRA    word.lower():swarzkorpf\n",
      "1.224826 B-BRA    word[-3:]:rpf\n",
      "1.224788 I-PRO|B-BRA word.lower():nyx\n",
      "1.224788 I-PRO    -1:word.lower():obagi\n",
      "1.224436 B-PRO|B-BRA word.lower():viva\n",
      "1.223464 B-PRO|B-BRA -1:word.lower()::\n",
      "1.222853 I-PRO|B-TYP -1:word.lower():sampo\n",
      "1.222176 O        word[-2:]:di\n",
      "1.221828 O        -1:word.lower():gue\n",
      "1.221295 B-BRA    word.lower():remington\n",
      "1.221100 B-BRA    word.lower():paul\n",
      "1.221100 B-BRA    word[-3:]:aul\n",
      "1.220606 I-PRO    -1:word.lower():bbsb\n",
      "1.220448 I-PRO|B-TYP word.lower():series\n",
      "1.220149 I-PRO    +1:word.lower():buat\n",
      "1.219405 O        word.lower():atau\n",
      "1.218522 B-BRA    word.lower():bless\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.218488 O        word.lower():so\n",
      "1.216293 O        word[-3:]:I\n",
      "1.216293 O        word[-2:]:I\n",
      "1.215961 B-TYP    word[-2:]:ac\n",
      "1.215730 I-PRO|B-BRA word.lower():gnc\n",
      "1.215730 I-PRO|B-BRA word[-3:]:GNC\n",
      "1.215730 I-PRO|B-BRA word[-2:]:NC\n",
      "1.215205 I-PRO    -1:word.lower():bright\n",
      "1.214922 I-PRO|B-BRA +1:word.lower():gw\n",
      "1.214306 B-TYP    +1:word.lower():n\n",
      "1.214023 I-PRO|I-TYP word[-2:]:nt\n",
      "1.213996 I-PRO    -1:word.lower():ttdo\n",
      "1.213198 I-PRO|B-TYP word[-3:]:sic\n",
      "1.212986 B-TYP    +1:word.lower():adalah\n",
      "1.212637 I-BRA    word.lower():mitchell\n",
      "1.210829 I-PRO    -1:word.lower():mua\n",
      "1.210475 O        word[-3:]:yan\n",
      "1.210121 I-PRO    word.lower():perfeume\n",
      "1.209402 B-PRO|B-BRA -1:word.lower():...\n",
      "1.209245 I-PRO    word[-3:]:non\n",
      "\n",
      "Top negative:\n",
      "-1.764110 O        -1:word.lower():bwt\n",
      "-1.822468 O        +1:word.lower():(\n",
      "-1.825160 O        +1:word.lower():cuman\n",
      "-1.855468 B-BRA    +1:neigbourFeatures:Thing\n",
      "-1.914137 B-BRA    word.onThingList\n",
      "-1.915545 O        word.isupper()\n",
      "-1.923959 O        +1:word.lower():hrg\n",
      "-1.934173 O        word[-3:]:ody\n",
      "-1.948411 B-PRO|B-TYP word.onThingList\n",
      "-1.971099 O        word.lower():ginseng\n",
      "-1.973727 O        word[-3:]:ats\n",
      "-2.034867 O        word[-2:]:rl\n",
      "-2.073671 O        word[-3:]:ima\n",
      "-2.177675 O        -1:word.lower():-\n",
      "-2.182283 O        -1:word.lower():milani\n",
      "-2.187194 O        +1:word.lower():itu\n",
      "-2.187263 O        -1:word.lower():clean\n",
      "-2.222930 O        word[-2:]:op\n",
      "-2.236658 O        -1:word.lower():tuh\n",
      "-2.308024 O        word[-2:]:ac\n",
      "-2.317904 O        -1:word.lower():lalu\n",
      "-2.573860 I-PRO|B-TYP word.onCommonList\n",
      "-2.605977 I-PRO|B-BRA word.onThingList\n",
      "-2.647999 I-PRO|B-TYP word.onThingList\n",
      "-2.734801 O        word[-3:]:int\n",
      "-2.832476 O        word[-2:]:ro\n",
      "-3.005350 O        word.onList\n",
      "-3.085137 B-PRO|B-BRA word.onThingList\n",
      "-3.241626 O        word[-3:]:eal\n",
      "-3.355240 O        word.onListAbb\n"
     ]
    }
   ],
   "source": [
    "def print_state_features(state_features):\n",
    "    for (attr, label), weight in state_features:\n",
    "        print(\"%0.6f %-8s %s\" % (weight, label, attr))\n",
    "\n",
    "print(\"Top positive:\")\n",
    "print_state_features(Counter(crf.state_features_).most_common(1000))\n",
    "\n",
    "print(\"\\nTop negative:\")\n",
    "print_state_features(Counter(crf.state_features_).most_common()[-30:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top likely transitions:\n",
      "B-PRO  -> I-PRO|B-BRA 4.209740\n",
      "I-TYP  -> I-TYP   4.055190\n",
      "I-PRO|B-TYP -> I-PRO|I-TYP 3.830596\n",
      "I-PRO  -> I-PRO|B-BRA 3.791523\n",
      "I-PRO|I-TYP -> I-PRO|I-TYP 3.747679\n",
      "B-TYP  -> I-TYP   3.698041\n",
      "B-PRO|B-TYP -> I-PRO|B-BRA 3.417400\n",
      "B-PRO|B-TYP -> I-PRO|I-TYP 3.386265\n",
      "I-PRO  -> I-PRO   3.076848\n",
      "I-PRO|B-BRA -> I-PRO|I-BRA 2.888759\n",
      "B-PRO|B-BRA -> I-PRO|B-TYP 2.807363\n",
      "I-PRO|I-BRA -> I-PRO|I-BRA 2.775058\n",
      "O      -> O       2.569619\n",
      "I-PRO|I-TYP -> I-PRO|B-BRA 2.519317\n",
      "B-PRO  -> I-PRO   1.979509\n",
      "I-PRO|I-BRA -> I-PRO|B-TYP 1.932849\n",
      "B-PRO|B-BRA -> I-PRO|I-BRA 1.802191\n",
      "O      -> B-PRO|B-BRA 1.549179\n",
      "O      -> B-TYP   1.340997\n",
      "O      -> B-BRA   1.300090\n",
      "\n",
      "Top unlikely transitions:\n",
      "I-PRO  -> I-BRA   -2.481249\n",
      "I-TYP  -> I-BRA   -2.610049\n",
      "B-PRO  -> B-BRA   -2.643754\n",
      "I-PRO|I-TYP -> I-BRA   -2.673295\n",
      "I-BRA  -> I-TYP   -2.751847\n",
      "I-BRA  -> I-PRO   -2.786995\n",
      "O      -> I-TYP   -2.799622\n",
      "I-PRO|I-BRA -> I-TYP   -2.954213\n",
      "I-PRO|I-TYP -> I-TYP   -2.960141\n",
      "B-PRO|B-BRA -> I-PRO|I-TYP -2.971458\n",
      "I-BRA  -> B-BRA   -3.106069\n",
      "B-PRO|B-BRA -> I-TYP   -3.120515\n",
      "I-BRA  -> I-PRO|B-TYP -3.218250\n",
      "B-TYP  -> I-BRA   -3.303614\n",
      "B-PRO|B-BRA -> I-BRA   -3.381701\n",
      "I-PRO|B-BRA -> I-BRA   -3.443431\n",
      "I-BRA  -> I-PRO|I-BRA -3.452326\n",
      "B-PRO  -> I-PRO|I-TYP -3.529941\n",
      "O      -> I-PRO|B-BRA -3.931420\n",
      "B-PRO  -> I-BRA   -3.999867\n"
     ]
    }
   ],
   "source": [
    "def print_transitions(trans_features):\n",
    "    for (label_from, label_to), weight in trans_features:\n",
    "        print(\"%-6s -> %-7s %0.6f\" % (label_from, label_to, weight))\n",
    "\n",
    "print(\"Top likely transitions:\")\n",
    "print_transitions(Counter(crf.transition_features_).most_common(20))\n",
    "\n",
    "print(\"\\nTop unlikely transitions:\")\n",
    "print_transitions(Counter(crf.transition_features_).most_common()[-20:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "for i in range(len(y_test)):\n",
    "    print(y_test[i])\n",
    "    print(y_pred[i])\n",
    "    print(sequence_accuracy_score(y_test[i], y_pred[i]))\n",
    "'''\n",
    "#the semi-supervised/automatic labelling\n",
    "#labels all unlabeled data using confidence score\n",
    "#first, label everything and then filter the data based on confidence score limit (limit changes when there's no data found)\n",
    "#then, remove the filtered data from unlabeled data and then add it to train data and then re-train the model\n",
    "#do it until all data is labeled\n",
    "'''\n",
    "for z in range(len(X_unlabeled)):\n",
    "    a = crf.predict_marginals_single(X_unlabeled[z])\n",
    "    b = crf.predict_single(X_unlabeled[z])\n",
    "    total = 0\n",
    "    size = len(a)\n",
    "    for i in range(size):\n",
    "        total += a[i][b[i]]\n",
    "    confidence = total / size\n",
    "    if confidence > 0.75 and confidence < 0.85:\n",
    "        for i in range(len(b)):\n",
    "            print(unlabeled[z][i]+' '+b[i]+' ; ', end='')\n",
    "        print('\\n',end='')\n",
    "'''\n",
    "X_train_sup = deepcopy(X_train)\n",
    "y_train_sup = deepcopy(y_train)\n",
    "X_unlabeled_sup = deepcopy(X_unlabeled)\n",
    "unlabeled_sup = deepcopy(unlabeled)\n",
    "upper = 1\n",
    "lower = 0.99\n",
    "w = 0\n",
    "label_for_unlabeled = []\n",
    "while(X_unlabeled_sup):#or w < 1 (default: X_unlabeled_sup)\n",
    "    print(str(w) + ' - data left:' + str(len(X_unlabeled_sup)) + ' - lower:' + str(lower) + ' - upper:' + str(upper))\n",
    "    found = False\n",
    "    noNew = True\n",
    "    num = []\n",
    "    w += 1\n",
    "    for z in range(len(X_unlabeled_sup)): #X_test/X_unlabeled\n",
    "        a = crf.predict_marginals_single(X_unlabeled_sup[z])\n",
    "        b = crf.predict_single(X_unlabeled_sup[z])\n",
    "        #b = y_pred[z]\n",
    "        total = 0\n",
    "        size = len(a)\n",
    "        #print(unlabeled_sup[z])\n",
    "        for i in range(size):\n",
    "            total += a[i][b[i]]\n",
    "        confidence = total / size\n",
    "        if confidence < upper and confidence > lower:\n",
    "            found = True\n",
    "            row = []\n",
    "            row.append(unlabeled_sup[z])\n",
    "            row.append(b)\n",
    "            label_for_unlabeled.append(row)\n",
    "            fullO = True\n",
    "            for qq in b:\n",
    "                if qq != 'O':\n",
    "                    fullO = False\n",
    "                    break\n",
    "            if fullO == False:\n",
    "                X_train_sup.append(X_unlabeled_sup[z])\n",
    "                y_train_sup.append(b)\n",
    "                noNew = False\n",
    "            num.append(z)\n",
    "    if found == True:\n",
    "        num.sort(reverse=True)\n",
    "        for i in num:\n",
    "            X_unlabeled_sup.pop(i)\n",
    "            unlabeled_sup.pop(i)\n",
    "        if noNew == False:\n",
    "            crf.fit(X_train_sup, y_train_sup)\n",
    "    else:\n",
    "        lower -= 0.01\n",
    "        #upper += 0.005\n",
    "y_pred = crf.predict(X_test)\n",
    "labels = list(crf.classes_)\n",
    "labels.remove('O') # remove 'O' label from evaluation\n",
    "sorted_labels = sorted(labels,key=lambda name: (name[1:], name[0])) # group B and I results\n",
    "print(flat_classification_report(y_test, y_pred, labels=sorted_labels, digits=3))\n",
    "#print(label_for_unlabeled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_sup = deepcopy(X_train)\n",
    "y_train_sup = deepcopy(y_train)\n",
    "X_unlabeled_sup = deepcopy(X_unlabeled)\n",
    "unlabeled_sup = deepcopy(unlabeled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def splitSequence(sequence):\n",
    "    res = []\n",
    "    row = []\n",
    "    for i in range(len(sequence)):\n",
    "        if i == 0:\n",
    "            row.append(sequence[i])\n",
    "        else:\n",
    "            if sequence[i - 1] != sequence[i] - 1:\n",
    "                res.append(row)\n",
    "                row = []\n",
    "                row.append(sequence[i])\n",
    "            else:\n",
    "                row.append(sequence[i])\n",
    "    if row:\n",
    "        res.append(row)\n",
    "    return res\n",
    "\n",
    "def extractSequenceLabel(sentence, labels, conf, limit):\n",
    "    allLabel = []\n",
    "    allSequence = []\n",
    "    sequence = []\n",
    "    label = []\n",
    "    c = 0\n",
    "    s = 0\n",
    "    found = False\n",
    "    for j in range(len(sentence)):\n",
    "        if labels[j] == 'O':\n",
    "            if label:\n",
    "                #if (c/s) >= limit:\n",
    "                if found == False:\n",
    "                    allLabel.append(label)\n",
    "                    allSequence.append(sequence)\n",
    "                found = False\n",
    "                c = 0\n",
    "                s = 0\n",
    "                label = []\n",
    "                sequence = []\n",
    "        elif labels[j][0] == 'B':\n",
    "            if label:\n",
    "                #if (c/s) >= limit:\n",
    "                if found == False:\n",
    "                    allLabel.append(label)\n",
    "                    allSequence.append(sequence)\n",
    "                found = False\n",
    "                c = 0\n",
    "                s = 0\n",
    "                label = []\n",
    "                sequence = []\n",
    "            label.append(labels[j])\n",
    "            sequence.append(sentence[j])\n",
    "            if conf[j][labels[j]] < limit:\n",
    "                found = True\n",
    "            c += conf[j][labels[j]]\n",
    "            s += 1\n",
    "        elif labels[j][0] == 'I':\n",
    "            label.append(labels[j])\n",
    "            sequence.append(sentence[j])\n",
    "            if conf[j][labels[j]] < limit:\n",
    "                found = True\n",
    "            c += conf[j][labels[j]]\n",
    "            s += 1\n",
    "    if label:\n",
    "        #if (c/s) >= limit:\n",
    "        if found == False:\n",
    "            allLabel.append(label)\n",
    "            allSequence.append(sequence)\n",
    "        c = 0\n",
    "        s = 0\n",
    "    return [allLabel, allSequence]\n",
    "'''\n",
    "ii = 10332\n",
    "a = crf.predict_marginals_single(X_unlabeled_sup[ii])\n",
    "b = crf.predict_single(X_unlabeled_sup[ii])\n",
    "pp = extractSequenceLabel(unlabeled_sup[ii],b,a,0.7)\n",
    "print(unlabeled_sup[ii])\n",
    "print(b)\n",
    "print(pp)\n",
    "'''\n",
    "\n",
    "def replaceLabel(sequence, labels, b, conf):\n",
    "    found = False\n",
    "    for c in range(len(b[1])):\n",
    "        N = [i for i in range(len(sequence)) if sequence[i] in b[1][c]]\n",
    "        if N:\n",
    "            Nn = splitSequence(N)\n",
    "            for s in Nn:\n",
    "                L = []\n",
    "                for i in s:\n",
    "                    L.append(b[1][c].index(sequence[i]))\n",
    "                notProOnly = False\n",
    "                proExist = False\n",
    "                for i in L:\n",
    "                    if 'PRO' in b[0][c][i]:\n",
    "                        proExist = True\n",
    "                        break\n",
    "                for i in L:\n",
    "                    if ('PRO' in b[0][c][i] and '|' in b[0][c][i]) or ('BRA' in b[0][c][i]) or ('TYP' in b[0][c][i]):\n",
    "                        notProOnly = True\n",
    "                        break\n",
    "                if ((proExist and notProOnly) and (proExist and len(s) > 1)) or (not proExist and notProOnly):\n",
    "                    low = False\n",
    "                    tot = 0\n",
    "                    clear = True\n",
    "                    for d in range(len(s)):\n",
    "                        if conf[s[d]] > 0.8:\n",
    "                            clear = False\n",
    "                            #break\n",
    "                        tot += conf[s[d]]\n",
    "                    avg = tot / len(s)\n",
    "                    if avg <= 0.8:\n",
    "                    #if clear:\n",
    "                        low = True\n",
    "                    if low:\n",
    "                        for d in range(len(s)):\n",
    "                            if len(sequence[s[d]]) > 0:\n",
    "                                newLabel = b[0][c][L[d]]\n",
    "                                if d < len(s):\n",
    "                                    if (d == 0) or ((d - 1) > 0 and labels[s[d] - 1] == 'O') or newLabel[:5] == 'B-PRO':\n",
    "                                        newLabel = newLabel[:0] + 'B' + newLabel[1:]\n",
    "                                        if '|' in newLabel:\n",
    "                                            if newLabel[6:7] == 'I':\n",
    "                                                newLabel = newLabel[:6] + 'B' + newLabel[7:]\n",
    "                                    if (d == 0) or ((d - 1) > 0 and (labels[s[d] - 1][0] == 'I' or labels[s[d] - 1][0] == 'B')) and newLabel[0] == 'B':\n",
    "                                        if labels[s[d] - 1][2:5] == newLabel[2:5]:\n",
    "                                            newLabel = newLabel[:0] + 'I' + newLabel[1:]\n",
    "                                    if len(newLabel) > 5 and ((d - 1) > 0 and len(labels[s[d] - 1]) > 5):\n",
    "                                        if (d == 0) or ((d - 1) > 0 and (labels[s[d] - 1][6] == 'I' or labels[s[d] - 1][6] == 'B')) and newLabel[6] == 'B':\n",
    "                                            if labels[s[d] - 1][8:11] == newLabel[8:11]:\n",
    "                                                newLabel = newLabel[:6] + 'I' + newLabel[7:]\n",
    "                                    if (d < (len(s) - 1) and (labels[s[d] + 1][0] == 'B')) and newLabel[0] == 'B':\n",
    "                                        if labels[s[d] + 1][2:5] == newLabel[2:5]:\n",
    "                                            labels[s[d] + 1] = labels[s[d] + 1][:0] + 'I' + labels[s[d] + 1][1:]\n",
    "                                    if len(newLabel) > 5 and (d < (len(s) - 1) and len(labels[s[d] + 1]) > 5):\n",
    "                                        if (d < (len(s) - 1) and (labels[s[d] + 1][6] == 'B')) and newLabel[6] == 'B':\n",
    "                                            if labels[s[d]+ 1][8:11] == newLabel[8:11]:\n",
    "                                                labels[s[d] + 1] = labels[s[d] + 1][:6] + 'I' + labels[s[d] + 1][7:]\n",
    "                                if 'PRO' in labels[s[d]] and 'PRO' not in newLabel:\n",
    "                                    labels[s[d]] = labels[s[d]]\n",
    "                                else:\n",
    "                                    labels[s[d]] = newLabel\n",
    "                                found = True\n",
    "                    \n",
    "            '''\n",
    "            L = []\n",
    "            for i in N:\n",
    "                L.append(b[1][c].index(sequence[i]))\n",
    "            for d in range(len(N)):\n",
    "                newLabel = b[0][c][L[d]]\n",
    "                if d < len(N) - 1:\n",
    "                    if (d == 0) or ((N[d] + 1) != N[d + 1]) or ((N[d] - 1) > 0 and labels[N[d] - 1] == 'O') or newLabel[:5] == 'B-PRO':\n",
    "                        newLabel = newLabel[:0] + 'B' + newLabel[1:]\n",
    "                        if '|' in newLabel:\n",
    "                            if newLabel[6:7] == 'I':\n",
    "                                newLabel = newLabel[:6] + 'B' + newLabel[7:]\n",
    "                labels[N[d]] = newLabel\n",
    "            '''\n",
    "        else:\n",
    "            return False\n",
    "    if not found:\n",
    "        return False\n",
    "    else:\n",
    "        return labels\n",
    "\n",
    "#ll = replaceLabel(unlabeled_sup[ii],b,pp)\n",
    "#print(ll)\n",
    "#print(replaceLabel(['a','b','c','d','e','f'],['O','O','O','O','O','O'],[[['I-BRA'],['I-TYP'],['B-PRO|B-BRA','I-PRO|B-TYP','I-PRO|I-TYP']],[['b'],['c'],['d','e','f']]],[0,0,0,0,0,0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filterPro(labels):\n",
    "    allLabel = []\n",
    "    allLabelIndex = []\n",
    "    label = []\n",
    "    labelIndex = []\n",
    "    for j in range(len(labels)):\n",
    "        if labels[j] == 'O':\n",
    "            if label:\n",
    "                allLabel.append(label)\n",
    "                allLabelIndex.append(labelIndex)\n",
    "                label = []\n",
    "                labelIndex = []\n",
    "        elif labels[j][0] == 'B':\n",
    "            if label:\n",
    "                allLabel.append(label)\n",
    "                allLabelIndex.append(labelIndex)\n",
    "                label = []\n",
    "                labelIndex = []\n",
    "            label.append(labels[j])\n",
    "            labelIndex.append(j)\n",
    "        elif labels[j][0] == 'I':\n",
    "            label.append(labels[j])\n",
    "            labelIndex.append(j)\n",
    "    if label:\n",
    "        allLabel.append(label)\n",
    "        allLabelIndex.append(labelIndex)\n",
    "    for i in range(len(allLabel)):\n",
    "        pizdec = True\n",
    "        lb = ''\n",
    "        for j in allLabel[i]:\n",
    "            if '|' not in j:\n",
    "                pizdec = False\n",
    "                break\n",
    "            else:\n",
    "                if lb == '':\n",
    "                    lb = j[8:11]\n",
    "                else:\n",
    "                    if j[8:11] != lb:\n",
    "                        pizdec = False\n",
    "                        break\n",
    "        if pizdec:\n",
    "            for j in range(len(allLabel[i])):\n",
    "                labels[allLabelIndex[i][j]] = allLabel[i][j][6:11]\n",
    "    return labels\n",
    "#aa = ['O','B-PRO|B-BRA','I-PRO|I-BRA','O','B-BRA','O']\n",
    "#print(aa)\n",
    "#aa = filterPro(aa)\n",
    "#print(aa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ruleReplace(feature, label):\n",
    "    for i in range(len(feature)):\n",
    "        if feature[i]['word.onList'] == True or feature[i]['word.onListAbb'] == True:\n",
    "            if 'BRA' not in label[i]:\n",
    "                if label[i] == 'O' or 'TYP' in label[i]:\n",
    "                    if 'BRA' in label[i - 1]:\n",
    "                        label[i] = 'I-BRA'\n",
    "                    else:\n",
    "                        label[i] = 'B-BRA'\n",
    "                elif 'PRO' in label[i]:\n",
    "                    if 'BRA' in label[i - 1]:\n",
    "                        label[i] = label[i][:6] + 'I-BRA'\n",
    "                    else:\n",
    "                        label[i] = label[i][:6] + 'B-BRA'\n",
    "    return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 - data left:16853\n",
      "# of Hi Conf: 1566\n",
      "PRO\n",
      "Precision : 0.7634854771784232\n",
      "Recall : 0.6237288135593221\n",
      "F1 : 0.6865671641791046\n",
      "BRA\n",
      "Precision : 0.9163090128755365\n",
      "Recall : 0.8767967145790554\n",
      "F1 : 0.8961175236096537\n",
      "TYP\n",
      "Precision : 0.4896551724137931\n",
      "Recall : 0.35323383084577115\n",
      "F1 : 0.41040462427745666\n",
      "O\n",
      "Precision : 0.9519382288055468\n",
      "Recall : 0.9890307793058284\n",
      "F1 : 0.9701300786895777\n",
      "Overall Without O\n",
      "Precision : 0.7832058949066059\n",
      "Recall : 0.6937945066124109\n",
      "F1 : 0.7339144220859674\n",
      "Overall With O\n",
      "Precision : 0.9285474680915912\n",
      "Recall : 0.9481032294457763\n",
      "F1 : 0.9373843460085244\n",
      "1 - data left:12714\n",
      "# of Hi Conf: 1140\n",
      "PRO\n",
      "Precision : 0.7666666666666667\n",
      "Recall : 0.6237288135593221\n",
      "F1 : 0.6878504672897197\n",
      "BRA\n",
      "Precision : 0.9102564102564102\n",
      "Recall : 0.8747433264887063\n",
      "F1 : 0.8921465968586387\n",
      "TYP\n",
      "Precision : 0.4866666666666667\n",
      "Recall : 0.36318407960199006\n",
      "F1 : 0.41595441595441596\n",
      "O\n",
      "Precision : 0.9535104364326376\n",
      "Recall : 0.9872298624754421\n",
      "F1 : 0.9700772200772202\n",
      "Overall Without O\n",
      "Precision : 0.7805509038265905\n",
      "Recall : 0.6948118006103764\n",
      "F1 : 0.7334670581154242\n",
      "Overall With O\n",
      "Precision : 0.9295336742620348\n",
      "Recall : 0.9466929911154985\n",
      "F1 : 0.9372767985275874\n",
      "2 - data left:10887\n",
      "# of Hi Conf: 168\n",
      "PRO\n",
      "Precision : 0.774468085106383\n",
      "Recall : 0.6169491525423729\n",
      "F1 : 0.6867924528301887\n",
      "BRA\n",
      "Precision : 0.9163090128755365\n",
      "Recall : 0.8767967145790554\n",
      "F1 : 0.8961175236096537\n",
      "TYP\n",
      "Precision : 0.5033557046979866\n",
      "Recall : 0.373134328358209\n",
      "F1 : 0.42857142857142866\n",
      "O\n",
      "Precision : 0.9524936868686869\n",
      "Recall : 0.9880484610347086\n",
      "F1 : 0.9699453551912568\n",
      "Overall Without O\n",
      "Precision : 0.7893032258606965\n",
      "Recall : 0.6958290946083419\n",
      "F1 : 0.7376967087748365\n",
      "Overall With O\n",
      "Precision : 0.9298711761972929\n",
      "Recall : 0.9475391341136652\n",
      "F1 : 0.9377495549617628\n",
      "3 - data left:10662\n",
      "# of Hi Conf: 40\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       B-BRA      0.702     0.788     0.742       203\n",
      "       I-BRA      0.569     0.744     0.644        39\n",
      "       B-PRO      0.860     0.481     0.617        77\n",
      "       I-PRO      0.646     0.526     0.580       344\n",
      " B-PRO|B-BRA      0.897     0.842     0.868       196\n",
      " I-PRO|B-BRA      0.870     0.534     0.662        88\n",
      " B-PRO|B-TYP      0.375     0.136     0.200        22\n",
      " I-PRO|B-TYP      0.712     0.631     0.669       149\n",
      " I-PRO|I-BRA      0.889     0.615     0.727        52\n",
      " I-PRO|I-TYP      0.605     0.468     0.527       154\n",
      "       B-TYP      0.222     0.067     0.103        30\n",
      "       I-TYP      0.400     0.087     0.143        23\n",
      "\n",
      "   micro avg      0.717     0.598     0.652      1377\n",
      "   macro avg      0.646     0.493     0.540      1377\n",
      "weighted avg      0.708     0.598     0.640      1377\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#per beginning and inner sequence, don't really care what entity inside those, especially if nested\n",
    "highLimit = 0.95\n",
    "w = 0\n",
    "label_for_unlabeled = []\n",
    "while(X_unlabeled_sup):#or w < 1 (default: X_unlabeled_sup)\n",
    "    print(str(w) + ' - data left:' + str(len(X_unlabeled_sup)))\n",
    "    found = False\n",
    "    noNew = True\n",
    "    num = []\n",
    "    labelAll = []\n",
    "    labelConfAll = []\n",
    "    w += 1\n",
    "    highAll = []\n",
    "    highIndex = []\n",
    "    #Xall = []\n",
    "    #newBias = 1.1**(-w)\n",
    "    for z in range(len(X_unlabeled_sup)): #X_test/X_unlabeled/\n",
    "        a = crf.predict_marginals_single(X_unlabeled_sup[z])\n",
    "        b = crf.predict_single(X_unlabeled_sup[z])\n",
    "        #Xall.append(X_unlabeled_sup[z])\n",
    "        labelAll.append(b)\n",
    "        conf = []\n",
    "        for i in range(len(a)):\n",
    "            conf.append(a[i][b[i]])\n",
    "        labelConfAll.append(conf)\n",
    "        high = extractSequenceLabel(unlabeled_sup[z],b,a,highLimit)\n",
    "        if high[0]:\n",
    "            #X_train_sup.append(X_unlabeled_sup[z])\n",
    "            #y_train_sup.append(labelAll[z])\n",
    "            highAll.append(high)\n",
    "            highIndex.append(z)\n",
    "            row = []\n",
    "            row.append(unlabeled_sup[z])\n",
    "            row.append(b)\n",
    "            label_for_unlabeled.append(row)\n",
    "            num.append(z)\n",
    "    #print('before replace: '+str(len(num)))\n",
    "    print('# of Hi Conf: ' + str(len(highAll)))\n",
    "    if num and len(highAll) >= 50:\n",
    "        added = False\n",
    "        if highAll:\n",
    "            for a in range(len(unlabeled_sup)):\n",
    "                changed = False\n",
    "                if a not in highIndex:\n",
    "                    for qq in range(len(highAll)):\n",
    "                        if a != highIndex[qq]:\n",
    "                            labelNew = replaceLabel(unlabeled_sup[a],labelAll[a],highAll[qq],labelConfAll[a])\n",
    "                            if labelNew:\n",
    "                                #print(labelAll[a])\n",
    "                                labelAll[a] = labelNew\n",
    "                                #print(labelAll[a])\n",
    "                                changed = True\n",
    "                                break\n",
    "                #labelReplace = ruleReplace(Xall[a],labelAll[a])\n",
    "                #if labelReplace != labelAll[a]:\n",
    "                #    labelAll[a] = labelReplace\n",
    "                #    changed = True\n",
    "                if changed:\n",
    "                    labelAll[a] = filterPro(labelAll[a])\n",
    "                    #for l in range(len(X_unlabeled_sup[a])):\n",
    "                    #    if newBias <= 0:\n",
    "                    #        X_unlabeled_sup[a][l]['bias'] = 0\n",
    "                    #    else:\n",
    "                    #        X_unlabeled_sup[a][l]['bias'] = newBias\n",
    "                    X_train_sup.append(X_unlabeled_sup[a])\n",
    "                    y_train_sup.append(labelAll[a])\n",
    "                    if a not in num:\n",
    "                        row = []\n",
    "                        row.append(unlabeled_sup[a])\n",
    "                        row.append(labelAll[a])\n",
    "                        label_for_unlabeled.append(row)\n",
    "                        num.append(a)\n",
    "                    added = True\n",
    "        #print('after replace: '+str(len(num)))\n",
    "        if added:\n",
    "            crf.fit(X_train_sup, y_train_sup)\n",
    "        num.sort(reverse=True) #num\n",
    "        for i in num: #num\n",
    "            X_unlabeled_sup.pop(i)\n",
    "            unlabeled_sup.pop(i)\n",
    "        y_pred = crf.predict(X_test)\n",
    "        evaluatione(y_pred)\n",
    "    else:\n",
    "        num = []\n",
    "        for a in range(len(unlabeled_sup)):\n",
    "            row = []\n",
    "            row.append(unlabeled_sup[a])\n",
    "            row.append(labelAll[a])\n",
    "            label_for_unlabeled.append(row)\n",
    "            num.append(a)\n",
    "        num.sort(reverse=True)\n",
    "        for i in num:\n",
    "            X_unlabeled_sup.pop(i)\n",
    "            unlabeled_sup.pop(i)\n",
    "y_pred = crf.predict(X_test)\n",
    "labels = list(crf.classes_)\n",
    "labels.remove('O') # remove 'O' label from evaluation\n",
    "sorted_labels = sorted(labels,key=lambda name: (name[1:], name[0])) # group B and I results\n",
    "print(flat_classification_report(y_test, y_pred, labels=sorted_labels, digits=3))\n",
    "#print(label_for_unlabeled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 - data left:16853\n",
      "# of Hi Conf: 308\n",
      "PRO\n",
      "Precision : 0.7735042735042735\n",
      "Recall : 0.6135593220338983\n",
      "F1 : 0.6843100189035918\n",
      "BRA\n",
      "Precision : 0.9173913043478261\n",
      "Recall : 0.86652977412731\n",
      "F1 : 0.8912354804646252\n",
      "TYP\n",
      "Precision : 0.5285714285714286\n",
      "Recall : 0.3681592039800995\n",
      "F1 : 0.4340175953079179\n",
      "O\n",
      "Precision : 0.9490004722178499\n",
      "Recall : 0.9870661427635887\n",
      "F1 : 0.9676590963807079\n",
      "Overall Without O\n",
      "Precision : 0.79470618824416\n",
      "Recall : 0.688708036622584\n",
      "F1 : 0.7356466645165042\n",
      "Overall With O\n",
      "Precision : 0.9276112067903873\n",
      "Recall : 0.945705824284304\n",
      "F1 : 0.9354960417307979\n",
      "1 - data left:15711\n",
      "# of Hi Conf: 462\n",
      "PRO\n",
      "Precision : 0.7854077253218884\n",
      "Recall : 0.6203389830508474\n",
      "F1 : 0.6931818181818182\n",
      "BRA\n",
      "Precision : 0.9112554112554112\n",
      "Recall : 0.864476386036961\n",
      "F1 : 0.8872497365648051\n",
      "TYP\n",
      "Precision : 0.5035460992907801\n",
      "Recall : 0.35323383084577115\n",
      "F1 : 0.415204678362573\n",
      "O\n",
      "Precision : 0.9494647355163728\n",
      "Recall : 0.9873935821872953\n",
      "F1 : 0.9680577849117173\n",
      "Overall Without O\n",
      "Precision : 0.7901214956345769\n",
      "Recall : 0.6866734486266531\n",
      "F1 : 0.732487689136901\n",
      "Overall With O\n",
      "Precision : 0.9273755513669151\n",
      "Recall : 0.945705824284304\n",
      "F1 : 0.9354015440223302\n",
      "2 - data left:14974\n",
      "# of Hi Conf: 162\n",
      "PRO\n",
      "Precision : 0.7887931034482759\n",
      "Recall : 0.6203389830508474\n",
      "F1 : 0.6944971537001897\n",
      "BRA\n",
      "Precision : 0.9130434782608695\n",
      "Recall : 0.8624229979466119\n",
      "F1 : 0.8870116156282999\n",
      "TYP\n",
      "Precision : 0.5138888888888888\n",
      "Recall : 0.3681592039800995\n",
      "F1 : 0.4289855072463768\n",
      "O\n",
      "Precision : 0.9490165224232887\n",
      "Recall : 0.9873935821872953\n",
      "F1 : 0.9678247612934284\n",
      "Overall Without O\n",
      "Precision : 0.7941381547273159\n",
      "Recall : 0.688708036622584\n",
      "F1 : 0.7355823032645573\n",
      "Overall With O\n",
      "Precision : 0.9275462875558312\n",
      "Recall : 0.9459878719503596\n",
      "F1 : 0.9356298189379948\n",
      "3 - data left:14674\n",
      "# of Hi Conf: 78\n",
      "PRO\n",
      "Precision : 0.8025751072961373\n",
      "Recall : 0.6338983050847458\n",
      "F1 : 0.7083333333333333\n",
      "BRA\n",
      "Precision : 0.9114470842332614\n",
      "Recall : 0.86652977412731\n",
      "F1 : 0.888421052631579\n",
      "TYP\n",
      "Precision : 0.5205479452054794\n",
      "Recall : 0.3781094527363184\n",
      "F1 : 0.43804034582132567\n",
      "O\n",
      "Precision : 0.9514118946206026\n",
      "Recall : 0.9873935821872953\n",
      "F1 : 0.9690688519321925\n",
      "Overall Without O\n",
      "Precision : 0.798844886734751\n",
      "Recall : 0.6968463886063072\n",
      "F1 : 0.7422843290691746\n",
      "Overall With O\n",
      "Precision : 0.9302620753071359\n",
      "Recall : 0.9471160626145818\n",
      "F1 : 0.9376305236323269\n",
      "4 - data left:14582\n",
      "# of Hi Conf: 16\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       B-BRA      0.686     0.773     0.727       203\n",
      "       I-BRA      0.528     0.718     0.609        39\n",
      "       B-PRO      0.816     0.519     0.635        77\n",
      "       I-PRO      0.633     0.491     0.553       344\n",
      " B-PRO|B-BRA      0.877     0.801     0.837       196\n",
      " I-PRO|B-BRA      0.909     0.568     0.699        88\n",
      " B-PRO|B-TYP      0.800     0.182     0.296        22\n",
      " I-PRO|B-TYP      0.694     0.624     0.657       149\n",
      " I-PRO|I-BRA      0.861     0.596     0.705        52\n",
      " I-PRO|I-TYP      0.595     0.487     0.536       154\n",
      "       B-TYP      0.286     0.067     0.108        30\n",
      "       I-TYP      0.333     0.087     0.138        23\n",
      "\n",
      "   micro avg      0.705     0.587     0.641      1377\n",
      "   macro avg      0.668     0.493     0.542      1377\n",
      "weighted avg      0.702     0.587     0.629      1377\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#per beginning and inner sequence, don't really care what entity inside those, especially if nested\n",
    "highLimit = 0.99\n",
    "w = 0\n",
    "label_for_unlabeled = []\n",
    "while(X_unlabeled_sup):#or w < 1 (default: X_unlabeled_sup)\n",
    "    print(str(w) + ' - data left:' + str(len(X_unlabeled_sup)))\n",
    "    found = False\n",
    "    noNew = True\n",
    "    num = []\n",
    "    labelAll = []\n",
    "    labelConfAll = []\n",
    "    w += 1\n",
    "    highAll = []\n",
    "    highIndex = []\n",
    "    #Xall = []\n",
    "    #newBias = 1.1**(-w)\n",
    "    for z in range(len(X_unlabeled_sup)): #X_test/X_unlabeled/\n",
    "        a = crf.predict_marginals_single(X_unlabeled_sup[z])\n",
    "        b = crf.predict_single(X_unlabeled_sup[z])\n",
    "        #Xall.append(X_unlabeled_sup[z])\n",
    "        labelAll.append(b)\n",
    "        conf = []\n",
    "        for i in range(len(a)):\n",
    "            conf.append(a[i][b[i]])\n",
    "        labelConfAll.append(conf)\n",
    "        high = extractSequenceLabel(unlabeled_sup[z],b,a,highLimit)\n",
    "        if high[0]:\n",
    "            #X_train_sup.append(X_unlabeled_sup[z])\n",
    "            #y_train_sup.append(labelAll[z])\n",
    "            highAll.append(high)\n",
    "            highIndex.append(z)\n",
    "            row = []\n",
    "            row.append(unlabeled_sup[z])\n",
    "            row.append(b)\n",
    "            label_for_unlabeled.append(row)\n",
    "            num.append(z)\n",
    "    #print('before replace: '+str(len(num)))\n",
    "    print('# of Hi Conf: ' + str(len(highAll)))\n",
    "    if num and len(highAll) >= 50:\n",
    "        allSequence = []\n",
    "        for i in highAll:\n",
    "            allSequenceIndexRow = []\n",
    "            for j in range(len(i[1])):\n",
    "                allSequence.append(' '.join(i[1][j]).lower())\n",
    "        counter = Counter(allSequence)\n",
    "        newHighAll = []\n",
    "        for i in highAll:\n",
    "            newHighAllRow = []\n",
    "            labelRow = []\n",
    "            sequenceRow = []\n",
    "            for j in range(len(i[1])):\n",
    "                check = ' '.join(i[1][j]).lower()\n",
    "                if counter[check] >= 2:\n",
    "                    labelRow.append(i[0][j])\n",
    "                    sequenceRow.append(i[1][j])\n",
    "                else:\n",
    "                    for k in i[1][j]:\n",
    "                        if counter[k.lower()] >= 2:\n",
    "                            labelRow.append(i[0][j])\n",
    "                            sequenceRow.append(i[1][j])\n",
    "            newHighAllRow.append(labelRow)\n",
    "            newHighAllRow.append(sequenceRow)\n",
    "            newHighAll.append(newHighAllRow)\n",
    "        added = False\n",
    "        if newHighAll:\n",
    "            for a in range(len(unlabeled_sup)):\n",
    "                changed = False\n",
    "                if a not in highIndex:\n",
    "                    for qq in range(len(newHighAll)):\n",
    "                        if a != highIndex[qq]:\n",
    "                            labelNew = replaceLabel(unlabeled_sup[a],labelAll[a],newHighAll[qq],labelConfAll[a])\n",
    "                            if labelNew:\n",
    "                                #print(labelAll[a])\n",
    "                                labelAll[a] = labelNew\n",
    "                                #print(labelAll[a])\n",
    "                                changed = True\n",
    "                                break\n",
    "                #labelReplace = ruleReplace(Xall[a],labelAll[a])\n",
    "                #if labelReplace != labelAll[a]:\n",
    "                #    labelAll[a] = labelReplace\n",
    "                #    changed = True\n",
    "                if changed:\n",
    "                    labelAll[a] = filterPro(labelAll[a])\n",
    "                    #for l in range(len(X_unlabeled_sup[a])):\n",
    "                    #    if newBias <= 0:\n",
    "                    #        X_unlabeled_sup[a][l]['bias'] = 0\n",
    "                    #    else:\n",
    "                    #        X_unlabeled_sup[a][l]['bias'] = newBias\n",
    "                    X_train_sup.append(X_unlabeled_sup[a])\n",
    "                    y_train_sup.append(labelAll[a])\n",
    "                    if a not in num:\n",
    "                        row = []\n",
    "                        row.append(unlabeled_sup[a])\n",
    "                        row.append(labelAll[a])\n",
    "                        label_for_unlabeled.append(row)\n",
    "                        num.append(a)\n",
    "                    added = True\n",
    "        #print('after replace: '+str(len(num)))\n",
    "        if added:\n",
    "            crf.fit(X_train_sup, y_train_sup)\n",
    "        else:\n",
    "            num = []\n",
    "            for a in range(len(unlabeled_sup)):\n",
    "                row = []\n",
    "                row.append(unlabeled_sup[a])\n",
    "                row.append(labelAll[a])\n",
    "                label_for_unlabeled.append(row)\n",
    "                num.append(a)\n",
    "        num.sort(reverse=True) #num\n",
    "        for i in num: #num\n",
    "            X_unlabeled_sup.pop(i)\n",
    "            unlabeled_sup.pop(i)\n",
    "        y_pred = crf.predict(X_test)\n",
    "        evaluatione(y_pred)\n",
    "    else:\n",
    "        num = []\n",
    "        for a in range(len(unlabeled_sup)):\n",
    "            row = []\n",
    "            row.append(unlabeled_sup[a])\n",
    "            row.append(labelAll[a])\n",
    "            label_for_unlabeled.append(row)\n",
    "            num.append(a)\n",
    "        num.sort(reverse=True)\n",
    "        for i in num:\n",
    "            X_unlabeled_sup.pop(i)\n",
    "            unlabeled_sup.pop(i)\n",
    "y_pred = crf.predict(X_test)\n",
    "labels = list(crf.classes_)\n",
    "labels.remove('O') # remove 'O' label from evaluation\n",
    "sorted_labels = sorted(labels,key=lambda name: (name[1:], name[0])) # group B and I results\n",
    "print(flat_classification_report(y_test, y_pred, labels=sorted_labels, digits=3))\n",
    "#print(label_for_unlabeled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "142\n"
     ]
    }
   ],
   "source": [
    "allSequence = []\n",
    "for i in highAll:\n",
    "    allSequenceIndexRow = []\n",
    "    for j in range(len(i[1])):\n",
    "        allSequence.append(' '.join(i[1][j]).lower())\n",
    "counter = Counter(allSequence)\n",
    "newHighAll = []\n",
    "for i in highAll:\n",
    "    newHighAllRow = []\n",
    "    labelRow = []\n",
    "    sequenceRow = []\n",
    "    for j in range(len(i[1])):\n",
    "        check = ' '.join(i[1][j]).lower()\n",
    "        if counter[check] >= 2:\n",
    "            labelRow.append(i[0][j])\n",
    "            sequenceRow.append(i[1][j])\n",
    "        else:\n",
    "            for k in i[1][j]:\n",
    "                if counter[k.lower()] >= 2:\n",
    "                    labelRow.append(i[0][j])\n",
    "                    sequenceRow.append(i[1][j])\n",
    "    newHighAllRow.append(labelRow)\n",
    "    newHighAllRow.append(sequenceRow)\n",
    "    newHighAll.append(newHighAllRow)\n",
    "kj = 0\n",
    "for i in range(len(highAll)):\n",
    "    if highAll[i] != newHighAll[i]:\n",
    "        #print(highAll[i])\n",
    "        #print(newHighAll[i])\n",
    "        kj += 1\n",
    "print(kj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#per label replace\n",
    "upperHigh = 1\n",
    "lowerHigh = 0.98\n",
    "upperLow = 0.8\n",
    "lowerLow = 0\n",
    "w = 0\n",
    "label_for_unlabeled = []\n",
    "while(X_unlabeled_sup):#or w < 1 (default: X_unlabeled_sup)\n",
    "    print(str(w) + ' - data left:' + str(len(X_unlabeled_sup)))\n",
    "    found = False\n",
    "    noNew = True\n",
    "    num = []\n",
    "    confidenceAll = []\n",
    "    labelAll = []\n",
    "    w += 1\n",
    "    tokensHigh = []\n",
    "    labelsHigh = []\n",
    "    for z in range(len(X_unlabeled_sup)): #X_test/X_unlabeled\n",
    "        a = crf.predict_marginals_single(X_unlabeled_sup[z])\n",
    "        b = crf.predict_single(X_unlabeled_sup[z])\n",
    "        labelAll.append(b)\n",
    "        #b = y_pred[z]\n",
    "        #total = 0\n",
    "        size = len(a)\n",
    "        cRow = []\n",
    "        highFound = False\n",
    "        for i in range(size):\n",
    "            #total += a[i][b[i]]\n",
    "            cRow.append(a[i][b[i]])\n",
    "            if b[i] != 'O':\n",
    "                if a[i][b[i]] >= lowerHigh and a[i][b[i]] <= upperHigh:\n",
    "                    labelsHigh.append(b[i])\n",
    "                    tokensHigh.append(unlabeled_sup[z][i])\n",
    "                    highFound = True\n",
    "        if highFound:\n",
    "            row = []\n",
    "            row.append(unlabeled_sup[z])\n",
    "            row.append(b)\n",
    "            label_for_unlabeled.append(row)\n",
    "            num.append(z)\n",
    "        #confidence = total / size\n",
    "        confidenceAll.append(cRow)\n",
    "    if num:\n",
    "        added = False\n",
    "        if tokensHigh:\n",
    "            for a in range(len(unlabeled_sup)):\n",
    "                lowConf = False\n",
    "                for b in range(len(unlabeled_sup[a])):\n",
    "                    if unlabeled_sup[a][b] in tokensHigh:\n",
    "                        pos = tokensHigh.index(unlabeled_sup[a][b])\n",
    "                        newLabel = labelsHigh[pos]\n",
    "                        if (b == 0 and newLabel[0] == 'I') or (labelAll[a][b - 1][0] == 'O' and newLabel[0] == 'I'):\n",
    "                            newLabel = newLabel[:0] + 'B' + newLabel[1:]\n",
    "                        labelAll[a][b] = newLabel\n",
    "                        if confidenceAll[a][b] >= lowerLow and confidenceAll[a][b] <= upperLow:\n",
    "                            lowConf = True\n",
    "                if lowConf:\n",
    "                    X_train_sup.append(X_unlabeled_sup[a])\n",
    "                    y_train_sup.append(labelAll[a])\n",
    "                    row = []\n",
    "                    row.append(unlabeled_sup[a])\n",
    "                    row.append(labelAll[a])\n",
    "                    label_for_unlabeled.append(row)\n",
    "                    num.append(a)\n",
    "                    added = True\n",
    "        if added:\n",
    "            crf.fit(X_train_sup, y_train_sup)\n",
    "        num.sort(reverse=True)\n",
    "        for i in num:\n",
    "            X_unlabeled_sup.pop(i)\n",
    "            unlabeled_sup.pop(i)\n",
    "    else:\n",
    "        for a in range(len(unlabeled_sup)):\n",
    "            row = []\n",
    "            row.append(unlabeled_sup[a])\n",
    "            row.append(labelAll[a])\n",
    "            label_for_unlabeled.append(row)\n",
    "            num.append(a)\n",
    "        num.sort(reverse=True)\n",
    "        for i in num:\n",
    "            X_unlabeled_sup.pop(i)\n",
    "            unlabeled_sup.pop(i)\n",
    "y_pred = crf.predict(X_test)\n",
    "labels = list(crf.classes_)\n",
    "labels.remove('O') # remove 'O' label from evaluation\n",
    "sorted_labels = sorted(labels,key=lambda name: (name[1:], name[0])) # group B and I results\n",
    "print(flat_classification_report(y_test, y_pred, labels=sorted_labels, digits=3))\n",
    "#print(label_for_unlabeled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataTest_labels = []\n",
    "for sentence in dataTest:\n",
    "    aa = [token[1] for token in sentence]\n",
    "    dataTest_labels.append(aa)\n",
    "    \n",
    "dataTest_token = []\n",
    "for sentence in dataTest:\n",
    "    aa = [token[0] for token in sentence]\n",
    "    dataTest_token.append(aa)\n",
    "\n",
    "#print(dataTest_labels[0])\n",
    "#print(dataTest_token[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#per entity evaluation\n",
    "def evaluatione(y_pred):\n",
    "    bra_data = []\n",
    "    bra_guess = []\n",
    "    typ_data = []\n",
    "    typ_guess = []\n",
    "    pro_data = []\n",
    "    pro_guess = []\n",
    "    o_data = []\n",
    "    o_guess = []\n",
    "    for i in range(len(dataTest)):\n",
    "        bra_data_row = []\n",
    "        bra_guess_row = []\n",
    "        typ_data_row = []\n",
    "        typ_guess_row = []\n",
    "        pro_data_row = []\n",
    "        pro_guess_row = []\n",
    "        o_data_row = []\n",
    "        o_guess_row = []\n",
    "        sen_pro_data = ''\n",
    "        sen_pro_guess = ''\n",
    "        sen_typ_data = ''\n",
    "        sen_typ_guess = ''\n",
    "        sen_bra_data = ''\n",
    "        sen_bra_guess = ''\n",
    "        for j in range(len(dataTest[i])):        \n",
    "            if dataTest_labels[i][j] == 'O':\n",
    "                o_data_row.append(dataTest_token[i][j])\n",
    "                if sen_pro_data:\n",
    "                    pro_data_row.append(sen_pro_data)\n",
    "                    sen_pro_data = ''\n",
    "                elif sen_bra_data:\n",
    "                    bra_data_row.append(sen_bra_data)\n",
    "                    sen_bra_data = ''\n",
    "                elif sen_typ_data:\n",
    "                    typ_data_row.append(sen_typ_data)\n",
    "                    sen_typ_data = ''\n",
    "            else:\n",
    "                if '|' in dataTest_labels[i][j]:\n",
    "                    if sen_pro_data and dataTest_labels[i][j][0] == 'B':\n",
    "                        pro_data_row.append(sen_pro_data)\n",
    "                        sen_pro_data = ''\n",
    "                        sen_pro_data += dataTest_token[i][j]\n",
    "                    elif dataTest_labels[i][j][0] == 'B':\n",
    "                        sen_pro_data += dataTest_token[i][j]\n",
    "                    elif dataTest_labels[i][j][0] == 'I':\n",
    "                        sen_pro_data += ' ' + dataTest_token[i][j]\n",
    "                    if dataTest_labels[i][j][8:] == 'BRA':\n",
    "                        if sen_bra_data and dataTest_labels[i][j][6:7] == 'B':\n",
    "                            bra_data_row.append(sen_bra_data)\n",
    "                            sen_bra_data = ''\n",
    "                            sen_bra_data += dataTest_token[i][j]\n",
    "                        elif dataTest_labels[i][j][6:7] == 'B':\n",
    "                            sen_bra_data += dataTest_token[i][j]\n",
    "                        elif dataTest_labels[i][j][6:7] == 'I':\n",
    "                            sen_bra_data += ' ' + dataTest_token[i][j]\n",
    "                    elif dataTest_labels[i][j][8:] == 'TYP':\n",
    "                        if sen_typ_data and dataTest_labels[i][j][6:7] == 'B':\n",
    "                            typ_data_row.append(sen_typ_data)\n",
    "                            sen_typ_data = ''\n",
    "                            sen_typ_data += dataTest_token[i][j]\n",
    "                        elif dataTest_labels[i][j][6:7] == 'B':\n",
    "                            sen_typ_data += dataTest_token[i][j]\n",
    "                        elif dataTest_labels[i][j][6:7] == 'I':\n",
    "                            sen_typ_data += ' ' + dataTest_token[i][j]\n",
    "                elif dataTest_labels[i][j][2:5] == 'PRO':\n",
    "                    if sen_pro_data and dataTest_labels[i][j][0] == 'B':\n",
    "                        pro_data_row.append(sen_pro_data)\n",
    "                        sen_pro_data = ''\n",
    "                        sen_pro_data += dataTest_token[i][j]\n",
    "                    elif dataTest_labels[i][j][0] == 'B':\n",
    "                        sen_pro_data += dataTest_token[i][j]\n",
    "                    elif dataTest_labels[i][j][0] == 'I':\n",
    "                        sen_pro_data += ' ' + dataTest_token[i][j]\n",
    "                elif dataTest_labels[i][j][2:5] == 'BRA':\n",
    "                    if sen_bra_data and dataTest_labels[i][j][0] == 'B':\n",
    "                        bra_data_row.append(sen_bra_data)\n",
    "                        sen_bra_data = ''\n",
    "                        sen_bra_data += dataTest_token[i][j]\n",
    "                    elif dataTest_labels[i][j][0] == 'B':\n",
    "                        sen_bra_data += dataTest_token[i][j]\n",
    "                    elif dataTest_labels[i][j][0] == 'I':\n",
    "                        sen_bra_data += ' ' + dataTest_token[i][j]\n",
    "                elif dataTest_labels[i][j][2:5] == 'TYP':\n",
    "                    if sen_typ_data and dataTest_labels[i][j][0] == 'B':\n",
    "                        typ_data_row.append(sen_typ_data)\n",
    "                        sen_typ_data = ''\n",
    "                        sen_typ_data += dataTest_token[i][j]\n",
    "                    elif dataTest_labels[i][j][0] == 'B':\n",
    "                        sen_typ_data += dataTest_token[i][j]\n",
    "                    elif dataTest_labels[i][j][0] == 'I':\n",
    "                        sen_typ_data += ' ' + dataTest_token[i][j]\n",
    "            if y_pred[i][j] == 'O':\n",
    "                o_guess_row.append(dataTest_token[i][j])\n",
    "                if sen_pro_guess:\n",
    "                    pro_guess_row.append(sen_pro_guess)\n",
    "                    sen_pro_guess = ''\n",
    "                elif sen_bra_guess:\n",
    "                    bra_guess_row.append(sen_bra_guess)\n",
    "                    sen_bra_guess = ''\n",
    "                elif sen_typ_guess:\n",
    "                    typ_guess_row.append(sen_typ_guess)\n",
    "                    sen_typ_guess = ''\n",
    "            else:\n",
    "                if '|' in y_pred[i][j]:\n",
    "                    if sen_pro_guess and y_pred[i][j][0] == 'B':\n",
    "                        pro_guess_row.append(sen_pro_guess)\n",
    "                        sen_pro_guess = ''\n",
    "                        sen_pro_guess += dataTest_token[i][j]\n",
    "                    elif y_pred[i][j][0] == 'B':\n",
    "                        sen_pro_guess += dataTest_token[i][j]\n",
    "                    elif y_pred[i][j][0] == 'I':\n",
    "                        sen_pro_guess += ' ' + dataTest_token[i][j]\n",
    "                    if y_pred[i][j][8:] == 'BRA':\n",
    "                        if sen_bra_guess and y_pred[i][j][6:7] == 'B':\n",
    "                            bra_guess_row.append(sen_bra_guess)\n",
    "                            sen_bra_guess = ''\n",
    "                            sen_bra_guess += dataTest_token[i][j]\n",
    "                        elif y_pred[i][j][6:7] == 'B':\n",
    "                            sen_bra_guess += dataTest_token[i][j]\n",
    "                        elif y_pred[i][j][6:7] == 'I':\n",
    "                            sen_bra_guess += ' ' + dataTest_token[i][j]\n",
    "                    elif y_pred[i][j][8:] == 'TYP':\n",
    "                        if sen_typ_guess and y_pred[i][j][6:7] == 'B':\n",
    "                            typ_guess_row.append(sen_typ_guess)\n",
    "                            sen_typ_guess = ''\n",
    "                            sen_typ_guess += dataTest_token[i][j]\n",
    "                        elif y_pred[i][j][6:7] == 'B':\n",
    "                            sen_typ_guess += dataTest_token[i][j]\n",
    "                        elif y_pred[i][j][6:7] == 'I':\n",
    "                            sen_typ_guess += ' ' + dataTest_token[i][j]\n",
    "                elif y_pred[i][j][2:5] == 'PRO':\n",
    "                    if sen_pro_guess and y_pred[i][j][0] == 'B':\n",
    "                        pro_guess_row.append(sen_pro_guess)\n",
    "                        sen_pro_guess = ''\n",
    "                        sen_pro_guess += dataTest_token[i][j]\n",
    "                    elif y_pred[i][j][0] == 'B':\n",
    "                        sen_pro_guess += dataTest_token[i][j]\n",
    "                    elif y_pred[i][j][0] == 'I':\n",
    "                        sen_pro_guess += ' ' + dataTest_token[i][j]\n",
    "                elif y_pred[i][j][2:5] == 'BRA':\n",
    "                    if sen_bra_guess and y_pred[i][j][0] == 'B':\n",
    "                        bra_guess_row.append(sen_bra_guess)\n",
    "                        sen_bra_guess = ''\n",
    "                        sen_bra_guess += dataTest_token[i][j]\n",
    "                    elif y_pred[i][j][0] == 'B':\n",
    "                        sen_bra_guess += dataTest_token[i][j]\n",
    "                    elif y_pred[i][j][0] == 'I':\n",
    "                        sen_bra_guess += ' ' + dataTest_token[i][j]\n",
    "                elif y_pred[i][j][2:5] == 'TYP':\n",
    "                    if sen_typ_guess and y_pred[i][j][0] == 'B':\n",
    "                        typ_guess_row.append(sen_typ_guess)\n",
    "                        sen_typ_guess = ''\n",
    "                        sen_typ_guess += dataTest_token[i][j]\n",
    "                    elif y_pred[i][j][0] == 'B':\n",
    "                        sen_typ_guess += dataTest_token[i][j]\n",
    "                    elif y_pred[i][j][0] == 'I':\n",
    "                        sen_typ_guess += ' ' + dataTest_token[i][j]\n",
    "        if sen_pro_data:\n",
    "            pro_data_row.append(sen_pro_data)\n",
    "        if sen_bra_data:\n",
    "            bra_data_row.append(sen_bra_data)\n",
    "        if sen_typ_data:\n",
    "            typ_data_row.append(sen_typ_data)\n",
    "        if sen_pro_guess:\n",
    "            pro_guess_row.append(sen_pro_guess)\n",
    "        if sen_bra_guess:\n",
    "            bra_guess_row.append(sen_bra_guess)\n",
    "        if sen_typ_guess:\n",
    "            typ_guess_row.append(sen_typ_guess)\n",
    "        o_data.append(o_data_row)\n",
    "        o_guess.append(o_guess_row)\n",
    "        pro_data.append(pro_data_row)\n",
    "        pro_guess.append(pro_guess_row)\n",
    "        bra_data.append(bra_data_row)\n",
    "        bra_guess.append(bra_guess_row)\n",
    "        typ_data.append(typ_data_row)\n",
    "        typ_guess.append(typ_guess_row)\n",
    "    '''\n",
    "    for i in range(len(bra_data)):\n",
    "        print('PRO')\n",
    "        print(pro_data[i])\n",
    "        print(pro_guess[i])\n",
    "        print('BRA')\n",
    "        print(bra_data[i])\n",
    "        print(bra_guess[i])\n",
    "        print('TYP')\n",
    "        print(typ_data[i])\n",
    "        print(typ_guess[i])\n",
    "        print('---------')\n",
    "    '''\n",
    "    #none is the actual number from data test, r is number of guess right, g is number of guess\n",
    "    bra = 0\n",
    "    bra_r = 0\n",
    "    bra_g = 0\n",
    "    typ = 0\n",
    "    typ_r = 0\n",
    "    typ_g = 0\n",
    "    pro = 0\n",
    "    pro_r = 0\n",
    "    pro_g = 0\n",
    "    o = 0\n",
    "    o_r = 0\n",
    "    o_g = 0\n",
    "    for i in range(len(pro_data)):\n",
    "        for j in range(len(pro_data[i])):\n",
    "            pro += 1\n",
    "        for j in range(len(pro_guess[i])):\n",
    "            pro_g += 1\n",
    "            if pro_guess[i][j] in pro_data[i]:\n",
    "                pro_r += 1\n",
    "                pro_data[i].remove(pro_guess[i][j])\n",
    "        for j in range(len(bra_data[i])):\n",
    "            bra += 1\n",
    "        for j in range(len(bra_guess[i])):\n",
    "            bra_g += 1\n",
    "            if bra_guess[i][j] in bra_data[i]:\n",
    "                bra_r += 1\n",
    "                bra_data[i].remove(bra_guess[i][j])\n",
    "        for j in range(len(typ_data[i])):\n",
    "            typ += 1\n",
    "        for j in range(len(typ_guess[i])):\n",
    "            typ_g += 1\n",
    "            if typ_guess[i][j] in typ_data[i]:\n",
    "                typ_r += 1\n",
    "                typ_data[i].remove(typ_guess[i][j])\n",
    "        for j in range(len(o_data[i])):\n",
    "            o += 1\n",
    "        for j in range(len(o_guess[i])):\n",
    "            o_g += 1\n",
    "            if o_guess[i][j] in o_data[i]:\n",
    "                o_r += 1\n",
    "                o_data[i].remove(o_guess[i][j])\n",
    "\n",
    "    print('PRO')\n",
    "    precision_pro = pro_r/pro_g\n",
    "    recall_pro = pro_r/pro\n",
    "    f1_pro = 2 * ((precision_pro * recall_pro)/(precision_pro + recall_pro))\n",
    "    print('Precision : ' + str(precision_pro))\n",
    "    print('Recall : ' + str(recall_pro))\n",
    "    print('F1 : ' + str(f1_pro))\n",
    "    print('BRA')\n",
    "    precision_bra = bra_r/bra_g\n",
    "    recall_bra = bra_r/bra\n",
    "    f1_bra = 2 * ((precision_bra * recall_bra)/(precision_bra + recall_bra))\n",
    "    print('Precision : ' + str(precision_bra))\n",
    "    print('Recall : ' + str(recall_bra))\n",
    "    print('F1 : ' + str(f1_bra))\n",
    "    print('TYP')\n",
    "    precision_typ = typ_r/typ_g\n",
    "    recall_typ = typ_r/typ\n",
    "    f1_typ = 2 * ((precision_typ * recall_typ)/(precision_typ + recall_typ))\n",
    "    print('Precision : ' + str(precision_typ))\n",
    "    print('Recall : ' + str(recall_typ))\n",
    "    print('F1 : ' + str(f1_typ))\n",
    "    print('O')\n",
    "    precision_o = o_r/o_g\n",
    "    recall_o = o_r/o\n",
    "    f1_o = 2 * ((precision_o * recall_o)/(precision_o + recall_o))\n",
    "    print('Precision : ' + str(precision_o))\n",
    "    print('Recall : ' + str(recall_o))\n",
    "    print('F1 : ' + str(f1_o))\n",
    "    print('Overall Without O')\n",
    "    total = pro + typ + bra\n",
    "    precision = ((pro * precision_pro) + (bra * precision_bra) + (typ * precision_typ)) / total\n",
    "    recall = ((pro * recall_pro) + (bra * recall_bra) + (typ * recall_typ)) / total\n",
    "    f1 = ((pro * f1_pro) + (bra * f1_bra) + (typ * f1_typ)) / total\n",
    "    print('Precision : ' + str(precision))\n",
    "    print('Recall : ' + str(recall))\n",
    "    print('F1 : ' + str(f1))\n",
    "    print('Overall With O')\n",
    "    total = pro + typ + bra + o\n",
    "    precision = ((pro * precision_pro) + (bra * precision_bra) + (typ * precision_typ) + (o * precision_o)) / total\n",
    "    recall = ((pro * recall_pro) + (bra * recall_bra) + (typ * recall_typ) + (o * recall_o)) / total\n",
    "    f1 = ((pro * f1_pro) + (bra * f1_bra) + (typ * f1_typ) + (o * f1_o)) / total\n",
    "    print('Precision : ' + str(precision))\n",
    "    print('Recall : ' + str(recall))\n",
    "    print('F1 : ' + str(f1))\n",
    "#evaluatione(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write labeled data (previously unlabeled)\n",
    "f = open('labeled_automatically (final) fixedztos hilo not avg min 2 0.99 50.tsv.tsv','w', encoding='utf-8') \n",
    "for i in range(len(label_for_unlabeled)):\n",
    "    for j in range(len(label_for_unlabeled[i][0])):\n",
    "        f.write(label_for_unlabeled[i][0][j])\n",
    "        f.write('\\t')\n",
    "        f.write(label_for_unlabeled[i][1][j])\n",
    "        f.write('\\n')\n",
    "        #print(label_for_unlabeled[i][j])\n",
    "        #print(label_for_unlabeled[i + 1][j])\n",
    "    f.write('\\n')\n",
    "f.write('\\n')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 - data left:16853\n",
      "# of hi conf that is not alone: 257\n",
      "PRO\n",
      "Precision : 0.7913043478260869\n",
      "Recall : 0.6169491525423729\n",
      "F1 : 0.6933333333333335\n",
      "BRA\n",
      "Precision : 0.9254385964912281\n",
      "Recall : 0.86652977412731\n",
      "F1 : 0.8950159066808059\n",
      "TYP\n",
      "Precision : 0.539568345323741\n",
      "Recall : 0.373134328358209\n",
      "F1 : 0.4411764705882353\n",
      "O\n",
      "Precision : 0.9490886235072281\n",
      "Recall : 0.9888670595939751\n",
      "F1 : 0.9685695958948043\n",
      "Overall Without O\n",
      "Precision : 0.8062834349033525\n",
      "Recall : 0.6907426246185148\n",
      "F1 : 0.7416913026196553\n",
      "Overall With O\n",
      "Precision : 0.9292920503302983\n",
      "Recall : 0.9475391341136652\n",
      "F1 : 0.9371182685376654\n",
      "1 - data left:15779\n",
      "# of hi conf that is not alone: 739\n",
      "PRO\n",
      "Precision : 0.7792207792207793\n",
      "Recall : 0.6101694915254238\n",
      "F1 : 0.6844106463878328\n",
      "BRA\n",
      "Precision : 0.9213973799126638\n",
      "Recall : 0.86652977412731\n",
      "F1 : 0.893121693121693\n",
      "TYP\n",
      "Precision : 0.5107913669064749\n",
      "Recall : 0.35323383084577115\n",
      "F1 : 0.4176470588235294\n",
      "O\n",
      "Precision : 0.9492138364779874\n",
      "Recall : 0.9883759004584152\n",
      "F1 : 0.9683991017003529\n",
      "Overall Without O\n",
      "Precision : 0.7947708226203444\n",
      "Recall : 0.6846388606307223\n",
      "F1 : 0.7332639512290994\n",
      "Overall With O\n",
      "Precision : 0.9278039531579956\n",
      "Recall : 0.9462699196164152\n",
      "F1 : 0.9358031557247158\n",
      "2 - data left:14516\n",
      "# of hi conf that is not alone: 964\n",
      "PRO\n",
      "Precision : 0.7713004484304933\n",
      "Recall : 0.5830508474576271\n",
      "F1 : 0.6640926640926641\n",
      "BRA\n",
      "Precision : 0.913232104121475\n",
      "Recall : 0.864476386036961\n",
      "F1 : 0.8881856540084387\n",
      "TYP\n",
      "Precision : 0.5112781954887218\n",
      "Recall : 0.3383084577114428\n",
      "F1 : 0.40718562874251496\n",
      "O\n",
      "Precision : 0.946551724137931\n",
      "Recall : 0.9887033398821218\n",
      "F1 : 0.9671684817424727\n",
      "Overall Without O\n",
      "Precision : 0.7884482037511565\n",
      "Recall : 0.6724313326551373\n",
      "F1 : 0.7225819540047722\n",
      "Overall With O\n",
      "Precision : 0.9246343978736242\n",
      "Recall : 0.9448596812861374\n",
      "F1 : 0.9332623250979714\n",
      "3 - data left:13193\n",
      "# of hi conf that is not alone: 1038\n",
      "PRO\n",
      "Precision : 0.7709251101321586\n",
      "Recall : 0.5932203389830508\n",
      "F1 : 0.6704980842911877\n",
      "BRA\n",
      "Precision : 0.9128540305010894\n",
      "Recall : 0.8603696098562629\n",
      "F1 : 0.8858350951374208\n",
      "TYP\n",
      "Precision : 0.5177304964539007\n",
      "Recall : 0.36318407960199006\n",
      "F1 : 0.4269005847953216\n",
      "O\n",
      "Precision : 0.948210922787194\n",
      "Recall : 0.9891944990176817\n",
      "F1 : 0.9682692307692308\n",
      "Overall Without O\n",
      "Precision : 0.7894675993186687\n",
      "Recall : 0.6785350966429298\n",
      "F1 : 0.7273709498898107\n",
      "Overall With O\n",
      "Precision : 0.9262049029071263\n",
      "Recall : 0.9461288957833874\n",
      "F1 : 0.9348743626117819\n",
      "4 - data left:11989\n",
      "# of hi conf that is not alone: 1097\n",
      "PRO\n",
      "Precision : 0.7641921397379913\n",
      "Recall : 0.5932203389830508\n",
      "F1 : 0.66793893129771\n",
      "BRA\n",
      "Precision : 0.9148471615720524\n",
      "Recall : 0.8603696098562629\n",
      "F1 : 0.8867724867724868\n",
      "TYP\n",
      "Precision : 0.5\n",
      "Recall : 0.35323383084577115\n",
      "F1 : 0.4139941690962099\n",
      "O\n",
      "Precision : 0.9486333647502356\n",
      "Recall : 0.9887033398821218\n",
      "F1 : 0.9682539682539683\n",
      "Overall Without O\n",
      "Precision : 0.784809001941299\n",
      "Recall : 0.676500508646999\n",
      "F1 : 0.7244282947908074\n",
      "Overall With O\n",
      "Precision : 0.9259229785365585\n",
      "Recall : 0.9454237766182485\n",
      "F1 : 0.9344532861196732\n",
      "5 - data left:10824\n",
      "# of hi conf that is not alone: 1069\n",
      "PRO\n",
      "Precision : 0.7705627705627706\n",
      "Recall : 0.6033898305084746\n",
      "F1 : 0.6768060836501901\n",
      "BRA\n",
      "Precision : 0.9108695652173913\n",
      "Recall : 0.8603696098562629\n",
      "F1 : 0.8848996832101371\n",
      "TYP\n",
      "Precision : 0.5035971223021583\n",
      "Recall : 0.3482587064676617\n",
      "F1 : 0.411764705882353\n",
      "O\n",
      "Precision : 0.948178391959799\n",
      "Recall : 0.9885396201702685\n",
      "F1 : 0.9679384418082719\n",
      "Overall Without O\n",
      "Precision : 0.7854857753404075\n",
      "Recall : 0.6785350966429298\n",
      "F1 : 0.725705642199894\n",
      "Overall With O\n",
      "Precision : 0.92562489567763\n",
      "Recall : 0.9455648004512762\n",
      "F1 : 0.934358574086507\n",
      "6 - data left:9661\n",
      "# of hi conf that is not alone: 971\n",
      "PRO\n",
      "Precision : 0.7797356828193832\n",
      "Recall : 0.6\n",
      "F1 : 0.6781609195402298\n",
      "BRA\n",
      "Precision : 0.9154013015184381\n",
      "Recall : 0.86652977412731\n",
      "F1 : 0.890295358649789\n",
      "TYP\n",
      "Precision : 0.5185185185185185\n",
      "Recall : 0.3482587064676617\n",
      "F1 : 0.4166666666666667\n",
      "O\n",
      "Precision : 0.94848437254594\n",
      "Recall : 0.9887033398821218\n",
      "F1 : 0.9681763527054108\n",
      "Overall Without O\n",
      "Precision : 0.7935347736453913\n",
      "Recall : 0.6805696846388606\n",
      "F1 : 0.729787701858408\n",
      "Overall With O\n",
      "Precision : 0.9270042631510395\n",
      "Recall : 0.9459878719503596\n",
      "F1 : 0.9351293855946219\n",
      "7 - data left:8607\n",
      "# of hi conf that is not alone: 849\n",
      "PRO\n",
      "Precision : 0.7763157894736842\n",
      "Recall : 0.6\n",
      "F1 : 0.6768642447418738\n",
      "BRA\n",
      "Precision : 0.9154013015184381\n",
      "Recall : 0.86652977412731\n",
      "F1 : 0.890295358649789\n",
      "TYP\n",
      "Precision : 0.5\n",
      "Recall : 0.34328358208955223\n",
      "F1 : 0.4070796460176991\n",
      "O\n",
      "Precision : 0.9483354271356784\n",
      "Recall : 0.9887033398821218\n",
      "F1 : 0.9680987495992305\n",
      "Overall Without O\n",
      "Precision : 0.788721863412224\n",
      "Recall : 0.6795523906408952\n",
      "F1 : 0.7274382509774745\n",
      "Overall With O\n",
      "Precision : 0.9262087689576844\n",
      "Recall : 0.9458468481173319\n",
      "F1 : 0.9347368443467715\n",
      "8 - data left:7746\n",
      "# of hi conf that is not alone: 806\n",
      "PRO\n",
      "Precision : 0.7695652173913043\n",
      "Recall : 0.6\n",
      "F1 : 0.6742857142857144\n",
      "BRA\n",
      "Precision : 0.9130434782608695\n",
      "Recall : 0.8624229979466119\n",
      "F1 : 0.8870116156282999\n",
      "TYP\n",
      "Precision : 0.5323741007194245\n",
      "Recall : 0.3681592039800995\n",
      "F1 : 0.43529411764705883\n",
      "O\n",
      "Precision : 0.9496300960176295\n",
      "Recall : 0.987721021611002\n",
      "F1 : 0.9683010994302224\n",
      "Overall Without O\n",
      "Precision : 0.7921476167732274\n",
      "Recall : 0.6826042726347915\n",
      "F1 : 0.7308067753533333\n",
      "Overall With O\n",
      "Precision : 0.9277988624684479\n",
      "Recall : 0.9454237766182485\n",
      "F1 : 0.9353781096449195\n",
      "9 - data left:6927\n",
      "# of hi conf that is not alone: 731\n",
      "PRO\n",
      "Precision : 0.7757847533632287\n",
      "Recall : 0.5864406779661017\n",
      "F1 : 0.6679536679536678\n",
      "BRA\n",
      "Precision : 0.9192139737991266\n",
      "Recall : 0.864476386036961\n",
      "F1 : 0.891005291005291\n",
      "TYP\n",
      "Precision : 0.5338345864661654\n",
      "Recall : 0.35323383084577115\n",
      "F1 : 0.4251497005988024\n",
      "O\n",
      "Precision : 0.9461152882205514\n",
      "Recall : 0.9888670595939751\n",
      "F1 : 0.9670188920909383\n",
      "Overall Without O\n",
      "Precision : 0.7973697450274938\n",
      "Recall : 0.676500508646999\n",
      "F1 : 0.7288107818781975\n",
      "Overall With O\n",
      "Precision : 0.9254952249066639\n",
      "Recall : 0.9455648004512762\n",
      "F1 : 0.9339969526833618\n",
      "10 - data left:6195\n",
      "# of hi conf that is not alone: 669\n",
      "PRO\n",
      "Precision : 0.7816593886462883\n",
      "Recall : 0.6067796610169491\n",
      "F1 : 0.683206106870229\n",
      "BRA\n",
      "Precision : 0.9152173913043479\n",
      "Recall : 0.864476386036961\n",
      "F1 : 0.8891235480464625\n",
      "TYP\n",
      "Precision : 0.5179856115107914\n",
      "Recall : 0.3582089552238806\n",
      "F1 : 0.4235294117647059\n",
      "O\n",
      "Precision : 0.9493790284546455\n",
      "Recall : 0.9887033398821218\n",
      "F1 : 0.9686422327371882\n",
      "Overall Without O\n",
      "Precision : 0.7939120011490758\n",
      "Recall : 0.6836215666327569\n",
      "F1 : 0.7321244976501025\n",
      "Overall With O\n",
      "Precision : 0.9278271898082803\n",
      "Recall : 0.946410943449443\n",
      "F1 : 0.9358546239950354\n",
      "11 - data left:5525\n",
      "# of hi conf that is not alone: 579\n"
     ]
    }
   ],
   "source": [
    "#per beginning and inner sequence, don't really care what entity inside those, especially if nested\n",
    "highLimit = 0.99\n",
    "w = 0\n",
    "label_for_unlabeled = []\n",
    "while(X_unlabeled_sup):#or w < 1 (default: X_unlabeled_sup)\n",
    "    print(str(w) + ' - data left:' + str(len(X_unlabeled_sup)))\n",
    "    found = False\n",
    "    noNew = True\n",
    "    num = []\n",
    "    labelAll = []\n",
    "    labelConfAll = []\n",
    "    w += 1\n",
    "    highAll = []\n",
    "    highIndex = []\n",
    "    #Xall = []\n",
    "    #newBias = 1.1**(-w)\n",
    "    for z in range(len(X_unlabeled_sup)): #X_test/X_unlabeled/\n",
    "        a = crf.predict_marginals_single(X_unlabeled_sup[z])\n",
    "        b = crf.predict_single(X_unlabeled_sup[z])\n",
    "        #Xall.append(X_unlabeled_sup[z])\n",
    "        labelAll.append(b)\n",
    "        conf = []\n",
    "        for i in range(len(a)):\n",
    "            conf.append(a[i][b[i]])\n",
    "        labelConfAll.append(conf)\n",
    "        high = extractSequenceLabel(unlabeled_sup[z],b,a,highLimit)\n",
    "        if high[0]:\n",
    "            #X_train_sup.append(X_unlabeled_sup[z])\n",
    "            #y_train_sup.append(labelAll[z])\n",
    "            highAll.append(high)\n",
    "            highIndex.append(z)\n",
    "            row = []\n",
    "            row.append(unlabeled_sup[z])\n",
    "            row.append(b)\n",
    "            label_for_unlabeled.append(row)\n",
    "    #print('before replace: '+str(len(num)))\n",
    "    num = []\n",
    "    allSequence = []\n",
    "    for i in highAll:\n",
    "        allSequenceIndexRow = []\n",
    "        for j in range(len(i[1])):\n",
    "            allSequence.append(' '.join(i[1][j]).lower())\n",
    "    counter = Counter(allSequence)\n",
    "    newHighAll = []\n",
    "    for i in highAll:\n",
    "        newHighAllRow = []\n",
    "        labelRow = []\n",
    "        sequenceRow = []\n",
    "        for j in range(len(i[1])):\n",
    "            check = ' '.join(i[1][j]).lower()\n",
    "            if counter[check] >= 2:\n",
    "                labelRow.append(i[0][j])\n",
    "                sequenceRow.append(i[1][j])\n",
    "            else:\n",
    "                for k in i[1][j]:\n",
    "                    if counter[k.lower()] >= 2:\n",
    "                        labelRow.append(i[0][j])\n",
    "                        sequenceRow.append(i[1][j])\n",
    "        newHighAllRow.append(labelRow)\n",
    "        newHighAllRow.append(sequenceRow)\n",
    "        newHighAll.append(newHighAllRow)\n",
    "    added = False\n",
    "    for i in range(len(newHighAll)):\n",
    "        if newHighAll[i][0]:\n",
    "            num.append(i)\n",
    "            X_train_sup.append(X_unlabeled_sup[highIndex[i]])\n",
    "            y_train_sup.append(labelAll[highIndex[i]])\n",
    "            added = True\n",
    "    print('# of hi conf that is not alone: ' + str(len(num)))\n",
    "    if num and len(num) >= 50:\n",
    "        if newHighAll:\n",
    "            for a in range(len(unlabeled_sup)):\n",
    "                changed = False\n",
    "                if a not in highIndex:\n",
    "                    for qq in range(len(newHighAll)):\n",
    "                        if a != highIndex[qq]:\n",
    "                            labelNew = replaceLabel(unlabeled_sup[a],labelAll[a],newHighAll[qq],labelConfAll[a])\n",
    "                            if labelNew:\n",
    "                                #print(labelAll[a])\n",
    "                                labelAll[a] = labelNew\n",
    "                                #print(labelAll[a])\n",
    "                                changed = True\n",
    "                                break\n",
    "                #labelReplace = ruleReplace(Xall[a],labelAll[a])\n",
    "                #if labelReplace != labelAll[a]:\n",
    "                #    labelAll[a] = labelReplace\n",
    "                #    changed = True\n",
    "                if changed:\n",
    "                    labelAll[a] = filterPro(labelAll[a])\n",
    "                    #for l in range(len(X_unlabeled_sup[a])):\n",
    "                    #    if newBias <= 0:\n",
    "                    #        X_unlabeled_sup[a][l]['bias'] = 0\n",
    "                    #    else:\n",
    "                    #        X_unlabeled_sup[a][l]['bias'] = newBias\n",
    "                    X_train_sup.append(X_unlabeled_sup[a])\n",
    "                    y_train_sup.append(labelAll[a])\n",
    "                    if a not in num:\n",
    "                        row = []\n",
    "                        row.append(unlabeled_sup[a])\n",
    "                        row.append(labelAll[a])\n",
    "                        label_for_unlabeled.append(row)\n",
    "                        num.append(a)\n",
    "                    added = True\n",
    "        #print('after replace: '+str(len(num)))\n",
    "        if added:\n",
    "            crf.fit(X_train_sup, y_train_sup)\n",
    "        else:\n",
    "            num = []\n",
    "            for a in range(len(unlabeled_sup)):\n",
    "                row = []\n",
    "                row.append(unlabeled_sup[a])\n",
    "                row.append(labelAll[a])\n",
    "                label_for_unlabeled.append(row)\n",
    "                num.append(a)\n",
    "        num.sort(reverse=True) #num\n",
    "        for i in num: #num\n",
    "            X_unlabeled_sup.pop(i)\n",
    "            unlabeled_sup.pop(i)\n",
    "        y_pred = crf.predict(X_test)\n",
    "        evaluatione(y_pred)\n",
    "    else:\n",
    "        num = []\n",
    "        for a in range(len(unlabeled_sup)):\n",
    "            row = []\n",
    "            row.append(unlabeled_sup[a])\n",
    "            row.append(labelAll[a])\n",
    "            label_for_unlabeled.append(row)\n",
    "            num.append(a)\n",
    "        num.sort(reverse=True)\n",
    "        for i in num:\n",
    "            X_unlabeled_sup.pop(i)\n",
    "            unlabeled_sup.pop(i)\n",
    "y_pred = crf.predict(X_test)\n",
    "labels = list(crf.classes_)\n",
    "labels.remove('O') # remove 'O' label from evaluation\n",
    "sorted_labels = sorted(labels,key=lambda name: (name[1:], name[0])) # group B and I results\n",
    "print(flat_classification_report(y_test, y_pred, labels=sorted_labels, digits=3))\n",
    "#print(label_for_unlabeled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractEntity(sentence, labels, conf, limit):\n",
    "    bra_data = []\n",
    "    typ_data = []\n",
    "    pro_data = []\n",
    "    sen_pro_data = ''\n",
    "    sen_typ_data = ''\n",
    "    sen_bra_data = ''\n",
    "    confB = 0\n",
    "    confP = 0\n",
    "    confT = 0\n",
    "    sizeB = 0\n",
    "    sizeP = 0\n",
    "    sizeT = 0\n",
    "    for j in range(len(sentence)):\n",
    "        if labels[j] == 'O':\n",
    "            if sen_pro_data:\n",
    "                if (confP/sizeP) >= limit:\n",
    "                    pro_data.append(sen_pro_data)\n",
    "                confP = 0\n",
    "                sizeP = 0\n",
    "                sen_pro_data = ''\n",
    "            if sen_bra_data:\n",
    "                if (confB/sizeB) >= limit:\n",
    "                    bra_data.append(sen_bra_data)\n",
    "                confB = 0\n",
    "                sizeB = 0\n",
    "                sen_bra_data = ''\n",
    "            if sen_typ_data:\n",
    "                if (confT/sizeT) >= limit:\n",
    "                    typ_data.append(sen_typ_data)\n",
    "                confT = 0\n",
    "                sizeT = 0\n",
    "                sen_typ_data = ''\n",
    "        else:\n",
    "            if '|' in labels[j]:\n",
    "                if sen_pro_data and labels[j][0] == 'B':\n",
    "                    if (confP/sizeP) >= limit:\n",
    "                        pro_data.append(sen_pro_data)\n",
    "                    confP = 0\n",
    "                    sizeP = 0\n",
    "                    sen_pro_data = ''\n",
    "                    sen_pro_data += sentence[j]\n",
    "                    confP += conf[j][labels[j]]\n",
    "                    sizeP += 1\n",
    "                elif labels[j][0] == 'B':\n",
    "                    sen_pro_data += sentence[j]\n",
    "                    confP += conf[j][labels[j]]\n",
    "                    sizeP += 1\n",
    "                elif labels[j][0] == 'I':\n",
    "                    sen_pro_data += ' ' + sentence[j]\n",
    "                    confP += conf[j][labels[j]]\n",
    "                    sizeP += 1\n",
    "                if labels[j][8:] == 'BRA':\n",
    "                    if sen_bra_data and labels[j][6:7] == 'B':\n",
    "                        if (confB/sizeB) >= limit:\n",
    "                            bra_data.append(sen_bra_data)\n",
    "                        confB = 0\n",
    "                        sizeB = 0\n",
    "                        sen_bra_data = ''\n",
    "                        sen_bra_data += sentence[j]\n",
    "                        confB += conf[j][labels[j]]\n",
    "                        sizeB += 1\n",
    "                    elif labels[j][6:7] == 'B':\n",
    "                        sen_bra_data += sentence[j]\n",
    "                        confB += conf[j][labels[j]]\n",
    "                        sizeB += 1\n",
    "                    elif labels[j][6:7] == 'I':\n",
    "                        sen_bra_data += ' ' + sentence[j]\n",
    "                        confB += conf[j][labels[j]]\n",
    "                        sizeB += 1\n",
    "                elif labels[j][8:] == 'TYP':\n",
    "                    if sen_typ_data and labels[j][6:7] == 'B':\n",
    "                        if (confT/sizeT) >= limit:\n",
    "                            typ_data.append(sen_typ_data)\n",
    "                        confT = 0\n",
    "                        sizeT = 0\n",
    "                        sen_typ_data = ''\n",
    "                        sen_typ_data += sentence[j]\n",
    "                        confT += conf[j][labels[j]]\n",
    "                        sizeT += 1\n",
    "                    elif labels[j][6:7] == 'B':\n",
    "                        sen_typ_data += sentence[j]\n",
    "                        confT += conf[j][labels[j]]\n",
    "                        sizeT += 1\n",
    "                    elif labels[j][6:7] == 'I':\n",
    "                        sen_typ_data += ' ' + sentence[j]\n",
    "                        confT += conf[j][labels[j]]\n",
    "                        sizeT += 1\n",
    "            elif labels[j][2:5] == 'PRO':\n",
    "                if sen_pro_data and labels[j][0] == 'B':\n",
    "                    if (confP/sizeP) >= limit:\n",
    "                        pro_data.append(sen_pro_data)\n",
    "                    confP = 0\n",
    "                    sizeP = 0\n",
    "                    sen_pro_data = ''\n",
    "                    sen_pro_data += sentence[j]\n",
    "                    confP += conf[j][labels[j]]\n",
    "                    sizeP += 1\n",
    "                elif labels[j][0] == 'B':\n",
    "                    sen_pro_data += sentence[j]\n",
    "                    confP += conf[j][labels[j]]\n",
    "                    sizeP += 1\n",
    "                elif labels[j][0] == 'I':\n",
    "                    sen_pro_data += ' ' + sentence[j]\n",
    "                    confP += conf[j][labels[j]]\n",
    "                    sizeP += 1\n",
    "            elif labels[j][2:5] == 'BRA':\n",
    "                if sen_bra_data and labels[j][0] == 'B':\n",
    "                    if (confB/sizeB) >= limit:\n",
    "                        bra_data.append(sen_bra_data)\n",
    "                    confB = 0\n",
    "                    sizeB = 0\n",
    "                    sen_bra_data = ''\n",
    "                    sen_bra_data += sentence[j]\n",
    "                    confB += conf[j][labels[j]]\n",
    "                    sizeB += 1\n",
    "                elif labels[j][0] == 'B':\n",
    "                    sen_bra_data += sentence[j]\n",
    "                    confB += conf[j][labels[j]]\n",
    "                    sizeB += 1\n",
    "                elif labels[j][0] == 'I':\n",
    "                    sen_bra_data += ' ' + sentence[j]\n",
    "                    confB += conf[j][labels[j]]\n",
    "                    sizeB += 1\n",
    "            elif labels[j][2:5] == 'TYP':\n",
    "                if sen_typ_data and labels[j][0] == 'B':\n",
    "                    if (confT/sizeT) >= limit:\n",
    "                        typ_data.append(sen_typ_data)\n",
    "                    confT = 0\n",
    "                    sizeT = 0\n",
    "                    sen_typ_data = ''\n",
    "                    sen_typ_data += sentence[j]\n",
    "                    confT += conf[j][labels[j]]\n",
    "                    sizeT += 1\n",
    "                elif labels[j][0] == 'B':\n",
    "                    sen_typ_data += sentence[j]\n",
    "                    confT += conf[j][labels[j]]\n",
    "                    sizeT += 1\n",
    "                elif labels[j][0] == 'I':\n",
    "                    sen_typ_data += ' ' + sentence[j]\n",
    "                    confT += conf[j][labels[j]]\n",
    "                    sizeT += 1\n",
    "    if sen_pro_data:\n",
    "        if (confP/sizeP) >= limit:\n",
    "            pro_data.append(sen_pro_data)\n",
    "    if sen_bra_data:\n",
    "        if (confB/sizeB) >= limit:\n",
    "            bra_data.append(sen_bra_data)\n",
    "    if sen_typ_data:\n",
    "        if (confT/sizeT) >= limit:\n",
    "            typ_data.append(sen_typ_data)\n",
    "    return [pro_data,bra_data,typ_data]\n",
    "\n",
    "ii = 16407\n",
    "a = crf.predict_marginals_single(X_unlabeled_sup[ii])\n",
    "b = crf.predict_single(X_unlabeled_sup[ii])\n",
    "pp = extractEntity(unlabeled_sup[ii],b,a,0.98)\n",
    "print(unlabeled_sup[ii])\n",
    "print(b)\n",
    "print(pp)\n",
    "'''\n",
    "for z in range(len(X_unlabeled_sup)): #X_test/X_unlabeled\n",
    "    a = crf.predict_marginals_single(X_unlabeled_sup[z])\n",
    "    b = crf.predict_single(X_unlabeled_sup[z])\n",
    "    labelAll.append(b)\n",
    "    size = len(a)\n",
    "    highFound = False\n",
    "    for i in range(size):\n",
    "        if b[i] != 'O':\n",
    "            if a[i][b[i]] >= 0.5 and a[i][b[i]] <= 0.6:\n",
    "                highFound = True\n",
    "    if highFound:\n",
    "        print(z)\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
